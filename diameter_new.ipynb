{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diameter_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6Pe9TgLQvv578LPtlvY3x"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRG0-NUe6vp6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "#전처리\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# 매개변수 그리드\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# 성능 평가\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "f1_scorer = make_scorer(f1_score, pos_label=\"Y\")\n",
        "\n",
        "\n",
        "#파이프라인\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import make_pipeline\n",
        "\n",
        "# model\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fofDiLPi7XMA"
      },
      "source": [
        "# 딥러닝\n",
        "import tensorflow\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCEeyUtU7YZh"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "link = 'https://drive.google.com/file/d/1zdaujvrEHpei8_MIr5RRq-uA6LsCVCzZ/view?usp=sharing' # The shareable link\n",
        "#fluff, id = link.split('=')\n",
        "#print (id) # Verify that you have everything after '='\n",
        "id = '1zdaujvrEHpei8_MIr5RRq-uA6LsCVCzZ'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('results.csv') \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R9WDTJt7b63",
        "outputId": "6dbac2b0-85ae-4056-8b66-8ced461b6737"
      },
      "source": [
        "datas = pd.read_csv('results.csv')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gzb4Bi-7221",
        "outputId": "782a815c-ba9f-4a17-da00-05d17f61a0da"
      },
      "source": [
        "datas.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1079619, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jzZFI-67tbP",
        "outputId": "5584d6de-e055-4dbb-e170-f23bdcf1f4b3"
      },
      "source": [
        "datas.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name        1057436\n",
              "neo               2\n",
              "pha           10615\n",
              "H              3986\n",
              "diameter     939620\n",
              "albedo       940771\n",
              "rot_per     1047042\n",
              "spec_B      1077953\n",
              "e                 0\n",
              "a                 0\n",
              "q                 0\n",
              "i                 0\n",
              "om                0\n",
              "w                 0\n",
              "ma                1\n",
              "ad                2\n",
              "n                 0\n",
              "tp                0\n",
              "per               2\n",
              "moid          10615\n",
              "class             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDI90vR7vJo",
        "outputId": "e69092bc-866e-4291-e255-65e95e6bb966"
      },
      "source": [
        "X = datas.drop(['name', 'spec_B', 'rot_per'], axis=1)\n",
        "X = X.dropna(subset=['diameter', 'moid', 'H', 'ma', 'albedo', 'pha', 'ad', 'neo'])\n",
        "y = X['diameter']\n",
        "\n",
        "X = X.drop(['diameter'], axis=1)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(136393, 17)\n",
            "(136393,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "FT5fOoZL9agE",
        "outputId": "56b81d79-90c7-4573-e12c-561503c917f3"
      },
      "source": [
        "plt.hist( y, bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "EVNnjJDY9t2h",
        "outputId": "310882a4-78d0-40e1-bf57-4561312aa6c9"
      },
      "source": [
        "plt.boxplot(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7f5cd7a26090>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f5cd7e3dd90>,\n",
              "  <matplotlib.lines.Line2D at 0x7f5cd7e47350>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f5cd7bbb710>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f5cd7e61350>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7f5cd7a713d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f5cd7a26350>]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH8hpAaj-7Bo"
      },
      "source": [
        "def remove_mask(data):\n",
        "  q1 = np.percentile(data, 25)\n",
        "  q3 = np.percentile(data, 75)\n",
        "  print(q1)\n",
        "  print(q3)\n",
        "  iqr = q3-q1\n",
        "  iqr = iqr * 1.5\n",
        "\n",
        "  lowest = q1 - iqr\n",
        "  hightest = q3 + iqr\n",
        "  print(hightest)\n",
        "  mask_index = data[(data > lowest) | (data < hightest)]\n",
        "  print(mask_index)\n",
        "  return mask_index"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNXJ6FkREjBy",
        "outputId": "991b870f-c6f1-4824-dcb1-a87d22964381"
      },
      "source": [
        "mask = remove_mask(np.array(y))\n",
        "mask.shape"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.8110000000000004\n",
            "5.79\n",
            "10.2585\n",
            "[939.4   545.    246.596 ...   2.182   2.887   2.226]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(136393,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2NWzeFIH-wT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zL8pwdE_15_",
        "outputId": "f82a61ae-8e11-4c2e-c473-e7f0e11123db"
      },
      "source": [
        "X = pd.get_dummies(X)\n",
        "X_res = X[:50000]\n",
        "y_res = y[:50000]\n",
        "# 데이터는 50000개로 제한\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, random_state=0)\n",
        "# 훈련 / 테스트 데이터로 분할\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37500, 29)\n",
            "(12500, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93s1adDw_8uQ"
      },
      "source": [
        "# 스케일링\n",
        "\n",
        "stdscaler = StandardScaler()\n",
        "\n",
        "X_train_sscaled = stdscaler.fit_transform(X_train)\n",
        "X_test_sscaled = stdscaler.transform(X_test)\n",
        "\n",
        "mmscaler = MinMaxScaler()\n",
        "X_train_mscaled = mmscaler.fit_transform(X_train)\n",
        "X_test_mscaled = mmscaler.transform(X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgmlfRlYAKud",
        "outputId": "c4565c21-25c8-4e0e-d718-ae2d5d784748"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=0).fit(X_train, y_train)\n",
        "print(rf.score(X_test, y_test))\n",
        "print(mean_squared_error(y_test, rf.predict(X_test)))\n",
        "print(mean_absolute_error(y_test, rf.predict(X_test)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9539735240169872\n",
            "9.352734611171474\n",
            "0.6270222336000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L5iTas8BJkO"
      },
      "source": [
        "# 중요도 함수\n",
        "def plot_feature_importances(model, X, fea):\n",
        "    n_features = X.shape[1]\n",
        "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
        "    plt.yticks(np.arange(n_features), fea)\n",
        "    plt.xlabel(\"importances\")\n",
        "    plt.ylabel(\"feature\")\n",
        "    plt.ylim(-1, n_features)\n",
        "    plt.xlim(0,1)\n",
        "    plt.grid()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "wfhD0ejjBMj_",
        "outputId": "ac508fdc-c761-446a-8c71-229513c98e59"
      },
      "source": [
        "features = X_train.columns\n",
        "print(features)\n",
        "\n",
        "plot_feature_importances(rf, X_train, features)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['H', 'albedo', 'e', 'a', 'q', 'i', 'om', 'w', 'ma', 'ad', 'n', 'tp',\n",
            "       'per', 'moid', 'neo_N', 'neo_Y', 'pha_N', 'pha_Y', 'class_AMO',\n",
            "       'class_APO', 'class_AST', 'class_ATE', 'class_CEN', 'class_IMB',\n",
            "       'class_MBA', 'class_MCA', 'class_OMB', 'class_TJN', 'class_TNO'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "p8Wzt8A7DHvG",
        "outputId": "4020078b-dab1-41d4-be9e-3575514adece"
      },
      "source": [
        "plt.plot(X_res.albedo, y_res, '.')\n",
        "plt.xlabel('albedo')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'albedo')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "6d-23XnLDR1j",
        "outputId": "c2a4f5f3-d950-4a03-8d2f-4c548a47ea0a"
      },
      "source": [
        "plt.plot(X_res.H, y_res, '.')\n",
        "plt.xlabel('H')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'H')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME78553KBcPS",
        "outputId": "801768ea-1a24-4251-ac44-385b13d82a39"
      },
      "source": [
        "param_grid = { \n",
        "              'max_depth' : [1,2,3,5,7,9,11,13,15]\n",
        "             }\n",
        "\n",
        "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=0), param_grid, cv=5)\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"테스트 세트 점수 : \", grid_search_rf.score(X_test, y_test))\n",
        "print(\"최적 매개변수 \", grid_search_rf.best_params_)\n",
        "print(\"최적 교차 검증 점수 \", grid_search_rf.best_score_)\n",
        "print(\"최적 성능 모델 \", grid_search_rf.best_estimator_)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 세트 점수 :  0.954077754458425\n",
            "최적 매개변수  {'max_depth': 11}\n",
            "최적 교차 검증 점수  0.9438651587060936\n",
            "최적 성능 모델  RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=11, max_features='auto', max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
            "                      random_state=0, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3lNJQ5ACNnY",
        "outputId": "73601216-ed9c-46b5-d73d-d5f6162353d2"
      },
      "source": [
        "rf_grid = RandomForestRegressor(max_depth=11, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "print(rf_grid.score(X_test, y_test))\n",
        "print(mean_squared_error(y_test, rf_grid.predict(X_test)))\n",
        "print(mean_absolute_error(y_test, rf_grid.predict(X_test)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.954077754458425\n",
            "9.331554635160865\n",
            "0.6252035440559272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em-lIwu8BTTJ",
        "outputId": "77bec4a8-cfab-4773-ef8d-42df87a57eaf"
      },
      "source": [
        "rf_grid = RandomForestRegressor(max_depth=13, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "print(rf_grid.score(X_test, y_test))\n",
        "print(mean_squared_error(y_test, rf_grid.predict(X_test)))\n",
        "print(mean_absolute_error(y_test, rf_grid.predict(X_test)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9540768085175082\n",
            "9.331746853534412\n",
            "0.6237439947556174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VB879fAe6bw"
      },
      "source": [
        "rf_grid = RandomForestRegressor(max_depth=13).fit(X_train, y_train)\n",
        "\n",
        "print(rf_grid.score(X_test, y_test))\n",
        "print(mean_squared_error(y_test, rf_grid.predict(X_test)))\n",
        "print(mean_absolute_error(y_test, rf_grid.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjvqJMRwAMmN",
        "outputId": "bb2c8483-0604-4927-adbe-0be835d78977"
      },
      "source": [
        "xg = XGBRegressor(random_state=0).fit(X_train, y_train)\n",
        "print(xg.score(X_test, y_test))\n",
        "print(mean_squared_error(y_test, xg.predict(X_test)))\n",
        "print(mean_absolute_error(y_test, xg.predict(X_test)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[08:08:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "0.9213034194695613\n",
            "15.991409656901105\n",
            "0.7276772583573533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqN3qz_2DooB",
        "outputId": "57a9aeb3-c601-4e8b-9e83-ac28fc0bcf8b"
      },
      "source": [
        "param_grid = { \n",
        "              'max_depth' : [1,2,3,5,7,9,11,13],\n",
        "             }\n",
        "\n",
        "grid_search_xg = GridSearchCV(XGBRegressor(random_state=0), param_grid, cv=5)\n",
        "grid_search_xg.fit(X_train, y_train)\n",
        "\n",
        "print(\"테스트 세트 점수 : \", grid_search_xg.score(X_test, y_test))\n",
        "print(\"최적 매개변수 \", grid_search_xg.best_params_)\n",
        "print(\"최적 교차 검증 점수 \", grid_search_xg.best_score_)\n",
        "print(\"최적 성능 모델 \", grid_search_xg.best_estimator_)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[08:36:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:37:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:38:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:38:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:38:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:38:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:38:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:38:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:38:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:39:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:39:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:39:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:39:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:40:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:40:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:40:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:40:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:41:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:41:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:41:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "테스트 세트 점수 :  0.8995006668109763\n",
            "최적 매개변수  {'max_depth': 7}\n",
            "최적 교차 검증 점수  0.9787807734040571\n",
            "최적 성능 모델  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
            "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "             silent=None, subsample=1, verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmmz8GC7DvMq",
        "outputId": "5c1e4651-1a98-4688-b0d9-ea4850881e1d"
      },
      "source": [
        "xg_grid = XGBRegressor(max_depth=7, learning_rate=0.1, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "print(xg_grid.score(X_test, y_test)) \n",
        "print(mean_squared_error(y_test, xg_grid.predict(X_test)))\n",
        "print(mean_absolute_error(y_test, xg_grid.predict(X_test)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[08:06:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "0.8995006668109763\n",
            "20.421802274489714\n",
            "0.6407373584480286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I-g0yM8AOFW",
        "outputId": "c0e79d86-170b-4908-fe6c-3126b701d2a7"
      },
      "source": [
        "svr = SVR().fit(X_train_sscaled, y_train)\n",
        "print(svr.score(X_test_sscaled, y_test))\n",
        "print(mean_squared_error(y_test, svr.predict(X_test_sscaled)))\n",
        "print(mean_absolute_error(y_test, svr.predict(X_test_sscaled)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6079715076181682\n",
            "79.6615072294077\n",
            "1.2851494069299174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OToWQaC2BFIn",
        "outputId": "797661ca-3dc5-4b51-88fe-caf33fa9721d"
      },
      "source": [
        "svr = SVR().fit(X_train_mscaled, y_train)\n",
        "print(svr.score(X_test_mscaled, y_test))\n",
        "print(mean_squared_error(y_test, svr.predict(X_test_mscaled)))\n",
        "print(mean_absolute_error(y_test, svr.predict(X_test_mscaled)))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3532971288355967\n",
            "131.41219693890122\n",
            "2.1619269559406438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BwgzENBCVDt",
        "outputId": "5c966eeb-d211-41ca-87e5-647b4454cd77"
      },
      "source": [
        "pipe = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVR()\n",
        ")\n",
        "\n",
        "param_grid_svr = {\n",
        "    'svr__C' : [0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_svr = GridSearchCV(pipe, param_grid_svr, cv=5)\n",
        "grid_svr.fit(X_train, y_train)\n",
        "\n",
        "print(\"테스트 세트 점수 : \", grid_svr.score(X_test, y_test))\n",
        "print(\"최적 매개변수 \", grid_svr.best_params_)\n",
        "print(\"최적 교차 검증 점수 \", grid_svr.best_score_)\n",
        "print(\"최적 성능 모델 \", grid_svr.best_estimator_)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 세트 점수 :  0.7769356947417684\n",
            "최적 매개변수  {'svr__C': 10}\n",
            "최적 교차 검증 점수  0.7659451391130441\n",
            "최적 성능 모델  Pipeline(memory=None,\n",
            "         steps=[('standardscaler',\n",
            "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
            "                ('svr',\n",
            "                 SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
            "                     gamma='scale', kernel='rbf', max_iter=-1, shrinking=True,\n",
            "                     tol=0.001, verbose=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Sy09tWCZIx",
        "outputId": "a18ac2af-0e8b-4287-8069-c788bde1c876"
      },
      "source": [
        "svr_grid = SVR(C=10).fit(X_train_sscaled, y_train)\n",
        "\n",
        "print(svr_grid.score(X_test_sscaled, y_test))\n",
        "print(mean_squared_error(y_test, svr_grid.predict(X_test_sscaled)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7769356947417684\n",
            "45.32741653033721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L22D5F2APsn",
        "outputId": "c5ef0a78-ad8d-4222-9d0f-11dd974d4370"
      },
      "source": [
        "mlp = MLPRegressor(random_state=0).fit(X_train_sscaled, y_train)\n",
        "print(mlp.score(X_test_sscaled, y_test))\n",
        "print(mean_squared_error(y_test, mlp.predict(X_test_sscaled)))\n",
        "print(mean_absolute_error(y_test, mlp.predict(X_test_sscaled)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9397729587288763\n",
            "12.238337204716373\n",
            "0.8471237988521523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RexpdvZBEV8",
        "outputId": "2aa6352f-7182-4eec-dd34-3dcf88c615fd"
      },
      "source": [
        "mlp = MLPRegressor(random_state=0).fit(X_train_mscaled, y_train)\n",
        "print(mlp.score(X_test_mscaled, y_test))\n",
        "print(mean_squared_error(y_test, mlp.predict(X_test_mscaled)))\n",
        "print(mean_absolute_error(y_test, mlp.predict(X_test_mscaled)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9362201832258275\n",
            "12.96027312753944\n",
            "0.8367553632013109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5atufmlBa5m",
        "outputId": "c230a006-03ee-4d88-a532-9c7e229a0ca9"
      },
      "source": [
        "mlp = MLPRegressor(random_state=0, hidden_layer_sizes=(10,10)).fit(X_train_sscaled, y_train)\n",
        "print(mlp.score(X_test_sscaled, y_test))\n",
        "print(mean_squared_error(y_test, mlp.predict(X_test_sscaled)))\n",
        "print(mean_absolute_error(y_test, mlp.predict(X_test_sscaled)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9546039073150856\n",
            "9.224638606328412\n",
            "0.8488582661380603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuEar6ZzCfuq",
        "outputId": "ddca8d28-984e-4517-84a6-61084f2f4846"
      },
      "source": [
        "mlp = MLPRegressor(random_state=0, hidden_layer_sizes=(100,10,10)).fit(X_train_sscaled, y_train)\n",
        "print(mlp.score(X_test_sscaled, y_test))\n",
        "print(mean_squared_error(y_test, mlp.predict(X_test_sscaled)))\n",
        "print(mean_absolute_error(y_test, mlp.predict(X_test_sscaled)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9271640118474027\n",
            "14.800517588726333\n",
            "1.0073818525863938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvBtnH6ECgyn",
        "outputId": "2eb1108c-3da9-450e-e549-e2403a5e4a14"
      },
      "source": [
        "mlp = MLPRegressor(random_state=0, hidden_layer_sizes=(100,10,10,10)).fit(X_train_sscaled, y_train)\n",
        "print(mlp.score(X_test_sscaled, y_test))\n",
        "print(mean_squared_error(y_test, mlp.predict(X_test_sscaled)))\n",
        "print(mean_absolute_error(y_test, mlp.predict(X_test_sscaled)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9459347330408824\n",
            "10.986243955270243\n",
            "0.7659587908855688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGs3jzcyChBD",
        "outputId": "dab701b0-c340-4ba9-95e0-f7cb25591961"
      },
      "source": [
        "mlp = MLPRegressor(random_state=0, hidden_layer_sizes=(100,100,10,10,10)).fit(X_train_sscaled, y_train)\n",
        "print(mlp.score(X_test_sscaled, y_test))\n",
        "print(mean_squared_error(y_test, mlp.predict(X_test_sscaled)))\n",
        "print(mean_absolute_error(y_test, mlp.predict(X_test_sscaled)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9218285087445823\n",
            "15.88470975143244\n",
            "0.7514697514842957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV810bMYChJ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU5utqUVCmsj"
      },
      "source": [
        "# 학습 / 검증 데이터로 분할 후 스케일링\n",
        "\n",
        "X_traind, X_testd, y_traind, y_testd = train_test_split(X_res, y_res, random_state=0)\n",
        "\n",
        "X_traind, X_valid, y_traind, y_valid = train_test_split(X_traind, y_traind, random_state=0)\n",
        "std = StandardScaler()\n",
        "X_train_scaled = std.fit_transform(X_traind)\n",
        "X_valid_scaled = std.transform(X_valid)\n",
        "X_test_scaled = std.transform(X_testd)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcfUEjWbtFw8",
        "outputId": "7fc790d1-cfcd-40b3-fa8a-33d4c5784be6"
      },
      "source": [
        "print(X_train_scaled.shape)\n",
        "print(X_valid_scaled.shape)\n",
        "print(X_test_scaled.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28125, 29)\n",
            "(9375, 29)\n",
            "(12500, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD46WmEH2pa7"
      },
      "source": [
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tensorflow.random.set_seed(seed)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8MwYXn2Cmvr",
        "outputId": "61f2361a-b046-42d0-9e8f-c67e6d116250"
      },
      "source": [
        "# 자동 종료를 위해 추가\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_mse', patience=100)\n",
        "\n",
        "model = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "history = model.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "57/57 [==============================] - 1s 6ms/step - loss: 266.2503 - mae: 7.7160 - mse: 266.2503 - val_loss: 202.1752 - val_mae: 6.4510 - val_mse: 202.1752\n",
            "Epoch 2/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 282.5701 - mae: 6.1036 - mse: 282.5701 - val_loss: 162.1038 - val_mae: 4.7303 - val_mse: 162.1038\n",
            "Epoch 3/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 240.6987 - mae: 4.5642 - mse: 240.6987 - val_loss: 131.0324 - val_mae: 3.4470 - val_mse: 131.0324\n",
            "Epoch 4/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 144.2010 - mae: 3.4667 - mse: 144.2010 - val_loss: 111.6342 - val_mae: 3.0641 - val_mse: 111.6342\n",
            "Epoch 5/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 187.4604 - mae: 3.2735 - mse: 187.4604 - val_loss: 98.8579 - val_mae: 3.0181 - val_mse: 98.8579\n",
            "Epoch 6/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 149.3776 - mae: 3.1336 - mse: 149.3776 - val_loss: 89.3344 - val_mae: 3.0042 - val_mse: 89.3344\n",
            "Epoch 7/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 105.0720 - mae: 3.0720 - mse: 105.0720 - val_loss: 80.7464 - val_mae: 2.8734 - val_mse: 80.7464\n",
            "Epoch 8/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 101.3155 - mae: 2.9289 - mse: 101.3155 - val_loss: 72.5127 - val_mae: 2.7713 - val_mse: 72.5127\n",
            "Epoch 9/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 93.1340 - mae: 2.7383 - mse: 93.1340 - val_loss: 65.6232 - val_mae: 2.6180 - val_mse: 65.6232\n",
            "Epoch 10/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 92.3920 - mae: 2.6500 - mse: 92.3920 - val_loss: 59.6892 - val_mae: 2.6191 - val_mse: 59.6892\n",
            "Epoch 11/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 66.5737 - mae: 2.5993 - mse: 66.5737 - val_loss: 55.3628 - val_mae: 2.6624 - val_mse: 55.3628\n",
            "Epoch 12/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 62.9195 - mae: 2.6457 - mse: 62.9195 - val_loss: 51.7624 - val_mae: 2.7409 - val_mse: 51.7624\n",
            "Epoch 13/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 68.5934 - mae: 2.7187 - mse: 68.5934 - val_loss: 49.4198 - val_mae: 2.7389 - val_mse: 49.4198\n",
            "Epoch 14/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 112.0240 - mae: 2.9062 - mse: 112.0240 - val_loss: 47.4466 - val_mae: 2.7707 - val_mse: 47.4466\n",
            "Epoch 15/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 80.4463 - mae: 2.8161 - mse: 80.4463 - val_loss: 46.1865 - val_mae: 2.7950 - val_mse: 46.1865\n",
            "Epoch 16/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 60.3499 - mae: 2.7841 - mse: 60.3499 - val_loss: 44.3560 - val_mae: 2.8135 - val_mse: 44.3560\n",
            "Epoch 17/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 82.0879 - mae: 2.8790 - mse: 82.0879 - val_loss: 43.0761 - val_mae: 2.7335 - val_mse: 43.0761\n",
            "Epoch 18/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 47.3421 - mae: 2.7197 - mse: 47.3421 - val_loss: 41.8738 - val_mae: 2.7028 - val_mse: 41.8738\n",
            "Epoch 19/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 120.1063 - mae: 2.7760 - mse: 120.1063 - val_loss: 40.7080 - val_mae: 2.7324 - val_mse: 40.7080\n",
            "Epoch 20/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 58.0055 - mae: 2.7370 - mse: 58.0055 - val_loss: 39.8520 - val_mae: 2.6383 - val_mse: 39.8520\n",
            "Epoch 21/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 90.6877 - mae: 2.6966 - mse: 90.6877 - val_loss: 38.6751 - val_mae: 2.5960 - val_mse: 38.6751\n",
            "Epoch 22/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 42.8027 - mae: 2.5845 - mse: 42.8027 - val_loss: 37.8639 - val_mae: 2.5300 - val_mse: 37.8639\n",
            "Epoch 23/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 44.1583 - mae: 2.4713 - mse: 44.1583 - val_loss: 36.5990 - val_mae: 2.5246 - val_mse: 36.5990\n",
            "Epoch 24/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 49.8559 - mae: 2.5017 - mse: 49.8559 - val_loss: 36.0255 - val_mae: 2.4969 - val_mse: 36.0255\n",
            "Epoch 25/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 104.7736 - mae: 2.5819 - mse: 104.7736 - val_loss: 35.1172 - val_mae: 2.4467 - val_mse: 35.1172\n",
            "Epoch 26/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 97.5328 - mae: 2.4724 - mse: 97.5328 - val_loss: 34.2860 - val_mae: 2.3937 - val_mse: 34.2860\n",
            "Epoch 27/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 106.1939 - mae: 2.4484 - mse: 106.1939 - val_loss: 33.3702 - val_mae: 2.3367 - val_mse: 33.3702\n",
            "Epoch 28/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 43.9403 - mae: 2.2709 - mse: 43.9403 - val_loss: 32.6159 - val_mae: 2.3001 - val_mse: 32.6159\n",
            "Epoch 29/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 35.3693 - mae: 2.2303 - mse: 35.3693 - val_loss: 31.7960 - val_mae: 2.2578 - val_mse: 31.7960\n",
            "Epoch 30/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 58.5242 - mae: 2.2866 - mse: 58.5242 - val_loss: 30.9975 - val_mae: 2.1891 - val_mse: 30.9975\n",
            "Epoch 31/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 42.0894 - mae: 2.1642 - mse: 42.0894 - val_loss: 30.2915 - val_mae: 2.1365 - val_mse: 30.2915\n",
            "Epoch 32/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 67.5067 - mae: 2.1848 - mse: 67.5067 - val_loss: 29.5232 - val_mae: 2.0702 - val_mse: 29.5232\n",
            "Epoch 33/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 46.2904 - mae: 2.0903 - mse: 46.2904 - val_loss: 28.8650 - val_mae: 2.0157 - val_mse: 28.8650\n",
            "Epoch 34/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 33.9584 - mae: 1.9438 - mse: 33.9584 - val_loss: 28.0896 - val_mae: 1.9636 - val_mse: 28.0896\n",
            "Epoch 35/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 32.6411 - mae: 1.9110 - mse: 32.6411 - val_loss: 27.2890 - val_mae: 1.9062 - val_mse: 27.2890\n",
            "Epoch 36/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 38.1803 - mae: 1.8752 - mse: 38.1803 - val_loss: 27.1536 - val_mae: 1.8667 - val_mse: 27.1536\n",
            "Epoch 37/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 54.1313 - mae: 1.9441 - mse: 54.1313 - val_loss: 26.0514 - val_mae: 1.8216 - val_mse: 26.0514\n",
            "Epoch 38/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 97.4981 - mae: 1.9207 - mse: 97.4981 - val_loss: 25.4676 - val_mae: 1.7638 - val_mse: 25.4676\n",
            "Epoch 39/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 28.1465 - mae: 1.7190 - mse: 28.1465 - val_loss: 25.0700 - val_mae: 1.7122 - val_mse: 25.0700\n",
            "Epoch 40/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 42.3543 - mae: 1.7169 - mse: 42.3543 - val_loss: 24.5008 - val_mae: 1.6850 - val_mse: 24.5008\n",
            "Epoch 41/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 96.8285 - mae: 1.7799 - mse: 96.8285 - val_loss: 23.8665 - val_mae: 1.6575 - val_mse: 23.8665\n",
            "Epoch 42/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 76.2807 - mae: 1.7095 - mse: 76.2807 - val_loss: 23.2990 - val_mae: 1.6228 - val_mse: 23.2990\n",
            "Epoch 43/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 33.9085 - mae: 1.6417 - mse: 33.9085 - val_loss: 22.6539 - val_mae: 1.5833 - val_mse: 22.6539\n",
            "Epoch 44/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.9001 - mae: 1.5866 - mse: 29.9001 - val_loss: 22.4804 - val_mae: 1.5772 - val_mse: 22.4804\n",
            "Epoch 45/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34.1936 - mae: 1.6159 - mse: 34.1936 - val_loss: 21.9459 - val_mae: 1.5335 - val_mse: 21.9459\n",
            "Epoch 46/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 39.7995 - mae: 1.5277 - mse: 39.7995 - val_loss: 21.3820 - val_mae: 1.5244 - val_mse: 21.3820\n",
            "Epoch 47/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 62.3269 - mae: 1.5836 - mse: 62.3269 - val_loss: 21.2760 - val_mae: 1.5017 - val_mse: 21.2760\n",
            "Epoch 48/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 33.4259 - mae: 1.4937 - mse: 33.4259 - val_loss: 20.8029 - val_mae: 1.4774 - val_mse: 20.8029\n",
            "Epoch 49/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 62.2105 - mae: 1.5646 - mse: 62.2105 - val_loss: 20.5165 - val_mae: 1.4695 - val_mse: 20.5165\n",
            "Epoch 50/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24.5914 - mae: 1.4755 - mse: 24.5914 - val_loss: 20.3116 - val_mae: 1.4264 - val_mse: 20.3116\n",
            "Epoch 51/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 37.2770 - mae: 1.5717 - mse: 37.2770 - val_loss: 20.2963 - val_mae: 1.4918 - val_mse: 20.2963\n",
            "Epoch 52/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.6626 - mae: 1.4845 - mse: 21.6626 - val_loss: 19.4428 - val_mae: 1.4359 - val_mse: 19.4428\n",
            "Epoch 53/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 39.7212 - mae: 1.4834 - mse: 39.7212 - val_loss: 19.2390 - val_mae: 1.4396 - val_mse: 19.2390\n",
            "Epoch 54/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 41.9600 - mae: 1.4668 - mse: 41.9600 - val_loss: 19.0994 - val_mae: 1.4222 - val_mse: 19.0994\n",
            "Epoch 55/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.0887 - mae: 1.4366 - mse: 26.0887 - val_loss: 18.5080 - val_mae: 1.3863 - val_mse: 18.5080\n",
            "Epoch 56/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 39.2736 - mae: 1.4293 - mse: 39.2736 - val_loss: 18.3837 - val_mae: 1.3880 - val_mse: 18.3837\n",
            "Epoch 57/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.1919 - mae: 1.4002 - mse: 29.1919 - val_loss: 18.1797 - val_mae: 1.3828 - val_mse: 18.1797\n",
            "Epoch 58/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.9399 - mae: 1.3902 - mse: 25.9399 - val_loss: 17.8421 - val_mae: 1.3723 - val_mse: 17.8421\n",
            "Epoch 59/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.0824 - mae: 1.3961 - mse: 20.0824 - val_loss: 17.7179 - val_mae: 1.3670 - val_mse: 17.7179\n",
            "Epoch 60/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 68.1467 - mae: 1.4026 - mse: 68.1467 - val_loss: 17.5445 - val_mae: 1.3598 - val_mse: 17.5445\n",
            "Epoch 61/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 46.6785 - mae: 1.4203 - mse: 46.6785 - val_loss: 17.4544 - val_mae: 1.3620 - val_mse: 17.4544\n",
            "Epoch 62/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 43.0395 - mae: 1.4328 - mse: 43.0395 - val_loss: 17.4047 - val_mae: 1.3600 - val_mse: 17.4047\n",
            "Epoch 63/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 85.3186 - mae: 1.4385 - mse: 85.3186 - val_loss: 16.7669 - val_mae: 1.3424 - val_mse: 16.7669\n",
            "Epoch 64/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 45.6897 - mae: 1.3676 - mse: 45.6897 - val_loss: 16.5264 - val_mae: 1.3300 - val_mse: 16.5264\n",
            "Epoch 65/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.3158 - mae: 1.3212 - mse: 19.3158 - val_loss: 16.4420 - val_mae: 1.3172 - val_mse: 16.4420\n",
            "Epoch 66/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.9349 - mae: 1.3731 - mse: 29.9349 - val_loss: 16.3888 - val_mae: 1.3162 - val_mse: 16.3888\n",
            "Epoch 67/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 40.8011 - mae: 1.4031 - mse: 40.8011 - val_loss: 16.2038 - val_mae: 1.3254 - val_mse: 16.2038\n",
            "Epoch 68/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 55.8530 - mae: 1.3668 - mse: 55.8530 - val_loss: 16.2702 - val_mae: 1.2993 - val_mse: 16.2702\n",
            "Epoch 69/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34.5177 - mae: 1.3511 - mse: 34.5177 - val_loss: 15.4674 - val_mae: 1.2925 - val_mse: 15.4674\n",
            "Epoch 70/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.8956 - mae: 1.3016 - mse: 19.8956 - val_loss: 15.3227 - val_mae: 1.2881 - val_mse: 15.3227\n",
            "Epoch 71/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 30.3091 - mae: 1.3253 - mse: 30.3091 - val_loss: 15.3813 - val_mae: 1.3047 - val_mse: 15.3813\n",
            "Epoch 72/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 43.5413 - mae: 1.3836 - mse: 43.5413 - val_loss: 15.2083 - val_mae: 1.2910 - val_mse: 15.2083\n",
            "Epoch 73/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.2365 - mae: 1.2778 - mse: 23.2365 - val_loss: 15.1630 - val_mae: 1.2646 - val_mse: 15.1630\n",
            "Epoch 74/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.1149 - mae: 1.2471 - mse: 14.1149 - val_loss: 14.8136 - val_mae: 1.2416 - val_mse: 14.8136\n",
            "Epoch 75/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 49.8473 - mae: 1.3055 - mse: 49.8473 - val_loss: 14.8735 - val_mae: 1.2777 - val_mse: 14.8735\n",
            "Epoch 76/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34.0588 - mae: 1.3255 - mse: 34.0588 - val_loss: 14.4086 - val_mae: 1.2636 - val_mse: 14.4086\n",
            "Epoch 77/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.6555 - mae: 1.2591 - mse: 23.6555 - val_loss: 14.2896 - val_mae: 1.2572 - val_mse: 14.2896\n",
            "Epoch 78/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.9496 - mae: 1.2465 - mse: 17.9496 - val_loss: 14.4582 - val_mae: 1.2511 - val_mse: 14.4582\n",
            "Epoch 79/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.3953 - mae: 1.2854 - mse: 20.3953 - val_loss: 13.9531 - val_mae: 1.2444 - val_mse: 13.9531\n",
            "Epoch 80/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 71.9580 - mae: 1.3697 - mse: 71.9580 - val_loss: 13.9979 - val_mae: 1.2413 - val_mse: 13.9979\n",
            "Epoch 81/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.3626 - mae: 1.2467 - mse: 21.3626 - val_loss: 13.5892 - val_mae: 1.2278 - val_mse: 13.5892\n",
            "Epoch 82/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 43.0156 - mae: 1.2752 - mse: 43.0156 - val_loss: 13.6167 - val_mae: 1.2463 - val_mse: 13.6167\n",
            "Epoch 83/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.4047 - mae: 1.2514 - mse: 23.4047 - val_loss: 13.8968 - val_mae: 1.2250 - val_mse: 13.8968\n",
            "Epoch 84/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 35.2079 - mae: 1.2414 - mse: 35.2079 - val_loss: 13.5199 - val_mae: 1.2287 - val_mse: 13.5199\n",
            "Epoch 85/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22.9210 - mae: 1.2550 - mse: 22.9210 - val_loss: 13.6207 - val_mae: 1.2219 - val_mse: 13.6207\n",
            "Epoch 86/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 33.2036 - mae: 1.2687 - mse: 33.2036 - val_loss: 13.2909 - val_mae: 1.2151 - val_mse: 13.2909\n",
            "Epoch 87/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.4067 - mae: 1.1912 - mse: 14.4067 - val_loss: 13.0968 - val_mae: 1.2378 - val_mse: 13.0968\n",
            "Epoch 88/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 42.7404 - mae: 1.2975 - mse: 42.7404 - val_loss: 12.9584 - val_mae: 1.2116 - val_mse: 12.9584\n",
            "Epoch 89/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.0637 - mae: 1.2364 - mse: 19.0637 - val_loss: 12.7345 - val_mae: 1.2061 - val_mse: 12.7345\n",
            "Epoch 90/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 31.4070 - mae: 1.2245 - mse: 31.4070 - val_loss: 12.6809 - val_mae: 1.2099 - val_mse: 12.6809\n",
            "Epoch 91/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 43.7809 - mae: 1.2493 - mse: 43.7809 - val_loss: 12.7029 - val_mae: 1.2143 - val_mse: 12.7029\n",
            "Epoch 92/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 41.5810 - mae: 1.2640 - mse: 41.5810 - val_loss: 12.4308 - val_mae: 1.1968 - val_mse: 12.4308\n",
            "Epoch 93/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.8297 - mae: 1.2058 - mse: 23.8297 - val_loss: 12.3897 - val_mae: 1.1885 - val_mse: 12.3897\n",
            "Epoch 94/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.0145 - mae: 1.1986 - mse: 29.0145 - val_loss: 12.2252 - val_mae: 1.1939 - val_mse: 12.2252\n",
            "Epoch 95/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.6039 - mae: 1.1885 - mse: 25.6039 - val_loss: 12.2866 - val_mae: 1.1889 - val_mse: 12.2866\n",
            "Epoch 96/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.0560 - mae: 1.1826 - mse: 25.0560 - val_loss: 11.9415 - val_mae: 1.1922 - val_mse: 11.9415\n",
            "Epoch 97/3000\n",
            "57/57 [==============================] - 1s 9ms/step - loss: 27.4106 - mae: 1.1991 - mse: 27.4106 - val_loss: 12.1113 - val_mae: 1.1820 - val_mse: 12.1113\n",
            "Epoch 98/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 30.3914 - mae: 1.2036 - mse: 30.3914 - val_loss: 11.9860 - val_mae: 1.1828 - val_mse: 11.9860\n",
            "Epoch 99/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.3870 - mae: 1.1770 - mse: 14.3870 - val_loss: 11.5725 - val_mae: 1.1718 - val_mse: 11.5725\n",
            "Epoch 100/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.7207 - mae: 1.1306 - mse: 11.7207 - val_loss: 11.8999 - val_mae: 1.1724 - val_mse: 11.8999\n",
            "Epoch 101/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.9241 - mae: 1.1607 - mse: 17.9241 - val_loss: 11.4033 - val_mae: 1.1927 - val_mse: 11.4033\n",
            "Epoch 102/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.9405 - mae: 1.1526 - mse: 16.9405 - val_loss: 11.7440 - val_mae: 1.1736 - val_mse: 11.7440\n",
            "Epoch 103/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.0815 - mae: 1.1826 - mse: 23.0815 - val_loss: 11.3741 - val_mae: 1.1668 - val_mse: 11.3741\n",
            "Epoch 104/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.9730 - mae: 1.1664 - mse: 25.9730 - val_loss: 11.4498 - val_mae: 1.1639 - val_mse: 11.4498\n",
            "Epoch 105/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 47.8836 - mae: 1.1897 - mse: 47.8836 - val_loss: 11.4187 - val_mae: 1.1671 - val_mse: 11.4187\n",
            "Epoch 106/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.6788 - mae: 1.1224 - mse: 14.6788 - val_loss: 11.3823 - val_mae: 1.1559 - val_mse: 11.3823\n",
            "Epoch 107/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.6205 - mae: 1.1221 - mse: 16.6205 - val_loss: 11.3910 - val_mae: 1.1679 - val_mse: 11.3910\n",
            "Epoch 108/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.2709 - mae: 1.1490 - mse: 17.2709 - val_loss: 11.1882 - val_mae: 1.1579 - val_mse: 11.1882\n",
            "Epoch 109/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 35.6555 - mae: 1.1653 - mse: 35.6555 - val_loss: 11.1464 - val_mae: 1.1572 - val_mse: 11.1464\n",
            "Epoch 110/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.1684 - mae: 1.1599 - mse: 17.1684 - val_loss: 10.7313 - val_mae: 1.1454 - val_mse: 10.7313\n",
            "Epoch 111/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 32.1099 - mae: 1.1608 - mse: 32.1099 - val_loss: 11.0285 - val_mae: 1.1505 - val_mse: 11.0285\n",
            "Epoch 112/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.2340 - mae: 1.1229 - mse: 12.2340 - val_loss: 10.7122 - val_mae: 1.1337 - val_mse: 10.7122\n",
            "Epoch 113/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 28.0637 - mae: 1.1759 - mse: 28.0637 - val_loss: 10.8069 - val_mae: 1.1504 - val_mse: 10.8069\n",
            "Epoch 114/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 66.6015 - mae: 1.2075 - mse: 66.6015 - val_loss: 10.4867 - val_mae: 1.1290 - val_mse: 10.4867\n",
            "Epoch 115/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22.0650 - mae: 1.1255 - mse: 22.0650 - val_loss: 10.5339 - val_mae: 1.1337 - val_mse: 10.5339\n",
            "Epoch 116/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.1414 - mae: 1.1389 - mse: 19.1414 - val_loss: 10.4660 - val_mae: 1.1268 - val_mse: 10.4660\n",
            "Epoch 117/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34.6757 - mae: 1.1432 - mse: 34.6757 - val_loss: 10.4371 - val_mae: 1.1190 - val_mse: 10.4371\n",
            "Epoch 118/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 38.4526 - mae: 1.1418 - mse: 38.4526 - val_loss: 10.0758 - val_mae: 1.1355 - val_mse: 10.0758\n",
            "Epoch 119/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9094 - mae: 1.1127 - mse: 12.9094 - val_loss: 10.0326 - val_mae: 1.1060 - val_mse: 10.0326\n",
            "Epoch 120/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.2858 - mae: 1.0884 - mse: 20.2858 - val_loss: 10.1855 - val_mae: 1.1231 - val_mse: 10.1855\n",
            "Epoch 121/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.6167 - mae: 1.0880 - mse: 14.6167 - val_loss: 9.9722 - val_mae: 1.1252 - val_mse: 9.9722\n",
            "Epoch 122/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.1013 - mae: 1.1321 - mse: 25.1013 - val_loss: 10.3169 - val_mae: 1.1215 - val_mse: 10.3169\n",
            "Epoch 123/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.2139 - mae: 1.1230 - mse: 25.2139 - val_loss: 9.6004 - val_mae: 1.1103 - val_mse: 9.6004\n",
            "Epoch 124/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 79.5961 - mae: 1.1893 - mse: 79.5961 - val_loss: 9.7903 - val_mae: 1.1016 - val_mse: 9.7903\n",
            "Epoch 125/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.6424 - mae: 1.0731 - mse: 21.6424 - val_loss: 9.8559 - val_mae: 1.1046 - val_mse: 9.8559\n",
            "Epoch 126/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.5995 - mae: 1.1248 - mse: 18.5995 - val_loss: 9.6950 - val_mae: 1.1289 - val_mse: 9.6950\n",
            "Epoch 127/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.5599 - mae: 1.0696 - mse: 11.5599 - val_loss: 9.8865 - val_mae: 1.0940 - val_mse: 9.8865\n",
            "Epoch 128/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.3951 - mae: 1.1108 - mse: 29.3951 - val_loss: 9.8887 - val_mae: 1.1052 - val_mse: 9.8887\n",
            "Epoch 129/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.9856 - mae: 1.0827 - mse: 29.9856 - val_loss: 9.4844 - val_mae: 1.0917 - val_mse: 9.4844\n",
            "Epoch 130/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.0161 - mae: 1.1102 - mse: 17.0161 - val_loss: 9.3392 - val_mae: 1.0968 - val_mse: 9.3392\n",
            "Epoch 131/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.0452 - mae: 1.0855 - mse: 19.0452 - val_loss: 9.4424 - val_mae: 1.1023 - val_mse: 9.4424\n",
            "Epoch 132/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 61.5924 - mae: 1.1384 - mse: 61.5924 - val_loss: 9.2742 - val_mae: 1.0909 - val_mse: 9.2742\n",
            "Epoch 133/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 27.4136 - mae: 1.0721 - mse: 27.4136 - val_loss: 9.2709 - val_mae: 1.0976 - val_mse: 9.2709\n",
            "Epoch 134/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.9215 - mae: 1.0644 - mse: 10.9215 - val_loss: 8.9498 - val_mae: 1.0802 - val_mse: 8.9498\n",
            "Epoch 135/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.5925 - mae: 1.0446 - mse: 11.5925 - val_loss: 9.3092 - val_mae: 1.0815 - val_mse: 9.3092\n",
            "Epoch 136/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 27.4548 - mae: 1.0946 - mse: 27.4548 - val_loss: 9.1783 - val_mae: 1.0938 - val_mse: 9.1783\n",
            "Epoch 137/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.0480 - mae: 1.0694 - mse: 13.0480 - val_loss: 9.0744 - val_mae: 1.0844 - val_mse: 9.0744\n",
            "Epoch 138/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.3871 - mae: 1.0801 - mse: 20.3871 - val_loss: 9.0462 - val_mae: 1.0896 - val_mse: 9.0462\n",
            "Epoch 139/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.9508 - mae: 1.0380 - mse: 15.9508 - val_loss: 8.9980 - val_mae: 1.0782 - val_mse: 8.9980\n",
            "Epoch 140/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 28.8909 - mae: 1.0991 - mse: 28.8909 - val_loss: 8.8382 - val_mae: 1.0813 - val_mse: 8.8382\n",
            "Epoch 141/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 30.8769 - mae: 1.1056 - mse: 30.8769 - val_loss: 8.8611 - val_mae: 1.0792 - val_mse: 8.8611\n",
            "Epoch 142/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.7882 - mae: 1.0556 - mse: 10.7882 - val_loss: 8.8208 - val_mae: 1.0654 - val_mse: 8.8208\n",
            "Epoch 143/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 30.5141 - mae: 1.0777 - mse: 30.5141 - val_loss: 9.0561 - val_mae: 1.0947 - val_mse: 9.0561\n",
            "Epoch 144/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.6705 - mae: 1.0824 - mse: 23.6705 - val_loss: 8.8106 - val_mae: 1.0793 - val_mse: 8.8106\n",
            "Epoch 145/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.0031 - mae: 1.0598 - mse: 13.0031 - val_loss: 8.8210 - val_mae: 1.0825 - val_mse: 8.8210\n",
            "Epoch 146/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.3904 - mae: 1.0448 - mse: 9.3904 - val_loss: 8.7414 - val_mae: 1.0669 - val_mse: 8.7414\n",
            "Epoch 147/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 32.2595 - mae: 1.0730 - mse: 32.2595 - val_loss: 8.8041 - val_mae: 1.0790 - val_mse: 8.8041\n",
            "Epoch 148/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.4111 - mae: 1.0571 - mse: 14.4111 - val_loss: 8.9156 - val_mae: 1.0776 - val_mse: 8.9156\n",
            "Epoch 149/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.5510 - mae: 1.0468 - mse: 16.5510 - val_loss: 8.6861 - val_mae: 1.0768 - val_mse: 8.6861\n",
            "Epoch 150/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 28.7923 - mae: 1.0933 - mse: 28.7923 - val_loss: 8.5132 - val_mae: 1.0806 - val_mse: 8.5132\n",
            "Epoch 151/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.6254 - mae: 1.0599 - mse: 22.6254 - val_loss: 8.5984 - val_mae: 1.0714 - val_mse: 8.5984\n",
            "Epoch 152/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.8508 - mae: 1.0711 - mse: 25.8508 - val_loss: 8.5543 - val_mae: 1.0759 - val_mse: 8.5543\n",
            "Epoch 153/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.5847 - mae: 1.0851 - mse: 18.5847 - val_loss: 8.5769 - val_mae: 1.0709 - val_mse: 8.5769\n",
            "Epoch 154/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.3807 - mae: 1.0273 - mse: 15.3807 - val_loss: 8.5986 - val_mae: 1.0756 - val_mse: 8.5986\n",
            "Epoch 155/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 27.9324 - mae: 1.0720 - mse: 27.9324 - val_loss: 8.4923 - val_mae: 1.0652 - val_mse: 8.4923\n",
            "Epoch 156/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.9392 - mae: 1.0370 - mse: 11.9392 - val_loss: 8.1163 - val_mae: 1.0719 - val_mse: 8.1163\n",
            "Epoch 157/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15.0695 - mae: 1.0799 - mse: 15.0695 - val_loss: 8.4579 - val_mae: 1.0713 - val_mse: 8.4579\n",
            "Epoch 158/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.2453 - mae: 1.0674 - mse: 16.2453 - val_loss: 8.4870 - val_mae: 1.0662 - val_mse: 8.4870\n",
            "Epoch 159/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.8862 - mae: 1.0418 - mse: 10.8862 - val_loss: 8.3723 - val_mae: 1.0740 - val_mse: 8.3723\n",
            "Epoch 160/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24.7340 - mae: 1.0692 - mse: 24.7340 - val_loss: 8.3518 - val_mae: 1.0736 - val_mse: 8.3518\n",
            "Epoch 161/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.8115 - mae: 1.0267 - mse: 21.8115 - val_loss: 8.4263 - val_mae: 1.0722 - val_mse: 8.4263\n",
            "Epoch 162/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 37.7483 - mae: 1.0895 - mse: 37.7483 - val_loss: 8.1424 - val_mae: 1.0582 - val_mse: 8.1424\n",
            "Epoch 163/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 50.2934 - mae: 1.0779 - mse: 50.2934 - val_loss: 8.0608 - val_mae: 1.0717 - val_mse: 8.0608\n",
            "Epoch 164/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.6606 - mae: 1.0280 - mse: 8.6606 - val_loss: 7.8357 - val_mae: 1.0554 - val_mse: 7.8357\n",
            "Epoch 165/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 45.4707 - mae: 1.0846 - mse: 45.4707 - val_loss: 8.1187 - val_mae: 1.0666 - val_mse: 8.1187\n",
            "Epoch 166/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.6150 - mae: 1.0307 - mse: 13.6150 - val_loss: 8.1977 - val_mae: 1.0640 - val_mse: 8.1977\n",
            "Epoch 167/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.2239 - mae: 1.0620 - mse: 14.2239 - val_loss: 8.1722 - val_mae: 1.0667 - val_mse: 8.1722\n",
            "Epoch 168/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.9216 - mae: 1.0280 - mse: 9.9216 - val_loss: 8.0109 - val_mae: 1.0604 - val_mse: 8.0109\n",
            "Epoch 169/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.4280 - mae: 1.0311 - mse: 16.4280 - val_loss: 8.3523 - val_mae: 1.0812 - val_mse: 8.3523\n",
            "Epoch 170/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.6069 - mae: 1.0265 - mse: 11.6069 - val_loss: 8.1073 - val_mae: 1.0605 - val_mse: 8.1073\n",
            "Epoch 171/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.3967 - mae: 1.0095 - mse: 7.3967 - val_loss: 7.8109 - val_mae: 1.0608 - val_mse: 7.8109\n",
            "Epoch 172/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.1462 - mae: 1.0514 - mse: 20.1462 - val_loss: 8.1015 - val_mae: 1.0664 - val_mse: 8.1015\n",
            "Epoch 173/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34.8855 - mae: 1.0488 - mse: 34.8855 - val_loss: 7.9158 - val_mae: 1.0643 - val_mse: 7.9158\n",
            "Epoch 174/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.1262 - mae: 1.0467 - mse: 19.1262 - val_loss: 7.8830 - val_mae: 1.0572 - val_mse: 7.8830\n",
            "Epoch 175/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.8044 - mae: 1.0013 - mse: 9.8044 - val_loss: 8.1137 - val_mae: 1.0666 - val_mse: 8.1137\n",
            "Epoch 176/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.6220 - mae: 1.0000 - mse: 10.6220 - val_loss: 8.3214 - val_mae: 1.0685 - val_mse: 8.3214\n",
            "Epoch 177/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.8000 - mae: 1.0442 - mse: 9.8000 - val_loss: 8.1523 - val_mae: 1.0624 - val_mse: 8.1523\n",
            "Epoch 178/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.1705 - mae: 1.0587 - mse: 14.1705 - val_loss: 8.1853 - val_mae: 1.0733 - val_mse: 8.1853\n",
            "Epoch 179/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 31.1375 - mae: 1.0815 - mse: 31.1375 - val_loss: 7.9138 - val_mae: 1.0628 - val_mse: 7.9138\n",
            "Epoch 180/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.9676 - mae: 1.0492 - mse: 20.9676 - val_loss: 7.7849 - val_mae: 1.0607 - val_mse: 7.7849\n",
            "Epoch 181/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.5761 - mae: 1.0138 - mse: 9.5761 - val_loss: 7.9492 - val_mae: 1.0661 - val_mse: 7.9492\n",
            "Epoch 182/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.3025 - mae: 1.0322 - mse: 18.3025 - val_loss: 7.9837 - val_mae: 1.0775 - val_mse: 7.9837\n",
            "Epoch 183/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 42.2072 - mae: 1.0856 - mse: 42.2072 - val_loss: 7.6438 - val_mae: 1.0538 - val_mse: 7.6438\n",
            "Epoch 184/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.3871 - mae: 1.0353 - mse: 20.3871 - val_loss: 7.7547 - val_mae: 1.0579 - val_mse: 7.7547\n",
            "Epoch 185/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 30.9746 - mae: 1.0499 - mse: 30.9746 - val_loss: 7.6654 - val_mae: 1.0519 - val_mse: 7.6654\n",
            "Epoch 186/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.0584 - mae: 1.0105 - mse: 10.0584 - val_loss: 7.6508 - val_mae: 1.0594 - val_mse: 7.6508\n",
            "Epoch 187/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.5797 - mae: 1.0202 - mse: 12.5797 - val_loss: 7.7082 - val_mae: 1.0616 - val_mse: 7.7082\n",
            "Epoch 188/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1074 - mae: 1.0152 - mse: 10.1074 - val_loss: 7.7059 - val_mae: 1.0568 - val_mse: 7.7059\n",
            "Epoch 189/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.7777 - mae: 0.9917 - mse: 9.7777 - val_loss: 7.6237 - val_mae: 1.0568 - val_mse: 7.6237\n",
            "Epoch 190/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.4033 - mae: 1.0363 - mse: 25.4033 - val_loss: 7.5959 - val_mae: 1.0554 - val_mse: 7.5959\n",
            "Epoch 191/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.1543 - mae: 1.0362 - mse: 29.1543 - val_loss: 7.5499 - val_mae: 1.0489 - val_mse: 7.5499\n",
            "Epoch 192/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 65.9318 - mae: 1.1153 - mse: 65.9318 - val_loss: 7.5044 - val_mae: 1.0591 - val_mse: 7.5044\n",
            "Epoch 193/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.0874 - mae: 1.0175 - mse: 26.0874 - val_loss: 7.6381 - val_mae: 1.0564 - val_mse: 7.6381\n",
            "Epoch 194/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 18.0890 - mae: 1.0235 - mse: 18.0890 - val_loss: 7.7636 - val_mae: 1.0515 - val_mse: 7.7636\n",
            "Epoch 195/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1928 - mae: 1.0089 - mse: 10.1928 - val_loss: 7.7042 - val_mae: 1.0468 - val_mse: 7.7042\n",
            "Epoch 196/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.5285 - mae: 0.9907 - mse: 6.5285 - val_loss: 7.3905 - val_mae: 1.0461 - val_mse: 7.3905\n",
            "Epoch 197/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 34.3882 - mae: 1.0546 - mse: 34.3882 - val_loss: 7.5253 - val_mae: 1.0488 - val_mse: 7.5253\n",
            "Epoch 198/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.8201 - mae: 1.0249 - mse: 17.8201 - val_loss: 7.6863 - val_mae: 1.0514 - val_mse: 7.6863\n",
            "Epoch 199/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.2586 - mae: 1.0157 - mse: 13.2586 - val_loss: 7.8428 - val_mae: 1.0575 - val_mse: 7.8428\n",
            "Epoch 200/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 24.5314 - mae: 1.0216 - mse: 24.5314 - val_loss: 7.8282 - val_mae: 1.0564 - val_mse: 7.8282\n",
            "Epoch 201/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.4239 - mae: 1.0183 - mse: 17.4239 - val_loss: 7.4591 - val_mae: 1.0437 - val_mse: 7.4591\n",
            "Epoch 202/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22.2071 - mae: 1.0174 - mse: 22.2071 - val_loss: 7.8689 - val_mae: 1.0613 - val_mse: 7.8689\n",
            "Epoch 203/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.3225 - mae: 1.0109 - mse: 11.3225 - val_loss: 7.6315 - val_mae: 1.0503 - val_mse: 7.6315\n",
            "Epoch 204/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.7074 - mae: 0.9887 - mse: 10.7074 - val_loss: 7.6743 - val_mae: 1.0491 - val_mse: 7.6743\n",
            "Epoch 205/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.8678 - mae: 0.9912 - mse: 10.8678 - val_loss: 7.5342 - val_mae: 1.0387 - val_mse: 7.5342\n",
            "Epoch 206/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.3361 - mae: 0.9848 - mse: 8.3361 - val_loss: 7.5418 - val_mae: 1.0458 - val_mse: 7.5418\n",
            "Epoch 207/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 43.2280 - mae: 1.0423 - mse: 43.2280 - val_loss: 7.3889 - val_mae: 1.0448 - val_mse: 7.3889\n",
            "Epoch 208/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.0006 - mae: 1.0215 - mse: 18.0006 - val_loss: 7.7670 - val_mae: 1.0613 - val_mse: 7.7670\n",
            "Epoch 209/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.9717 - mae: 1.0159 - mse: 8.9717 - val_loss: 7.2699 - val_mae: 1.0377 - val_mse: 7.2699\n",
            "Epoch 210/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 32.0156 - mae: 1.0619 - mse: 32.0156 - val_loss: 7.3520 - val_mae: 1.0404 - val_mse: 7.3520\n",
            "Epoch 211/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.9030 - mae: 1.0139 - mse: 26.9030 - val_loss: 7.4233 - val_mae: 1.0438 - val_mse: 7.4233\n",
            "Epoch 212/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.6647 - mae: 1.0111 - mse: 17.6647 - val_loss: 7.4748 - val_mae: 1.0510 - val_mse: 7.4748\n",
            "Epoch 213/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.3262 - mae: 0.9878 - mse: 8.3262 - val_loss: 7.3705 - val_mae: 1.0384 - val_mse: 7.3705\n",
            "Epoch 214/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.7194 - mae: 1.0427 - mse: 23.7194 - val_loss: 7.6721 - val_mae: 1.0466 - val_mse: 7.6721\n",
            "Epoch 215/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 62.0629 - mae: 1.0959 - mse: 62.0629 - val_loss: 7.2403 - val_mae: 1.0474 - val_mse: 7.2403\n",
            "Epoch 216/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.1845 - mae: 1.0077 - mse: 20.1845 - val_loss: 7.4438 - val_mae: 1.0392 - val_mse: 7.4438\n",
            "Epoch 217/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.2018 - mae: 0.9963 - mse: 13.2018 - val_loss: 7.4181 - val_mae: 1.0468 - val_mse: 7.4181\n",
            "Epoch 218/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22.3854 - mae: 1.0366 - mse: 22.3854 - val_loss: 7.3417 - val_mae: 1.0519 - val_mse: 7.3417\n",
            "Epoch 219/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.8258 - mae: 1.0193 - mse: 17.8258 - val_loss: 7.4043 - val_mae: 1.0426 - val_mse: 7.4043\n",
            "Epoch 220/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.1576 - mae: 0.9812 - mse: 13.1576 - val_loss: 7.4665 - val_mae: 1.0494 - val_mse: 7.4665\n",
            "Epoch 221/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 26.1808 - mae: 1.0231 - mse: 26.1808 - val_loss: 7.2390 - val_mae: 1.0405 - val_mse: 7.2390\n",
            "Epoch 222/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.0081 - mae: 0.9814 - mse: 12.0081 - val_loss: 7.4114 - val_mae: 1.0421 - val_mse: 7.4114\n",
            "Epoch 223/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.7759 - mae: 1.0202 - mse: 19.7759 - val_loss: 7.3350 - val_mae: 1.0446 - val_mse: 7.3350\n",
            "Epoch 224/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.5918 - mae: 0.9798 - mse: 8.5918 - val_loss: 7.4715 - val_mae: 1.0441 - val_mse: 7.4715\n",
            "Epoch 225/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.3836 - mae: 0.9991 - mse: 17.3836 - val_loss: 7.5856 - val_mae: 1.0507 - val_mse: 7.5856\n",
            "Epoch 226/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.4856 - mae: 0.9756 - mse: 16.4856 - val_loss: 7.2599 - val_mae: 1.0406 - val_mse: 7.2599\n",
            "Epoch 227/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 30.4643 - mae: 1.0269 - mse: 30.4643 - val_loss: 7.2305 - val_mae: 1.0287 - val_mse: 7.2305\n",
            "Epoch 228/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.3355 - mae: 0.9978 - mse: 11.3355 - val_loss: 7.4327 - val_mae: 1.0448 - val_mse: 7.4327\n",
            "Epoch 229/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.8858 - mae: 0.9979 - mse: 7.8858 - val_loss: 7.3476 - val_mae: 1.0369 - val_mse: 7.3476\n",
            "Epoch 230/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 59.1754 - mae: 1.0702 - mse: 59.1754 - val_loss: 7.2029 - val_mae: 1.0353 - val_mse: 7.2029\n",
            "Epoch 231/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 27.0240 - mae: 1.0125 - mse: 27.0240 - val_loss: 7.1055 - val_mae: 1.0334 - val_mse: 7.1055\n",
            "Epoch 232/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.3444 - mae: 1.0053 - mse: 16.3444 - val_loss: 7.2316 - val_mae: 1.0357 - val_mse: 7.2316\n",
            "Epoch 233/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.0317 - mae: 0.9987 - mse: 9.0317 - val_loss: 7.1557 - val_mae: 1.0355 - val_mse: 7.1557\n",
            "Epoch 234/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.9521 - mae: 0.9628 - mse: 13.9521 - val_loss: 7.2894 - val_mae: 1.0403 - val_mse: 7.2894\n",
            "Epoch 235/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2851 - mae: 0.9685 - mse: 7.2851 - val_loss: 7.1053 - val_mae: 1.0341 - val_mse: 7.1053\n",
            "Epoch 236/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.2528 - mae: 0.9933 - mse: 16.2528 - val_loss: 7.3119 - val_mae: 1.0452 - val_mse: 7.3119\n",
            "Epoch 237/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.7131 - mae: 0.9618 - mse: 6.7131 - val_loss: 7.0820 - val_mae: 1.0344 - val_mse: 7.0820\n",
            "Epoch 238/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.2774 - mae: 1.0124 - mse: 13.2774 - val_loss: 7.5608 - val_mae: 1.0474 - val_mse: 7.5608\n",
            "Epoch 239/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 31.5882 - mae: 1.0319 - mse: 31.5882 - val_loss: 7.1143 - val_mae: 1.0354 - val_mse: 7.1143\n",
            "Epoch 240/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.3823 - mae: 1.0204 - mse: 15.3823 - val_loss: 7.2652 - val_mae: 1.0432 - val_mse: 7.2652\n",
            "Epoch 241/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.0849 - mae: 0.9787 - mse: 6.0849 - val_loss: 7.1544 - val_mae: 1.0429 - val_mse: 7.1544\n",
            "Epoch 242/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.3455 - mae: 0.9659 - mse: 8.3455 - val_loss: 7.3560 - val_mae: 1.0429 - val_mse: 7.3560\n",
            "Epoch 243/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 38.3766 - mae: 1.0608 - mse: 38.3766 - val_loss: 7.1390 - val_mae: 1.0480 - val_mse: 7.1390\n",
            "Epoch 244/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 57.4375 - mae: 1.0919 - mse: 57.4375 - val_loss: 7.1976 - val_mae: 1.0509 - val_mse: 7.1976\n",
            "Epoch 245/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.5706 - mae: 0.9868 - mse: 16.5706 - val_loss: 7.4554 - val_mae: 1.0469 - val_mse: 7.4554\n",
            "Epoch 246/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.7793 - mae: 1.0549 - mse: 21.7793 - val_loss: 7.0655 - val_mae: 1.0518 - val_mse: 7.0655\n",
            "Epoch 247/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.7238 - mae: 1.0300 - mse: 9.7238 - val_loss: 6.9393 - val_mae: 1.0258 - val_mse: 6.9393\n",
            "Epoch 248/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.8876 - mae: 0.9833 - mse: 10.8876 - val_loss: 7.2496 - val_mae: 1.0409 - val_mse: 7.2496\n",
            "Epoch 249/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.4761 - mae: 1.0016 - mse: 7.4761 - val_loss: 7.1349 - val_mae: 1.0246 - val_mse: 7.1349\n",
            "Epoch 250/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 46.0811 - mae: 1.0726 - mse: 46.0811 - val_loss: 7.2129 - val_mae: 1.0445 - val_mse: 7.2129\n",
            "Epoch 251/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.9995 - mae: 1.0129 - mse: 17.9995 - val_loss: 7.4179 - val_mae: 1.0369 - val_mse: 7.4179\n",
            "Epoch 252/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 24.4722 - mae: 1.0228 - mse: 24.4722 - val_loss: 6.9604 - val_mae: 1.0384 - val_mse: 6.9604\n",
            "Epoch 253/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.7501 - mae: 0.9918 - mse: 9.7501 - val_loss: 7.1971 - val_mae: 1.0336 - val_mse: 7.1971\n",
            "Epoch 254/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 56.1272 - mae: 1.0692 - mse: 56.1272 - val_loss: 6.8614 - val_mae: 1.0442 - val_mse: 6.8614\n",
            "Epoch 255/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.4461 - mae: 1.0419 - mse: 26.4461 - val_loss: 7.0334 - val_mae: 1.0232 - val_mse: 7.0334\n",
            "Epoch 256/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.1193 - mae: 1.0042 - mse: 16.1193 - val_loss: 6.8932 - val_mae: 1.0276 - val_mse: 6.8932\n",
            "Epoch 257/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.3217 - mae: 0.9702 - mse: 16.3217 - val_loss: 6.9676 - val_mae: 1.0227 - val_mse: 6.9676\n",
            "Epoch 258/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2936 - mae: 0.9846 - mse: 7.2936 - val_loss: 6.5863 - val_mae: 1.0040 - val_mse: 6.5863\n",
            "Epoch 259/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.6099 - mae: 0.9604 - mse: 8.6099 - val_loss: 7.0550 - val_mae: 1.0225 - val_mse: 7.0550\n",
            "Epoch 260/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.3221 - mae: 0.9881 - mse: 20.3221 - val_loss: 6.8872 - val_mae: 1.0171 - val_mse: 6.8872\n",
            "Epoch 261/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.6197 - mae: 0.9678 - mse: 13.6197 - val_loss: 6.8226 - val_mae: 1.0106 - val_mse: 6.8226\n",
            "Epoch 262/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 27.2168 - mae: 0.9826 - mse: 27.2168 - val_loss: 6.8396 - val_mae: 1.0147 - val_mse: 6.8396\n",
            "Epoch 263/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.0222 - mae: 0.9511 - mse: 7.0222 - val_loss: 6.9193 - val_mae: 1.0173 - val_mse: 6.9193\n",
            "Epoch 264/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.6621 - mae: 0.9626 - mse: 12.6621 - val_loss: 7.1392 - val_mae: 1.0223 - val_mse: 7.1392\n",
            "Epoch 265/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22.1665 - mae: 0.9784 - mse: 22.1665 - val_loss: 6.8067 - val_mae: 1.0201 - val_mse: 6.8067\n",
            "Epoch 266/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.1151 - mae: 0.9768 - mse: 11.1151 - val_loss: 7.1035 - val_mae: 1.0166 - val_mse: 7.1035\n",
            "Epoch 267/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.5308 - mae: 0.9367 - mse: 5.5308 - val_loss: 6.7164 - val_mae: 1.0168 - val_mse: 6.7164\n",
            "Epoch 268/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1749 - mae: 0.9448 - mse: 6.1749 - val_loss: 7.0326 - val_mae: 1.0255 - val_mse: 7.0326\n",
            "Epoch 269/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.7746 - mae: 0.9650 - mse: 17.7746 - val_loss: 6.7987 - val_mae: 1.0150 - val_mse: 6.7987\n",
            "Epoch 270/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.7211 - mae: 0.9787 - mse: 15.7211 - val_loss: 6.8157 - val_mae: 1.0132 - val_mse: 6.8157\n",
            "Epoch 271/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 17.2672 - mae: 0.9579 - mse: 17.2672 - val_loss: 6.6889 - val_mae: 1.0109 - val_mse: 6.6889\n",
            "Epoch 272/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2766 - mae: 0.9444 - mse: 5.2766 - val_loss: 6.7145 - val_mae: 1.0080 - val_mse: 6.7145\n",
            "Epoch 273/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24.0132 - mae: 0.9784 - mse: 24.0132 - val_loss: 6.9141 - val_mae: 1.0213 - val_mse: 6.9141\n",
            "Epoch 274/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.1050 - mae: 0.9670 - mse: 12.1050 - val_loss: 6.8606 - val_mae: 1.0184 - val_mse: 6.8606\n",
            "Epoch 275/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.4832 - mae: 0.9433 - mse: 6.4832 - val_loss: 6.5989 - val_mae: 1.0043 - val_mse: 6.5989\n",
            "Epoch 276/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 31.5596 - mae: 1.0006 - mse: 31.5596 - val_loss: 6.7693 - val_mae: 1.0107 - val_mse: 6.7693\n",
            "Epoch 277/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.4333 - mae: 0.9681 - mse: 9.4333 - val_loss: 6.8797 - val_mae: 1.0116 - val_mse: 6.8797\n",
            "Epoch 278/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 18.5331 - mae: 0.9585 - mse: 18.5331 - val_loss: 6.8729 - val_mae: 1.0095 - val_mse: 6.8729\n",
            "Epoch 279/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.2263 - mae: 0.9886 - mse: 16.2263 - val_loss: 6.7775 - val_mae: 1.0179 - val_mse: 6.7775\n",
            "Epoch 280/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.0390 - mae: 0.9693 - mse: 17.0390 - val_loss: 7.3293 - val_mae: 1.0350 - val_mse: 7.3293\n",
            "Epoch 281/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.1745 - mae: 0.9722 - mse: 12.1745 - val_loss: 6.9276 - val_mae: 1.0190 - val_mse: 6.9276\n",
            "Epoch 282/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.9273 - mae: 0.9975 - mse: 14.9273 - val_loss: 6.8993 - val_mae: 1.0197 - val_mse: 6.8993\n",
            "Epoch 283/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.9909 - mae: 0.9659 - mse: 10.9909 - val_loss: 6.9798 - val_mae: 1.0201 - val_mse: 6.9798\n",
            "Epoch 284/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.7914 - mae: 0.9691 - mse: 6.7914 - val_loss: 6.6322 - val_mae: 1.0059 - val_mse: 6.6322\n",
            "Epoch 285/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 42.4207 - mae: 1.0234 - mse: 42.4207 - val_loss: 6.8165 - val_mae: 1.0173 - val_mse: 6.8165\n",
            "Epoch 286/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.2818 - mae: 0.9745 - mse: 20.2818 - val_loss: 7.9360 - val_mae: 1.0485 - val_mse: 7.9360\n",
            "Epoch 287/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22.0351 - mae: 1.0202 - mse: 22.0351 - val_loss: 6.8329 - val_mae: 1.0275 - val_mse: 6.8329\n",
            "Epoch 288/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.9496 - mae: 0.9857 - mse: 18.9496 - val_loss: 6.9971 - val_mae: 1.0214 - val_mse: 6.9971\n",
            "Epoch 289/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.0837 - mae: 0.9622 - mse: 9.0837 - val_loss: 6.9156 - val_mae: 1.0165 - val_mse: 6.9156\n",
            "Epoch 290/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.7675 - mae: 0.9733 - mse: 8.7675 - val_loss: 7.2392 - val_mae: 1.0258 - val_mse: 7.2392\n",
            "Epoch 291/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 41.3155 - mae: 1.0191 - mse: 41.3155 - val_loss: 6.7140 - val_mae: 1.0126 - val_mse: 6.7140\n",
            "Epoch 292/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.5105 - mae: 0.9359 - mse: 9.5105 - val_loss: 6.8409 - val_mae: 1.0097 - val_mse: 6.8409\n",
            "Epoch 293/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 37.6648 - mae: 1.0102 - mse: 37.6648 - val_loss: 6.6973 - val_mae: 1.0097 - val_mse: 6.6973\n",
            "Epoch 294/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.1351 - mae: 0.9396 - mse: 7.1351 - val_loss: 6.8157 - val_mae: 1.0187 - val_mse: 6.8157\n",
            "Epoch 295/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 13.7641 - mae: 0.9524 - mse: 13.7641 - val_loss: 6.9928 - val_mae: 1.0169 - val_mse: 6.9928\n",
            "Epoch 296/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.6453 - mae: 0.9411 - mse: 5.6453 - val_loss: 6.4838 - val_mae: 0.9972 - val_mse: 6.4838\n",
            "Epoch 297/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.5530 - mae: 0.9691 - mse: 20.5530 - val_loss: 6.7681 - val_mae: 1.0110 - val_mse: 6.7681\n",
            "Epoch 298/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 51.0947 - mae: 1.0375 - mse: 51.0947 - val_loss: 6.6503 - val_mae: 1.0086 - val_mse: 6.6503\n",
            "Epoch 299/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 31.2541 - mae: 1.0051 - mse: 31.2541 - val_loss: 6.6346 - val_mae: 1.0126 - val_mse: 6.6346\n",
            "Epoch 300/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.9583 - mae: 0.9594 - mse: 7.9583 - val_loss: 6.6942 - val_mae: 1.0094 - val_mse: 6.6942\n",
            "Epoch 301/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.2562 - mae: 0.9963 - mse: 25.2562 - val_loss: 6.7337 - val_mae: 1.0073 - val_mse: 6.7337\n",
            "Epoch 302/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.1282 - mae: 0.9469 - mse: 6.1282 - val_loss: 6.6807 - val_mae: 1.0146 - val_mse: 6.6807\n",
            "Epoch 303/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.3895 - mae: 0.9467 - mse: 7.3895 - val_loss: 6.9634 - val_mae: 1.0153 - val_mse: 6.9634\n",
            "Epoch 304/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.5933 - mae: 0.9520 - mse: 8.5933 - val_loss: 6.7703 - val_mae: 1.0086 - val_mse: 6.7703\n",
            "Epoch 305/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.3239 - mae: 0.9724 - mse: 10.3239 - val_loss: 6.8744 - val_mae: 1.0117 - val_mse: 6.8744\n",
            "Epoch 306/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.3680 - mae: 1.0029 - mse: 35.3680 - val_loss: 6.8250 - val_mae: 1.0119 - val_mse: 6.8250\n",
            "Epoch 307/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.2854 - mae: 0.9585 - mse: 19.2854 - val_loss: 6.6915 - val_mae: 1.0075 - val_mse: 6.6915\n",
            "Epoch 308/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.0633 - mae: 0.9244 - mse: 8.0633 - val_loss: 7.0079 - val_mae: 1.0172 - val_mse: 7.0079\n",
            "Epoch 309/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.5191 - mae: 0.9623 - mse: 12.5191 - val_loss: 7.0628 - val_mae: 1.0186 - val_mse: 7.0628\n",
            "Epoch 310/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.0908 - mae: 0.9322 - mse: 9.0908 - val_loss: 6.8717 - val_mae: 1.0145 - val_mse: 6.8717\n",
            "Epoch 311/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 25.5308 - mae: 1.0081 - mse: 25.5308 - val_loss: 6.7512 - val_mae: 1.0068 - val_mse: 6.7512\n",
            "Epoch 312/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.6365 - mae: 0.9737 - mse: 14.6365 - val_loss: 6.9375 - val_mae: 1.0242 - val_mse: 6.9375\n",
            "Epoch 313/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.5145 - mae: 0.9993 - mse: 25.5145 - val_loss: 6.8633 - val_mae: 1.0129 - val_mse: 6.8633\n",
            "Epoch 314/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.4903 - mae: 0.9747 - mse: 8.4903 - val_loss: 6.7891 - val_mae: 1.0074 - val_mse: 6.7891\n",
            "Epoch 315/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.8742 - mae: 0.9736 - mse: 7.8742 - val_loss: 6.8226 - val_mae: 1.0090 - val_mse: 6.8226\n",
            "Epoch 316/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.8518 - mae: 0.9594 - mse: 8.8518 - val_loss: 6.7951 - val_mae: 1.0048 - val_mse: 6.7951\n",
            "Epoch 317/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.4182 - mae: 0.9524 - mse: 10.4182 - val_loss: 6.8207 - val_mae: 1.0066 - val_mse: 6.8207\n",
            "Epoch 318/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.4513 - mae: 0.9567 - mse: 12.4513 - val_loss: 6.7276 - val_mae: 1.0016 - val_mse: 6.7276\n",
            "Epoch 319/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.1849 - mae: 0.9830 - mse: 23.1849 - val_loss: 6.8463 - val_mae: 1.0101 - val_mse: 6.8463\n",
            "Epoch 320/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 26.1833 - mae: 0.9871 - mse: 26.1833 - val_loss: 6.8002 - val_mae: 1.0047 - val_mse: 6.8002\n",
            "Epoch 321/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 39.5784 - mae: 1.0030 - mse: 39.5784 - val_loss: 6.7856 - val_mae: 1.0181 - val_mse: 6.7856\n",
            "Epoch 322/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.3179 - mae: 0.9453 - mse: 6.3179 - val_loss: 6.6454 - val_mae: 1.0056 - val_mse: 6.6454\n",
            "Epoch 323/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.0627 - mae: 0.9971 - mse: 20.0627 - val_loss: 7.2174 - val_mae: 1.0150 - val_mse: 7.2174\n",
            "Epoch 324/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.5111 - mae: 0.9634 - mse: 10.5111 - val_loss: 7.5223 - val_mae: 1.0620 - val_mse: 7.5223\n",
            "Epoch 325/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.2488 - mae: 1.0022 - mse: 14.2488 - val_loss: 6.7625 - val_mae: 1.0011 - val_mse: 6.7625\n",
            "Epoch 326/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.1900 - mae: 0.9462 - mse: 9.1900 - val_loss: 6.8929 - val_mae: 1.0114 - val_mse: 6.8929\n",
            "Epoch 327/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 31.2402 - mae: 0.9874 - mse: 31.2402 - val_loss: 6.6688 - val_mae: 1.0009 - val_mse: 6.6688\n",
            "Epoch 328/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.4123 - mae: 0.9387 - mse: 14.4123 - val_loss: 6.7185 - val_mae: 1.0002 - val_mse: 6.7185\n",
            "Epoch 329/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.3801 - mae: 0.9550 - mse: 20.3801 - val_loss: 6.6538 - val_mae: 0.9990 - val_mse: 6.6538\n",
            "Epoch 330/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.1761 - mae: 0.9485 - mse: 12.1761 - val_loss: 6.8377 - val_mae: 1.0011 - val_mse: 6.8377\n",
            "Epoch 331/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.6318 - mae: 0.9351 - mse: 13.6318 - val_loss: 6.7912 - val_mae: 1.0010 - val_mse: 6.7912\n",
            "Epoch 332/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.0274 - mae: 0.9622 - mse: 11.0274 - val_loss: 6.7558 - val_mae: 1.0014 - val_mse: 6.7558\n",
            "Epoch 333/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.2852 - mae: 0.9398 - mse: 11.2852 - val_loss: 6.8670 - val_mae: 1.0063 - val_mse: 6.8670\n",
            "Epoch 334/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.8256 - mae: 0.9848 - mse: 23.8256 - val_loss: 6.6864 - val_mae: 0.9983 - val_mse: 6.6864\n",
            "Epoch 335/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.7282 - mae: 0.9462 - mse: 7.7282 - val_loss: 6.7451 - val_mae: 1.0017 - val_mse: 6.7451\n",
            "Epoch 336/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 48.9402 - mae: 1.0542 - mse: 48.9402 - val_loss: 6.8971 - val_mae: 1.0040 - val_mse: 6.8971\n",
            "Epoch 337/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 27.4105 - mae: 0.9949 - mse: 27.4105 - val_loss: 6.4340 - val_mae: 0.9920 - val_mse: 6.4340\n",
            "Epoch 338/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.7646 - mae: 0.9229 - mse: 5.7646 - val_loss: 6.7938 - val_mae: 0.9994 - val_mse: 6.7938\n",
            "Epoch 339/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.8612 - mae: 0.9490 - mse: 11.8612 - val_loss: 6.7631 - val_mae: 1.0017 - val_mse: 6.7631\n",
            "Epoch 340/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 30.4425 - mae: 0.9945 - mse: 30.4425 - val_loss: 6.7074 - val_mae: 0.9995 - val_mse: 6.7074\n",
            "Epoch 341/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.2928 - mae: 0.9329 - mse: 5.2928 - val_loss: 6.5913 - val_mae: 0.9963 - val_mse: 6.5913\n",
            "Epoch 342/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 28.3356 - mae: 0.9923 - mse: 28.3356 - val_loss: 7.0259 - val_mae: 1.0109 - val_mse: 7.0259\n",
            "Epoch 343/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.2354 - mae: 0.9909 - mse: 22.2354 - val_loss: 6.6673 - val_mae: 0.9951 - val_mse: 6.6673\n",
            "Epoch 344/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 27.5584 - mae: 0.9654 - mse: 27.5584 - val_loss: 7.0467 - val_mae: 1.0099 - val_mse: 7.0467\n",
            "Epoch 345/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.3194 - mae: 0.9344 - mse: 12.3194 - val_loss: 6.7788 - val_mae: 1.0050 - val_mse: 6.7788\n",
            "Epoch 346/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.3608 - mae: 0.9385 - mse: 13.3608 - val_loss: 6.7335 - val_mae: 0.9972 - val_mse: 6.7335\n",
            "Epoch 347/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.4514 - mae: 0.9634 - mse: 12.4514 - val_loss: 6.7385 - val_mae: 0.9997 - val_mse: 6.7385\n",
            "Epoch 348/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.3495 - mae: 0.9123 - mse: 4.3495 - val_loss: 6.8236 - val_mae: 1.0000 - val_mse: 6.8236\n",
            "Epoch 349/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 24.4296 - mae: 0.9738 - mse: 24.4296 - val_loss: 6.8469 - val_mae: 1.0001 - val_mse: 6.8469\n",
            "Epoch 350/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.5735 - mae: 0.9477 - mse: 6.5735 - val_loss: 7.1163 - val_mae: 1.0124 - val_mse: 7.1163\n",
            "Epoch 351/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.9375 - mae: 0.9330 - mse: 5.9375 - val_loss: 7.3416 - val_mae: 1.0088 - val_mse: 7.3416\n",
            "Epoch 352/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.3514 - mae: 0.9500 - mse: 7.3514 - val_loss: 7.0833 - val_mae: 1.0084 - val_mse: 7.0833\n",
            "Epoch 353/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.9751 - mae: 0.9600 - mse: 14.9751 - val_loss: 6.9331 - val_mae: 1.0069 - val_mse: 6.9331\n",
            "Epoch 354/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.8123 - mae: 0.9812 - mse: 19.8123 - val_loss: 6.8276 - val_mae: 0.9999 - val_mse: 6.8276\n",
            "Epoch 355/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.3958 - mae: 0.9748 - mse: 15.3958 - val_loss: 6.7267 - val_mae: 1.0063 - val_mse: 6.7267\n",
            "Epoch 356/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.3943 - mae: 0.9736 - mse: 18.3943 - val_loss: 7.0196 - val_mae: 1.0093 - val_mse: 7.0196\n",
            "Epoch 357/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 29.6603 - mae: 0.9886 - mse: 29.6603 - val_loss: 6.7318 - val_mae: 0.9955 - val_mse: 6.7318\n",
            "Epoch 358/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.2475 - mae: 0.9291 - mse: 10.2475 - val_loss: 7.1445 - val_mae: 1.0108 - val_mse: 7.1445\n",
            "Epoch 359/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24.7005 - mae: 0.9908 - mse: 24.7005 - val_loss: 6.8207 - val_mae: 1.0070 - val_mse: 6.8207\n",
            "Epoch 360/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.0101 - mae: 0.9523 - mse: 13.0101 - val_loss: 7.0138 - val_mae: 1.0054 - val_mse: 7.0138\n",
            "Epoch 361/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.6175 - mae: 0.9350 - mse: 6.6175 - val_loss: 7.4208 - val_mae: 1.0051 - val_mse: 7.4208\n",
            "Epoch 362/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.1077 - mae: 0.9651 - mse: 8.1077 - val_loss: 7.1300 - val_mae: 1.0133 - val_mse: 7.1300\n",
            "Epoch 363/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.6313 - mae: 1.0116 - mse: 19.6313 - val_loss: 7.5823 - val_mae: 1.0316 - val_mse: 7.5823\n",
            "Epoch 364/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 39.5937 - mae: 1.0304 - mse: 39.5937 - val_loss: 7.0964 - val_mae: 1.0144 - val_mse: 7.0964\n",
            "Epoch 365/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.8798 - mae: 0.9758 - mse: 20.8798 - val_loss: 7.1106 - val_mae: 1.0043 - val_mse: 7.1106\n",
            "Epoch 366/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 32.1327 - mae: 1.0034 - mse: 32.1327 - val_loss: 6.8439 - val_mae: 0.9947 - val_mse: 6.8439\n",
            "Epoch 367/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 36.4169 - mae: 1.0010 - mse: 36.4169 - val_loss: 6.9714 - val_mae: 1.0012 - val_mse: 6.9714\n",
            "Epoch 368/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.1661 - mae: 0.9659 - mse: 21.1661 - val_loss: 7.0163 - val_mae: 1.0026 - val_mse: 7.0163\n",
            "Epoch 369/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.5133 - mae: 0.9519 - mse: 15.5133 - val_loss: 6.7237 - val_mae: 0.9971 - val_mse: 6.7237\n",
            "Epoch 370/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.5021 - mae: 0.9220 - mse: 5.5021 - val_loss: 6.9488 - val_mae: 0.9983 - val_mse: 6.9488\n",
            "Epoch 371/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.4615 - mae: 0.9602 - mse: 19.4615 - val_loss: 6.9326 - val_mae: 1.0044 - val_mse: 6.9326\n",
            "Epoch 372/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.4454 - mae: 0.9793 - mse: 26.4454 - val_loss: 6.7354 - val_mae: 0.9967 - val_mse: 6.7354\n",
            "Epoch 373/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 13.0719 - mae: 0.9484 - mse: 13.0719 - val_loss: 6.9444 - val_mae: 1.0005 - val_mse: 6.9444\n",
            "Epoch 374/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.0535 - mae: 0.9264 - mse: 5.0535 - val_loss: 6.7321 - val_mae: 0.9940 - val_mse: 6.7321\n",
            "Epoch 375/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.3764 - mae: 0.9250 - mse: 8.3764 - val_loss: 7.1958 - val_mae: 1.0062 - val_mse: 7.1958\n",
            "Epoch 376/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.1630 - mae: 0.9448 - mse: 8.1630 - val_loss: 7.0038 - val_mae: 1.0006 - val_mse: 7.0038\n",
            "Epoch 377/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.5629 - mae: 0.9093 - mse: 5.5629 - val_loss: 7.0277 - val_mae: 1.0015 - val_mse: 7.0277\n",
            "Epoch 378/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.0943 - mae: 0.9682 - mse: 22.0943 - val_loss: 6.9748 - val_mae: 1.0019 - val_mse: 6.9748\n",
            "Epoch 379/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.7061 - mae: 0.9286 - mse: 9.7061 - val_loss: 7.2020 - val_mae: 1.0097 - val_mse: 7.2020\n",
            "Epoch 380/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.9083 - mae: 0.9320 - mse: 8.9083 - val_loss: 7.3474 - val_mae: 1.0098 - val_mse: 7.3474\n",
            "Epoch 381/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.2361 - mae: 0.9680 - mse: 16.2361 - val_loss: 6.9803 - val_mae: 0.9992 - val_mse: 6.9803\n",
            "Epoch 382/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.4419 - mae: 0.9288 - mse: 4.4419 - val_loss: 6.7753 - val_mae: 0.9954 - val_mse: 6.7753\n",
            "Epoch 383/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.6732 - mae: 0.9784 - mse: 5.6732 - val_loss: 7.5300 - val_mae: 1.0289 - val_mse: 7.5300\n",
            "Epoch 384/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.4116 - mae: 0.9975 - mse: 20.4116 - val_loss: 7.3756 - val_mae: 1.0249 - val_mse: 7.3756\n",
            "Epoch 385/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.6880 - mae: 0.9888 - mse: 15.6880 - val_loss: 7.1355 - val_mae: 1.0158 - val_mse: 7.1355\n",
            "Epoch 386/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.0818 - mae: 0.9508 - mse: 7.0818 - val_loss: 7.1088 - val_mae: 1.0113 - val_mse: 7.1088\n",
            "Epoch 387/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 25.8368 - mae: 0.9945 - mse: 25.8368 - val_loss: 7.0465 - val_mae: 1.0091 - val_mse: 7.0465\n",
            "Epoch 388/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.8500 - mae: 0.9356 - mse: 6.8500 - val_loss: 7.0711 - val_mae: 1.0074 - val_mse: 7.0711\n",
            "Epoch 389/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.5523 - mae: 0.9490 - mse: 6.5523 - val_loss: 7.0018 - val_mae: 1.0057 - val_mse: 7.0018\n",
            "Epoch 390/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 25.4893 - mae: 0.9732 - mse: 25.4893 - val_loss: 6.9630 - val_mae: 1.0036 - val_mse: 6.9630\n",
            "Epoch 391/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.8936 - mae: 0.9715 - mse: 19.8936 - val_loss: 7.1253 - val_mae: 1.0055 - val_mse: 7.1253\n",
            "Epoch 392/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.5050 - mae: 0.9434 - mse: 10.5050 - val_loss: 7.1417 - val_mae: 1.0104 - val_mse: 7.1417\n",
            "Epoch 393/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 23.7920 - mae: 0.9692 - mse: 23.7920 - val_loss: 6.9939 - val_mae: 1.0035 - val_mse: 6.9939\n",
            "Epoch 394/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.8123 - mae: 0.9586 - mse: 9.8123 - val_loss: 6.8254 - val_mae: 0.9997 - val_mse: 6.8254\n",
            "Epoch 395/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.0395 - mae: 0.9434 - mse: 16.0395 - val_loss: 7.2276 - val_mae: 1.0115 - val_mse: 7.2276\n",
            "Epoch 396/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 27.8028 - mae: 0.9884 - mse: 27.8028 - val_loss: 7.1700 - val_mae: 1.0067 - val_mse: 7.1700\n",
            "Epoch 397/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.0511 - mae: 0.9429 - mse: 10.0511 - val_loss: 7.0361 - val_mae: 0.9998 - val_mse: 7.0361\n",
            "Epoch 398/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.8224 - mae: 1.0147 - mse: 35.8224 - val_loss: 7.2022 - val_mae: 1.0042 - val_mse: 7.2022\n",
            "Epoch 399/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 28.3514 - mae: 0.9884 - mse: 28.3514 - val_loss: 7.1681 - val_mae: 1.0034 - val_mse: 7.1681\n",
            "Epoch 400/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.5159 - mae: 0.9548 - mse: 18.5159 - val_loss: 7.0261 - val_mae: 1.0010 - val_mse: 7.0261\n",
            "Epoch 401/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.7938 - mae: 0.9359 - mse: 11.7938 - val_loss: 7.2696 - val_mae: 1.0048 - val_mse: 7.2696\n",
            "Epoch 402/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.4942 - mae: 0.9390 - mse: 11.4942 - val_loss: 7.1395 - val_mae: 1.0066 - val_mse: 7.1395\n",
            "Epoch 403/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.7885 - mae: 0.9252 - mse: 4.7885 - val_loss: 6.8371 - val_mae: 0.9932 - val_mse: 6.8371\n",
            "Epoch 404/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 18.1539 - mae: 0.9537 - mse: 18.1539 - val_loss: 7.1794 - val_mae: 1.0126 - val_mse: 7.1794\n",
            "Epoch 405/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.3772 - mae: 0.9692 - mse: 17.3772 - val_loss: 7.1539 - val_mae: 0.9993 - val_mse: 7.1539\n",
            "Epoch 406/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.1283 - mae: 0.9692 - mse: 21.1283 - val_loss: 7.5099 - val_mae: 1.0122 - val_mse: 7.5099\n",
            "Epoch 407/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.8281 - mae: 0.9254 - mse: 9.8281 - val_loss: 6.8771 - val_mae: 0.9965 - val_mse: 6.8771\n",
            "Epoch 408/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.4606 - mae: 0.9343 - mse: 13.4606 - val_loss: 6.8944 - val_mae: 0.9990 - val_mse: 6.8944\n",
            "Epoch 409/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.5976 - mae: 0.9620 - mse: 23.5976 - val_loss: 7.2150 - val_mae: 1.0045 - val_mse: 7.2150\n",
            "Epoch 410/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.2999 - mae: 0.9325 - mse: 10.2999 - val_loss: 6.9938 - val_mae: 0.9972 - val_mse: 6.9938\n",
            "Epoch 411/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.5874 - mae: 0.9266 - mse: 6.5874 - val_loss: 7.0444 - val_mae: 1.0000 - val_mse: 7.0444\n",
            "Epoch 412/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1021 - mae: 0.9476 - mse: 10.1021 - val_loss: 7.0354 - val_mae: 0.9998 - val_mse: 7.0354\n",
            "Epoch 413/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 20.9935 - mae: 0.9457 - mse: 20.9935 - val_loss: 6.8513 - val_mae: 0.9990 - val_mse: 6.8513\n",
            "Epoch 414/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.9520 - mae: 0.9820 - mse: 20.9520 - val_loss: 7.6726 - val_mae: 1.0099 - val_mse: 7.6726\n",
            "Epoch 415/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 25.2676 - mae: 0.9852 - mse: 25.2676 - val_loss: 6.9066 - val_mae: 0.9938 - val_mse: 6.9066\n",
            "Epoch 416/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.4724 - mae: 0.9336 - mse: 14.4724 - val_loss: 7.1476 - val_mae: 0.9989 - val_mse: 7.1476\n",
            "Epoch 417/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.6032 - mae: 0.9248 - mse: 13.6032 - val_loss: 7.3194 - val_mae: 1.0017 - val_mse: 7.3194\n",
            "Epoch 418/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.9748 - mae: 0.9411 - mse: 12.9748 - val_loss: 7.0967 - val_mae: 0.9986 - val_mse: 7.0967\n",
            "Epoch 419/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1403 - mae: 0.9107 - mse: 10.1403 - val_loss: 7.2693 - val_mae: 1.0000 - val_mse: 7.2693\n",
            "Epoch 420/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.8352 - mae: 0.9460 - mse: 9.8352 - val_loss: 7.2894 - val_mae: 0.9984 - val_mse: 7.2894\n",
            "Epoch 421/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.5586 - mae: 0.9443 - mse: 5.5586 - val_loss: 7.2822 - val_mae: 0.9952 - val_mse: 7.2822\n",
            "Epoch 422/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.1228 - mae: 0.9296 - mse: 8.1228 - val_loss: 7.3211 - val_mae: 1.0127 - val_mse: 7.3211\n",
            "Epoch 423/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.3066 - mae: 0.9783 - mse: 26.3066 - val_loss: 7.2491 - val_mae: 1.0001 - val_mse: 7.2491\n",
            "Epoch 424/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.2492 - mae: 0.9489 - mse: 10.2492 - val_loss: 6.8390 - val_mae: 0.9934 - val_mse: 6.8390\n",
            "Epoch 425/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.4692 - mae: 0.9565 - mse: 9.4692 - val_loss: 7.4720 - val_mae: 1.0018 - val_mse: 7.4720\n",
            "Epoch 426/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.5671 - mae: 0.9543 - mse: 9.5671 - val_loss: 7.5241 - val_mae: 1.0080 - val_mse: 7.5241\n",
            "Epoch 427/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.4797 - mae: 0.9440 - mse: 6.4797 - val_loss: 6.9351 - val_mae: 0.9894 - val_mse: 6.9351\n",
            "Epoch 428/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.4051 - mae: 0.9350 - mse: 10.4051 - val_loss: 7.2977 - val_mae: 1.0282 - val_mse: 7.2977\n",
            "Epoch 429/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2617 - mae: 0.9328 - mse: 5.2617 - val_loss: 7.0876 - val_mae: 0.9923 - val_mse: 7.0876\n",
            "Epoch 430/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.0078 - mae: 0.9536 - mse: 19.0078 - val_loss: 7.1779 - val_mae: 0.9976 - val_mse: 7.1779\n",
            "Epoch 431/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2123 - mae: 0.9104 - mse: 4.2123 - val_loss: 6.9115 - val_mae: 0.9863 - val_mse: 6.9115\n",
            "Epoch 432/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.5482 - mae: 0.9405 - mse: 15.5482 - val_loss: 7.3308 - val_mae: 1.0000 - val_mse: 7.3308\n",
            "Epoch 433/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.4812 - mae: 0.9230 - mse: 5.4812 - val_loss: 7.1760 - val_mae: 0.9949 - val_mse: 7.1760\n",
            "Epoch 434/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.6375 - mae: 0.9222 - mse: 6.6375 - val_loss: 7.0641 - val_mae: 0.9911 - val_mse: 7.0641\n",
            "Epoch 435/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 13.1129 - mae: 0.9279 - mse: 13.1129 - val_loss: 7.8191 - val_mae: 1.0104 - val_mse: 7.8191\n",
            "Epoch 436/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 12.3698 - mae: 0.9407 - mse: 12.3698 - val_loss: 7.3151 - val_mae: 0.9975 - val_mse: 7.3151\n",
            "Epoch 437/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.6758 - mae: 0.9106 - mse: 6.6758 - val_loss: 7.6485 - val_mae: 1.0081 - val_mse: 7.6485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd2-SpLICpbO",
        "outputId": "9a905e50-4e8b-47f2-afea-e7f85ff07a8d"
      },
      "source": [
        "# 테스트 세트에 대한 성능 평가\n",
        "print(\"Accuracy : \", model.evaluate(X_test_scaled, y_testd)[1])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 0s 1ms/step - loss: 13.6317 - mae: 0.9931 - mse: 13.6317\n",
            "Accuracy :  0.9931209087371826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "_s9CNjsYCxO_",
        "outputId": "49796ace-d2d6-4ccf-e238-52827bce1e69"
      },
      "source": [
        "y_vloss = history.history['val_loss'] # 테스트 세트 손실\n",
        "y_loss = history.history['loss'] # 학습 세트의 정확도\n",
        "    \n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, '.', c='red', markersize=3, label=\"val_loss\")\n",
        "plt.plot(x_len, y_loss, '.', c='blue',  markersize=3,label = 'loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEOEgu_JRceE",
        "outputId": "48835cd2-f7df-4ef4-c752-fb235ba74a03"
      },
      "source": [
        "# 자동 종료를 위해 추가\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
        "\n",
        "model1 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model1.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "history1 = model1.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "57/57 [==============================] - 1s 7ms/step - loss: 257.5628 - mae: 7.4617 - val_loss: 170.3504 - val_mae: 4.7782\n",
            "Epoch 2/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 225.3252 - mae: 4.0681 - val_loss: 112.2076 - val_mae: 3.2883\n",
            "Epoch 3/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 172.7946 - mae: 3.6401 - val_loss: 87.8167 - val_mae: 2.9800\n",
            "Epoch 4/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 97.0599 - mae: 3.0256 - val_loss: 66.3840 - val_mae: 2.9117\n",
            "Epoch 5/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 122.1433 - mae: 2.9928 - val_loss: 52.6932 - val_mae: 2.6514\n",
            "Epoch 6/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 91.0324 - mae: 2.7728 - val_loss: 46.4910 - val_mae: 2.7774\n",
            "Epoch 7/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 54.3864 - mae: 2.8234 - val_loss: 43.1301 - val_mae: 2.6771\n",
            "Epoch 8/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 59.1959 - mae: 2.7543 - val_loss: 40.0499 - val_mae: 2.7371\n",
            "Epoch 9/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 60.5504 - mae: 2.6166 - val_loss: 36.6447 - val_mae: 2.4915\n",
            "Epoch 10/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 58.9134 - mae: 2.4620 - val_loss: 34.0701 - val_mae: 2.2885\n",
            "Epoch 11/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 41.0322 - mae: 2.1468 - val_loss: 31.8106 - val_mae: 2.0826\n",
            "Epoch 12/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 42.1514 - mae: 2.0508 - val_loss: 29.1024 - val_mae: 2.0068\n",
            "Epoch 13/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 42.6769 - mae: 1.9835 - val_loss: 28.4552 - val_mae: 1.8778\n",
            "Epoch 14/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 78.8470 - mae: 1.9851 - val_loss: 26.2584 - val_mae: 1.7310\n",
            "Epoch 15/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 54.4805 - mae: 1.7708 - val_loss: 25.6137 - val_mae: 1.7433\n",
            "Epoch 16/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 35.7069 - mae: 1.7065 - val_loss: 23.3157 - val_mae: 1.7282\n",
            "Epoch 17/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 51.3477 - mae: 1.7735 - val_loss: 23.1950 - val_mae: 1.6704\n",
            "Epoch 18/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.4406 - mae: 1.6409 - val_loss: 21.9035 - val_mae: 1.5692\n",
            "Epoch 19/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 88.7883 - mae: 1.7028 - val_loss: 19.6848 - val_mae: 1.5713\n",
            "Epoch 20/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 32.8991 - mae: 1.5830 - val_loss: 21.6803 - val_mae: 1.5514\n",
            "Epoch 21/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 59.0372 - mae: 1.5745 - val_loss: 19.5292 - val_mae: 1.4617\n",
            "Epoch 22/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.8565 - mae: 1.4200 - val_loss: 18.1553 - val_mae: 1.4205\n",
            "Epoch 23/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.9901 - mae: 1.3832 - val_loss: 17.3719 - val_mae: 1.4277\n",
            "Epoch 24/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 26.6104 - mae: 1.4143 - val_loss: 17.1064 - val_mae: 1.4279\n",
            "Epoch 25/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 68.7903 - mae: 1.4788 - val_loss: 15.7817 - val_mae: 1.3154\n",
            "Epoch 26/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 69.7914 - mae: 1.4118 - val_loss: 16.2435 - val_mae: 1.3293\n",
            "Epoch 27/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 71.5603 - mae: 1.3811 - val_loss: 14.6015 - val_mae: 1.2630\n",
            "Epoch 28/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.7547 - mae: 1.2071 - val_loss: 15.2022 - val_mae: 1.2912\n",
            "Epoch 29/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.8275 - mae: 1.2267 - val_loss: 13.9878 - val_mae: 1.2531\n",
            "Epoch 30/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 30.2330 - mae: 1.2671 - val_loss: 13.5427 - val_mae: 1.2168\n",
            "Epoch 31/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.2856 - mae: 1.1874 - val_loss: 13.3500 - val_mae: 1.2097\n",
            "Epoch 32/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 37.5411 - mae: 1.2195 - val_loss: 12.5797 - val_mae: 1.1595\n",
            "Epoch 33/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.2798 - mae: 1.1836 - val_loss: 13.7070 - val_mae: 1.2735\n",
            "Epoch 34/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15.5938 - mae: 1.1481 - val_loss: 11.6671 - val_mae: 1.1932\n",
            "Epoch 35/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.0345 - mae: 1.1277 - val_loss: 12.6327 - val_mae: 1.1840\n",
            "Epoch 36/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.7441 - mae: 1.1220 - val_loss: 11.0782 - val_mae: 1.1439\n",
            "Epoch 37/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.5954 - mae: 1.1628 - val_loss: 12.0360 - val_mae: 1.1268\n",
            "Epoch 38/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 60.0314 - mae: 1.2078 - val_loss: 10.2381 - val_mae: 1.0903\n",
            "Epoch 39/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.2311 - mae: 1.0380 - val_loss: 11.2111 - val_mae: 1.1956\n",
            "Epoch 40/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.8004 - mae: 1.1636 - val_loss: 10.5601 - val_mae: 1.1183\n",
            "Epoch 41/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 59.5998 - mae: 1.1642 - val_loss: 11.0615 - val_mae: 1.0829\n",
            "Epoch 42/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 44.2990 - mae: 1.1712 - val_loss: 9.9007 - val_mae: 1.0417\n",
            "Epoch 43/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.7621 - mae: 1.0383 - val_loss: 10.3702 - val_mae: 1.1701\n",
            "Epoch 44/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.6572 - mae: 1.0603 - val_loss: 9.3153 - val_mae: 1.0776\n",
            "Epoch 45/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.2882 - mae: 1.0536 - val_loss: 10.9730 - val_mae: 1.1142\n",
            "Epoch 46/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.0050 - mae: 1.0980 - val_loss: 8.0863 - val_mae: 1.0403\n",
            "Epoch 47/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 32.6433 - mae: 1.0901 - val_loss: 9.2417 - val_mae: 1.0157\n",
            "Epoch 48/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.5805 - mae: 0.9798 - val_loss: 9.4843 - val_mae: 1.0687\n",
            "Epoch 49/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 30.9265 - mae: 1.0613 - val_loss: 7.6326 - val_mae: 0.9980\n",
            "Epoch 50/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.1537 - mae: 0.9728 - val_loss: 10.3332 - val_mae: 1.0891\n",
            "Epoch 51/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.9248 - mae: 1.4056 - val_loss: 9.0299 - val_mae: 1.0714\n",
            "Epoch 52/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2225 - mae: 0.9949 - val_loss: 9.2362 - val_mae: 1.0856\n",
            "Epoch 53/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.1182 - mae: 1.0773 - val_loss: 8.6024 - val_mae: 1.0251\n",
            "Epoch 54/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.1103 - mae: 1.0199 - val_loss: 8.8947 - val_mae: 1.0191\n",
            "Epoch 55/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.7928 - mae: 0.9784 - val_loss: 9.7955 - val_mae: 1.1144\n",
            "Epoch 56/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.2568 - mae: 1.0313 - val_loss: 7.8786 - val_mae: 0.9742\n",
            "Epoch 57/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.8072 - mae: 0.9376 - val_loss: 7.5564 - val_mae: 0.9988\n",
            "Epoch 58/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.9839 - mae: 0.9510 - val_loss: 9.3087 - val_mae: 1.0638\n",
            "Epoch 59/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.9754 - mae: 0.9611 - val_loss: 8.0138 - val_mae: 1.0021\n",
            "Epoch 60/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 36.0585 - mae: 1.0663 - val_loss: 7.9663 - val_mae: 0.9741\n",
            "Epoch 61/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.6798 - mae: 0.9772 - val_loss: 8.6654 - val_mae: 0.9701\n",
            "Epoch 62/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.0097 - mae: 0.9766 - val_loss: 9.2147 - val_mae: 0.9685\n",
            "Epoch 63/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 43.3817 - mae: 1.0489 - val_loss: 7.1996 - val_mae: 0.9378\n",
            "Epoch 64/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.7055 - mae: 0.9518 - val_loss: 7.2142 - val_mae: 0.9603\n",
            "Epoch 65/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.2233 - mae: 0.9087 - val_loss: 8.9068 - val_mae: 1.0974\n",
            "Epoch 66/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.4815 - mae: 1.0454 - val_loss: 10.3898 - val_mae: 1.0651\n",
            "Epoch 67/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.2094 - mae: 1.0202 - val_loss: 8.6601 - val_mae: 0.9422\n",
            "Epoch 68/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 26.9264 - mae: 0.9683 - val_loss: 7.8578 - val_mae: 0.9265\n",
            "Epoch 69/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.1455 - mae: 0.9164 - val_loss: 7.9636 - val_mae: 0.9708\n",
            "Epoch 70/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.4313 - mae: 0.9200 - val_loss: 8.2878 - val_mae: 0.9888\n",
            "Epoch 71/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.8524 - mae: 0.9498 - val_loss: 6.7608 - val_mae: 0.9521\n",
            "Epoch 72/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.6605 - mae: 0.9955 - val_loss: 7.9428 - val_mae: 1.0026\n",
            "Epoch 73/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.2830 - mae: 0.8988 - val_loss: 8.9790 - val_mae: 1.0613\n",
            "Epoch 74/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.6591 - mae: 0.9258 - val_loss: 9.0727 - val_mae: 1.0406\n",
            "Epoch 75/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.0069 - mae: 0.9833 - val_loss: 8.2826 - val_mae: 0.9184\n",
            "Epoch 76/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.3925 - mae: 0.9266 - val_loss: 8.1341 - val_mae: 0.9749\n",
            "Epoch 77/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.2241 - mae: 0.9018 - val_loss: 7.4991 - val_mae: 1.0076\n",
            "Epoch 78/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.3294 - mae: 0.8839 - val_loss: 10.1036 - val_mae: 0.9881\n",
            "Epoch 79/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.4502 - mae: 0.9187 - val_loss: 8.5536 - val_mae: 0.9572\n",
            "Epoch 80/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 31.5969 - mae: 0.9706 - val_loss: 8.0611 - val_mae: 0.9238\n",
            "Epoch 81/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.5685 - mae: 0.8686 - val_loss: 8.2069 - val_mae: 0.9557\n",
            "Epoch 82/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.0593 - mae: 0.9433 - val_loss: 6.6069 - val_mae: 0.9250\n",
            "Epoch 83/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.8527 - mae: 0.8745 - val_loss: 10.1556 - val_mae: 1.0563\n",
            "Epoch 84/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.5286 - mae: 1.0456 - val_loss: 7.4065 - val_mae: 0.9303\n",
            "Epoch 85/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.0228 - mae: 0.9058 - val_loss: 9.1869 - val_mae: 1.0061\n",
            "Epoch 86/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.0487 - mae: 0.9105 - val_loss: 7.5421 - val_mae: 0.9466\n",
            "Epoch 87/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.1468 - mae: 0.8427 - val_loss: 8.4027 - val_mae: 1.0372\n",
            "Epoch 88/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.2229 - mae: 0.9708 - val_loss: 7.6352 - val_mae: 0.8903\n",
            "Epoch 89/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.5220 - mae: 0.8440 - val_loss: 9.4182 - val_mae: 1.0558\n",
            "Epoch 90/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.4871 - mae: 0.9494 - val_loss: 7.8960 - val_mae: 0.8884\n",
            "Epoch 91/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.3740 - mae: 0.9409 - val_loss: 8.0951 - val_mae: 0.9147\n",
            "Epoch 92/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.3913 - mae: 0.8736 - val_loss: 7.8387 - val_mae: 0.8938\n",
            "Epoch 93/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.5328 - mae: 0.8474 - val_loss: 7.8639 - val_mae: 0.9406\n",
            "Epoch 94/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.5719 - mae: 0.8748 - val_loss: 7.2125 - val_mae: 0.8801\n",
            "Epoch 95/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.5410 - mae: 0.8618 - val_loss: 7.4404 - val_mae: 0.9250\n",
            "Epoch 96/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.5125 - mae: 0.8564 - val_loss: 7.4581 - val_mae: 0.9111\n",
            "Epoch 97/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.3748 - mae: 0.8727 - val_loss: 7.9401 - val_mae: 0.9216\n",
            "Epoch 98/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.5313 - mae: 0.8511 - val_loss: 7.9590 - val_mae: 0.8794\n",
            "Epoch 99/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.3009 - mae: 0.8221 - val_loss: 9.4546 - val_mae: 1.0520\n",
            "Epoch 100/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.7992 - mae: 0.9116 - val_loss: 11.8499 - val_mae: 0.9817\n",
            "Epoch 101/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2550 - mae: 0.8923 - val_loss: 6.4484 - val_mae: 0.9285\n",
            "Epoch 102/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.1581 - mae: 0.8851 - val_loss: 7.5427 - val_mae: 0.9395\n",
            "Epoch 103/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.5368 - mae: 0.8897 - val_loss: 9.1770 - val_mae: 0.9799\n",
            "Epoch 104/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.1368 - mae: 0.9060 - val_loss: 8.1874 - val_mae: 1.0087\n",
            "Epoch 105/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.1027 - mae: 0.9292 - val_loss: 7.1308 - val_mae: 0.8785\n",
            "Epoch 106/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.7926 - mae: 0.7970 - val_loss: 7.9435 - val_mae: 0.9334\n",
            "Epoch 107/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.2130 - mae: 0.8191 - val_loss: 9.1494 - val_mae: 0.9914\n",
            "Epoch 108/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.2731 - mae: 0.8708 - val_loss: 7.9419 - val_mae: 0.9417\n",
            "Epoch 109/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.3309 - mae: 0.8901 - val_loss: 7.5753 - val_mae: 0.8852\n",
            "Epoch 110/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.8118 - mae: 0.8117 - val_loss: 8.5585 - val_mae: 0.9827\n",
            "Epoch 111/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.8967 - mae: 0.9219 - val_loss: 7.8814 - val_mae: 0.8968\n",
            "Epoch 112/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.6853 - mae: 0.8478 - val_loss: 7.8678 - val_mae: 0.9047\n",
            "Epoch 113/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.9309 - mae: 0.9024 - val_loss: 7.7087 - val_mae: 0.8675\n",
            "Epoch 114/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.3654 - mae: 0.9555 - val_loss: 7.4217 - val_mae: 0.9372\n",
            "Epoch 115/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.8916 - mae: 0.9220 - val_loss: 7.9501 - val_mae: 0.8956\n",
            "Epoch 116/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.3338 - mae: 0.8178 - val_loss: 8.8377 - val_mae: 0.9243\n",
            "Epoch 117/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.4451 - mae: 0.9112 - val_loss: 8.4356 - val_mae: 0.8871\n",
            "Epoch 118/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.0999 - mae: 0.8711 - val_loss: 7.9973 - val_mae: 0.8806\n",
            "Epoch 119/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.3245 - mae: 0.8047 - val_loss: 8.7393 - val_mae: 1.0616\n",
            "Epoch 120/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.6523 - mae: 0.8956 - val_loss: 9.3113 - val_mae: 0.9272\n",
            "Epoch 121/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.7342 - mae: 0.8251 - val_loss: 8.5634 - val_mae: 1.0092\n",
            "Epoch 122/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.5565 - mae: 0.9032 - val_loss: 8.8702 - val_mae: 0.8937\n",
            "Epoch 123/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.2777 - mae: 0.8580 - val_loss: 7.5313 - val_mae: 0.8826\n",
            "Epoch 124/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 27.0288 - mae: 0.8973 - val_loss: 7.3326 - val_mae: 0.8516\n",
            "Epoch 125/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.6915 - mae: 0.8163 - val_loss: 7.7546 - val_mae: 0.8716\n",
            "Epoch 126/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.1707 - mae: 0.7950 - val_loss: 8.9592 - val_mae: 0.9927\n",
            "Epoch 127/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8656 - mae: 0.8321 - val_loss: 8.9584 - val_mae: 0.9228\n",
            "Epoch 128/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.7060 - mae: 0.8509 - val_loss: 9.6129 - val_mae: 0.8836\n",
            "Epoch 129/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.4018 - mae: 0.8426 - val_loss: 6.9579 - val_mae: 0.9133\n",
            "Epoch 130/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.1402 - mae: 0.8359 - val_loss: 8.3410 - val_mae: 0.9799\n",
            "Epoch 131/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.3213 - mae: 0.8515 - val_loss: 8.1587 - val_mae: 0.9010\n",
            "Epoch 132/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.5453 - mae: 0.8617 - val_loss: 7.5465 - val_mae: 0.8532\n",
            "Epoch 133/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.9990 - mae: 0.8122 - val_loss: 7.2551 - val_mae: 0.8609\n",
            "Epoch 134/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3.6047 - mae: 0.7856 - val_loss: 9.7428 - val_mae: 1.0193\n",
            "Epoch 135/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2372 - mae: 0.8758 - val_loss: 9.6664 - val_mae: 0.9900\n",
            "Epoch 136/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.3754 - mae: 0.9025 - val_loss: 9.3116 - val_mae: 0.8765\n",
            "Epoch 137/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.7866 - mae: 0.8039 - val_loss: 9.7681 - val_mae: 1.0319\n",
            "Epoch 138/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.6141 - mae: 0.8473 - val_loss: 7.2179 - val_mae: 0.8746\n",
            "Epoch 139/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.3652 - mae: 0.8011 - val_loss: 8.5631 - val_mae: 0.8984\n",
            "Epoch 140/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.2754 - mae: 0.8284 - val_loss: 8.0286 - val_mae: 0.8712\n",
            "Epoch 141/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.3208 - mae: 0.8508 - val_loss: 7.7360 - val_mae: 0.8567\n",
            "Epoch 142/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.0696 - mae: 0.7708 - val_loss: 8.0671 - val_mae: 0.9390\n",
            "Epoch 143/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.2290 - mae: 0.8575 - val_loss: 7.9137 - val_mae: 0.8669\n",
            "Epoch 144/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.5488 - mae: 0.8288 - val_loss: 8.0563 - val_mae: 0.8828\n",
            "Epoch 145/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8528 - mae: 0.7835 - val_loss: 9.3225 - val_mae: 1.0508\n",
            "Epoch 146/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.7325 - mae: 0.8675 - val_loss: 10.2588 - val_mae: 1.1115\n",
            "Epoch 147/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1273 - mae: 0.9444 - val_loss: 8.1700 - val_mae: 0.8615\n",
            "Epoch 148/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.8460 - mae: 0.8299 - val_loss: 10.4359 - val_mae: 0.9621\n",
            "Epoch 149/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.5586 - mae: 0.8786 - val_loss: 7.2099 - val_mae: 0.9134\n",
            "Epoch 150/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.4167 - mae: 0.8573 - val_loss: 7.2250 - val_mae: 0.8510\n",
            "Epoch 151/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.1057 - mae: 0.8105 - val_loss: 7.6331 - val_mae: 0.8553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "6FRbBU5-Rr1U",
        "outputId": "2e8f1569-191a-47d4-fd71-5bd01c0cc49d"
      },
      "source": [
        "# 테스트 세트에 대한 성능 평가\n",
        "print(\"Accuracy : \", model1.evaluate(X_test_scaled, y_testd)[1])\n",
        "\n",
        "\n",
        "y_vloss = history1.history['val_loss'] # 테스트 세트 손실\n",
        "y_loss = history1.history['loss'] # 학습 세트의 정확도\n",
        "    \n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, '.', c='red', markersize=3, label=\"val_loss\")\n",
        "plt.plot(x_len, y_loss, '.', c='blue',  markersize=3,label = 'loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 0s 959us/step - loss: 14.0973 - mae: 0.8520\n",
            "Accuracy :  0.85200434923172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKDUdbh7CzGg",
        "outputId": "a709a432-4c9c-4cb5-bd2a-27dfdb44469e"
      },
      "source": [
        "\n",
        "model2 = Sequential([\n",
        "      Dense(128, activation='relu', input_dim=X_train.shape[1]),\n",
        "      Dense(64, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model2.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "history2 = model2.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "57/57 [==============================] - 1s 9ms/step - loss: 239.3289 - mae: 6.6292 - mse: 239.3289 - val_loss: 129.7288 - val_mae: 3.5658 - val_mse: 129.7288\n",
            "Epoch 2/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 175.7392 - mae: 3.6776 - mse: 175.7392 - val_loss: 81.6080 - val_mae: 2.8866 - val_mse: 81.6080\n",
            "Epoch 3/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 128.0916 - mae: 3.0917 - mse: 128.0916 - val_loss: 52.2824 - val_mae: 2.7776 - val_mse: 52.2824\n",
            "Epoch 4/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 58.8882 - mae: 2.8503 - mse: 58.8882 - val_loss: 41.8523 - val_mae: 2.8959 - val_mse: 41.8523\n",
            "Epoch 5/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 86.4688 - mae: 3.0440 - mse: 86.4688 - val_loss: 37.2346 - val_mae: 2.5248 - val_mse: 37.2346\n",
            "Epoch 6/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 70.8450 - mae: 2.4926 - mse: 70.8450 - val_loss: 31.4617 - val_mae: 2.3240 - val_mse: 31.4617\n",
            "Epoch 7/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 36.5535 - mae: 2.2024 - mse: 36.5535 - val_loss: 29.8731 - val_mae: 2.0155 - val_mse: 29.8731\n",
            "Epoch 8/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 41.2843 - mae: 2.0303 - mse: 41.2843 - val_loss: 24.5801 - val_mae: 1.8724 - val_mse: 24.5801\n",
            "Epoch 9/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 47.0795 - mae: 1.8217 - mse: 47.0795 - val_loss: 21.6993 - val_mae: 1.6209 - val_mse: 21.6993\n",
            "Epoch 10/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 41.3056 - mae: 1.5788 - mse: 41.3056 - val_loss: 21.2280 - val_mae: 1.4832 - val_mse: 21.2280\n",
            "Epoch 11/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 27.0140 - mae: 1.3923 - mse: 27.0140 - val_loss: 19.0507 - val_mae: 1.4627 - val_mse: 19.0507\n",
            "Epoch 12/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 24.7175 - mae: 1.4271 - mse: 24.7175 - val_loss: 19.0905 - val_mae: 1.6385 - val_mse: 19.0905\n",
            "Epoch 13/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 26.6754 - mae: 1.4906 - mse: 26.6754 - val_loss: 17.2699 - val_mae: 1.4142 - val_mse: 17.2699\n",
            "Epoch 14/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 58.3109 - mae: 1.4745 - mse: 58.3109 - val_loss: 14.8860 - val_mae: 1.1922 - val_mse: 14.8860\n",
            "Epoch 15/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 33.2398 - mae: 1.2381 - mse: 33.2398 - val_loss: 15.4882 - val_mae: 1.2070 - val_mse: 15.4882\n",
            "Epoch 16/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 20.8953 - mae: 1.1948 - mse: 20.8953 - val_loss: 13.7904 - val_mae: 1.2833 - val_mse: 13.7904\n",
            "Epoch 17/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.5508 - mae: 1.2424 - mse: 35.5508 - val_loss: 13.6938 - val_mae: 1.1224 - val_mse: 13.6938\n",
            "Epoch 18/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 15.9631 - mae: 1.1380 - mse: 15.9631 - val_loss: 12.8305 - val_mae: 1.0948 - val_mse: 12.8305\n",
            "Epoch 19/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 66.6815 - mae: 1.2331 - mse: 66.6815 - val_loss: 10.9721 - val_mae: 1.0800 - val_mse: 10.9721\n",
            "Epoch 20/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 22.1631 - mae: 1.1233 - mse: 22.1631 - val_loss: 12.0418 - val_mae: 1.0603 - val_mse: 12.0418\n",
            "Epoch 21/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 40.7527 - mae: 1.0729 - mse: 40.7527 - val_loss: 13.5988 - val_mae: 1.0675 - val_mse: 13.5988\n",
            "Epoch 22/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 12.0963 - mae: 0.9857 - mse: 12.0963 - val_loss: 11.5214 - val_mae: 1.1547 - val_mse: 11.5214\n",
            "Epoch 23/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 13.1364 - mae: 1.0621 - mse: 13.1364 - val_loss: 10.6440 - val_mae: 0.9705 - val_mse: 10.6440\n",
            "Epoch 24/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 16.3428 - mae: 0.9682 - mse: 16.3428 - val_loss: 10.8621 - val_mae: 0.9683 - val_mse: 10.8621\n",
            "Epoch 25/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 47.1004 - mae: 1.0052 - mse: 47.1004 - val_loss: 10.6883 - val_mae: 0.9630 - val_mse: 10.6883\n",
            "Epoch 26/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 44.8732 - mae: 1.0453 - mse: 44.8732 - val_loss: 10.4651 - val_mae: 0.9575 - val_mse: 10.4651\n",
            "Epoch 27/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 52.0918 - mae: 1.0331 - mse: 52.0918 - val_loss: 11.0707 - val_mae: 0.9104 - val_mse: 11.0707\n",
            "Epoch 28/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 37.8104 - mae: 1.0276 - mse: 37.8104 - val_loss: 10.6859 - val_mae: 0.9463 - val_mse: 10.6859\n",
            "Epoch 29/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.9408 - mae: 0.8700 - mse: 8.9408 - val_loss: 10.3991 - val_mae: 1.0180 - val_mse: 10.3991\n",
            "Epoch 30/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 18.9431 - mae: 0.9983 - mse: 18.9431 - val_loss: 9.3351 - val_mae: 0.8621 - val_mse: 9.3351\n",
            "Epoch 31/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.5437 - mae: 0.8452 - mse: 10.5437 - val_loss: 9.9396 - val_mae: 0.8796 - val_mse: 9.9396\n",
            "Epoch 32/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 23.8989 - mae: 0.8530 - mse: 23.8989 - val_loss: 9.2590 - val_mae: 0.8393 - val_mse: 9.2590\n",
            "Epoch 33/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 12.1208 - mae: 0.8364 - mse: 12.1208 - val_loss: 10.7844 - val_mae: 0.9315 - val_mse: 10.7844\n",
            "Epoch 34/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.8630 - mae: 0.8265 - mse: 9.8630 - val_loss: 9.8505 - val_mae: 0.9400 - val_mse: 9.8505\n",
            "Epoch 35/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.8862 - mae: 0.8413 - mse: 8.8862 - val_loss: 10.8319 - val_mae: 1.0042 - val_mse: 10.8319\n",
            "Epoch 36/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.6274 - mae: 0.8632 - mse: 10.6274 - val_loss: 9.4845 - val_mae: 0.8747 - val_mse: 9.4845\n",
            "Epoch 37/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 16.4616 - mae: 0.8539 - mse: 16.4616 - val_loss: 9.4784 - val_mae: 0.8517 - val_mse: 9.4784\n",
            "Epoch 38/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 37.5675 - mae: 0.8856 - mse: 37.5675 - val_loss: 8.8988 - val_mae: 0.8204 - val_mse: 8.8988\n",
            "Epoch 39/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.1759 - mae: 0.7602 - mse: 5.1759 - val_loss: 9.9608 - val_mae: 0.8936 - val_mse: 9.9608\n",
            "Epoch 40/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 13.3429 - mae: 0.8697 - mse: 13.3429 - val_loss: 9.1513 - val_mae: 0.8417 - val_mse: 9.1513\n",
            "Epoch 41/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 38.4786 - mae: 0.8787 - mse: 38.4786 - val_loss: 9.4620 - val_mae: 0.8314 - val_mse: 9.4620\n",
            "Epoch 42/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 27.9239 - mae: 0.8741 - mse: 27.9239 - val_loss: 8.7812 - val_mae: 0.8146 - val_mse: 8.7812\n",
            "Epoch 43/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.7126 - mae: 0.7880 - mse: 7.7126 - val_loss: 10.4112 - val_mae: 0.9285 - val_mse: 10.4112\n",
            "Epoch 44/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.4847 - mae: 0.7955 - mse: 7.4847 - val_loss: 9.4651 - val_mae: 0.8700 - val_mse: 9.4651\n",
            "Epoch 45/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 17.6468 - mae: 0.9163 - mse: 17.6468 - val_loss: 11.2131 - val_mae: 0.8987 - val_mse: 11.2131\n",
            "Epoch 46/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 16.4045 - mae: 0.8762 - mse: 16.4045 - val_loss: 7.8822 - val_mae: 0.9459 - val_mse: 7.8822\n",
            "Epoch 47/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 23.5817 - mae: 0.9434 - mse: 23.5817 - val_loss: 10.6522 - val_mae: 0.8684 - val_mse: 10.6522\n",
            "Epoch 48/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.9483 - mae: 0.7957 - mse: 10.9483 - val_loss: 10.0255 - val_mae: 1.0024 - val_mse: 10.0255\n",
            "Epoch 49/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 21.1651 - mae: 0.9198 - mse: 21.1651 - val_loss: 8.7730 - val_mae: 0.8175 - val_mse: 8.7730\n",
            "Epoch 50/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.9964 - mae: 0.7746 - mse: 5.9964 - val_loss: 11.1445 - val_mae: 0.8927 - val_mse: 11.1445\n",
            "Epoch 51/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 15.1825 - mae: 1.0703 - mse: 15.1825 - val_loss: 9.8677 - val_mae: 0.8742 - val_mse: 9.8677\n",
            "Epoch 52/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.4086 - mae: 0.7959 - mse: 5.4086 - val_loss: 10.1580 - val_mae: 0.8718 - val_mse: 10.1580\n",
            "Epoch 53/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 11.3924 - mae: 0.8112 - mse: 11.3924 - val_loss: 9.4202 - val_mae: 0.8792 - val_mse: 9.4202\n",
            "Epoch 54/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 12.9188 - mae: 0.8206 - mse: 12.9188 - val_loss: 10.7467 - val_mae: 0.9570 - val_mse: 10.7467\n",
            "Epoch 55/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 11.2834 - mae: 0.8575 - mse: 11.2834 - val_loss: 9.5038 - val_mae: 0.9523 - val_mse: 9.5038\n",
            "Epoch 56/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 12.7073 - mae: 0.8450 - mse: 12.7073 - val_loss: 9.0810 - val_mae: 0.8249 - val_mse: 9.0810\n",
            "Epoch 57/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.0005 - mae: 0.7699 - mse: 8.0005 - val_loss: 9.7387 - val_mae: 0.8408 - val_mse: 9.7387\n",
            "Epoch 58/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.7509 - mae: 0.7656 - mse: 5.7509 - val_loss: 9.6728 - val_mae: 0.8541 - val_mse: 9.6728\n",
            "Epoch 59/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.4462 - mae: 0.7669 - mse: 4.4462 - val_loss: 8.9466 - val_mae: 0.8061 - val_mse: 8.9466\n",
            "Epoch 60/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 20.9090 - mae: 0.8399 - mse: 20.9090 - val_loss: 8.9299 - val_mae: 0.8136 - val_mse: 8.9299\n",
            "Epoch 61/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 12.0682 - mae: 0.7688 - mse: 12.0682 - val_loss: 9.3491 - val_mae: 0.8247 - val_mse: 9.3491\n",
            "Epoch 62/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.8667 - mae: 0.7854 - mse: 10.8667 - val_loss: 9.2614 - val_mae: 0.8093 - val_mse: 9.2614\n",
            "Epoch 63/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 23.0532 - mae: 0.8288 - mse: 23.0532 - val_loss: 8.2449 - val_mae: 0.7879 - val_mse: 8.2449\n",
            "Epoch 64/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 10.9237 - mae: 0.7396 - mse: 10.9237 - val_loss: 8.4362 - val_mae: 0.7999 - val_mse: 8.4362\n",
            "Epoch 65/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.9760 - mae: 0.7250 - mse: 3.9760 - val_loss: 8.7242 - val_mae: 0.8264 - val_mse: 8.7242\n",
            "Epoch 66/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.4660 - mae: 0.7686 - mse: 5.4660 - val_loss: 10.3101 - val_mae: 0.8342 - val_mse: 10.3101\n",
            "Epoch 67/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.7160 - mae: 0.7849 - mse: 9.7160 - val_loss: 9.0937 - val_mae: 0.7965 - val_mse: 9.0937\n",
            "Epoch 68/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 13.8809 - mae: 0.7747 - mse: 13.8809 - val_loss: 9.0891 - val_mae: 0.7945 - val_mse: 9.0891\n",
            "Epoch 69/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.1552 - mae: 0.7323 - mse: 7.1552 - val_loss: 8.4301 - val_mae: 0.8212 - val_mse: 8.4301\n",
            "Epoch 70/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.5826 - mae: 0.7581 - mse: 4.5826 - val_loss: 9.1840 - val_mae: 0.8156 - val_mse: 9.1840\n",
            "Epoch 71/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.5664 - mae: 0.7344 - mse: 6.5664 - val_loss: 8.4474 - val_mae: 0.7810 - val_mse: 8.4474\n",
            "Epoch 72/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.1549 - mae: 0.7518 - mse: 9.1549 - val_loss: 9.2807 - val_mae: 0.7964 - val_mse: 9.2807\n",
            "Epoch 73/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.2091 - mae: 0.7016 - mse: 4.2091 - val_loss: 9.3029 - val_mae: 0.8192 - val_mse: 9.3029\n",
            "Epoch 74/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.4813 - mae: 0.7132 - mse: 3.4813 - val_loss: 9.4840 - val_mae: 0.7978 - val_mse: 9.4840\n",
            "Epoch 75/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.8034 - mae: 0.7630 - mse: 9.8034 - val_loss: 8.7274 - val_mae: 0.7868 - val_mse: 8.7274\n",
            "Epoch 76/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.1367 - mae: 0.7243 - mse: 6.1367 - val_loss: 7.3904 - val_mae: 0.7872 - val_mse: 7.3904\n",
            "Epoch 77/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.7510 - mae: 0.7346 - mse: 4.7510 - val_loss: 7.8482 - val_mae: 0.8248 - val_mse: 7.8482\n",
            "Epoch 78/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6557 - mae: 0.7204 - mse: 3.6557 - val_loss: 10.0433 - val_mae: 0.8642 - val_mse: 10.0433\n",
            "Epoch 79/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.9737 - mae: 0.7519 - mse: 3.9737 - val_loss: 9.0196 - val_mae: 0.7867 - val_mse: 9.0196\n",
            "Epoch 80/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 12.5826 - mae: 0.7846 - mse: 12.5826 - val_loss: 7.6507 - val_mae: 0.7815 - val_mse: 7.6507\n",
            "Epoch 81/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6342 - mae: 0.7015 - mse: 3.6342 - val_loss: 8.7872 - val_mae: 0.8061 - val_mse: 8.7872\n",
            "Epoch 82/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.7776 - mae: 0.7461 - mse: 7.7776 - val_loss: 7.8755 - val_mae: 0.8390 - val_mse: 7.8755\n",
            "Epoch 83/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.1782 - mae: 0.7668 - mse: 7.1782 - val_loss: 13.7391 - val_mae: 1.1206 - val_mse: 13.7391\n",
            "Epoch 84/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 54.9101 - mae: 1.0139 - mse: 54.9101 - val_loss: 8.8109 - val_mae: 0.8217 - val_mse: 8.8109\n",
            "Epoch 85/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 19.0811 - mae: 0.8412 - mse: 19.0811 - val_loss: 11.6259 - val_mae: 0.8793 - val_mse: 11.6259\n",
            "Epoch 86/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 14.5129 - mae: 0.8742 - mse: 14.5129 - val_loss: 8.4549 - val_mae: 0.7958 - val_mse: 8.4549\n",
            "Epoch 87/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.0418 - mae: 0.7179 - mse: 4.0418 - val_loss: 8.7230 - val_mae: 0.9448 - val_mse: 8.7230\n",
            "Epoch 88/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 12.9750 - mae: 0.9298 - mse: 12.9750 - val_loss: 8.3945 - val_mae: 0.7927 - val_mse: 8.3945\n",
            "Epoch 89/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.4505 - mae: 0.7710 - mse: 6.4505 - val_loss: 8.4358 - val_mae: 0.8358 - val_mse: 8.4358\n",
            "Epoch 90/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.0217 - mae: 0.7944 - mse: 9.0217 - val_loss: 7.7234 - val_mae: 0.8321 - val_mse: 7.7234\n",
            "Epoch 91/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.4462 - mae: 0.8023 - mse: 8.4462 - val_loss: 8.5225 - val_mae: 0.8590 - val_mse: 8.5225\n",
            "Epoch 92/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.5659 - mae: 0.7676 - mse: 7.5659 - val_loss: 7.7835 - val_mae: 0.7835 - val_mse: 7.7835\n",
            "Epoch 93/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.0743 - mae: 0.7160 - mse: 5.0743 - val_loss: 8.8090 - val_mae: 0.8117 - val_mse: 8.8090\n",
            "Epoch 94/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.5566 - mae: 0.7256 - mse: 5.5566 - val_loss: 8.1359 - val_mae: 0.7856 - val_mse: 8.1359\n",
            "Epoch 95/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1010 - mae: 0.7277 - mse: 6.1010 - val_loss: 8.2656 - val_mae: 0.7887 - val_mse: 8.2656\n",
            "Epoch 96/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.7553 - mae: 0.7182 - mse: 4.7553 - val_loss: 8.7029 - val_mae: 0.8088 - val_mse: 8.7029\n",
            "Epoch 97/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.0823 - mae: 0.7339 - mse: 5.0823 - val_loss: 8.8725 - val_mae: 0.7796 - val_mse: 8.8725\n",
            "Epoch 98/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.3806 - mae: 0.6978 - mse: 4.3806 - val_loss: 7.5976 - val_mae: 0.7826 - val_mse: 7.5976\n",
            "Epoch 99/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.3917 - mae: 0.7168 - mse: 4.3917 - val_loss: 7.4759 - val_mae: 0.7759 - val_mse: 7.4759\n",
            "Epoch 100/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.1904 - mae: 0.7215 - mse: 4.1904 - val_loss: 8.1747 - val_mae: 0.8695 - val_mse: 8.1747\n",
            "Epoch 101/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0561 - mae: 0.7441 - mse: 3.0561 - val_loss: 6.2603 - val_mae: 0.8245 - val_mse: 6.2603\n",
            "Epoch 102/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.3098 - mae: 0.7950 - mse: 5.3098 - val_loss: 8.9162 - val_mae: 0.7876 - val_mse: 8.9162\n",
            "Epoch 103/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.9587 - mae: 0.7116 - mse: 3.9587 - val_loss: 7.9539 - val_mae: 0.8024 - val_mse: 7.9539\n",
            "Epoch 104/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.9196 - mae: 0.7242 - mse: 3.9196 - val_loss: 7.5647 - val_mae: 0.7749 - val_mse: 7.5647\n",
            "Epoch 105/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 4.9248 - mae: 0.7236 - mse: 4.9248 - val_loss: 7.6792 - val_mae: 0.7522 - val_mse: 7.6792\n",
            "Epoch 106/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9775 - mae: 0.6793 - mse: 2.9775 - val_loss: 8.4391 - val_mae: 0.7705 - val_mse: 8.4391\n",
            "Epoch 107/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0671 - mae: 0.6647 - mse: 3.0671 - val_loss: 8.7332 - val_mae: 0.8459 - val_mse: 8.7332\n",
            "Epoch 108/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 3.0020 - mae: 0.7316 - mse: 3.0020 - val_loss: 7.6629 - val_mae: 0.7647 - val_mse: 7.6629\n",
            "Epoch 109/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.7169 - mae: 0.6919 - mse: 3.7169 - val_loss: 7.1457 - val_mae: 0.7563 - val_mse: 7.1457\n",
            "Epoch 110/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.5708 - mae: 0.6775 - mse: 2.5708 - val_loss: 8.3526 - val_mae: 0.8380 - val_mse: 8.3526\n",
            "Epoch 111/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.7560 - mae: 0.7299 - mse: 3.7560 - val_loss: 7.0343 - val_mae: 0.7658 - val_mse: 7.0343\n",
            "Epoch 112/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.7419 - mae: 0.6908 - mse: 2.7419 - val_loss: 8.2770 - val_mae: 0.7724 - val_mse: 8.2770\n",
            "Epoch 113/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.2096 - mae: 0.6941 - mse: 3.2096 - val_loss: 7.7572 - val_mae: 0.7996 - val_mse: 7.7572\n",
            "Epoch 114/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.3213 - mae: 0.7276 - mse: 4.3213 - val_loss: 6.7879 - val_mae: 0.7528 - val_mse: 6.7879\n",
            "Epoch 115/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.3233 - mae: 0.7293 - mse: 5.3233 - val_loss: 8.0272 - val_mae: 0.7637 - val_mse: 8.0272\n",
            "Epoch 116/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.2105 - mae: 0.7014 - mse: 4.2105 - val_loss: 8.4595 - val_mae: 0.7707 - val_mse: 8.4595\n",
            "Epoch 117/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.1952 - mae: 0.6895 - mse: 3.1952 - val_loss: 7.3496 - val_mae: 0.7506 - val_mse: 7.3496\n",
            "Epoch 118/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9837 - mae: 0.6885 - mse: 2.9837 - val_loss: 7.7293 - val_mae: 0.7469 - val_mse: 7.7293\n",
            "Epoch 119/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.0143 - mae: 0.7186 - mse: 4.0143 - val_loss: 7.7051 - val_mae: 0.7447 - val_mse: 7.7051\n",
            "Epoch 120/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6966 - mae: 0.6766 - mse: 2.6966 - val_loss: 7.2733 - val_mae: 0.7798 - val_mse: 7.2733\n",
            "Epoch 121/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3804 - mae: 0.6813 - mse: 2.3804 - val_loss: 8.5026 - val_mae: 0.7784 - val_mse: 8.5026\n",
            "Epoch 122/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9403 - mae: 0.6921 - mse: 2.9403 - val_loss: 7.3529 - val_mae: 0.7491 - val_mse: 7.3529\n",
            "Epoch 123/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.5826 - mae: 0.6731 - mse: 2.5826 - val_loss: 7.8686 - val_mae: 0.7523 - val_mse: 7.8686\n",
            "Epoch 124/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.7386 - mae: 0.7146 - mse: 3.7386 - val_loss: 7.2777 - val_mae: 0.7350 - val_mse: 7.2777\n",
            "Epoch 125/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.9038 - mae: 0.6818 - mse: 3.9038 - val_loss: 8.1949 - val_mae: 0.7718 - val_mse: 8.1949\n",
            "Epoch 126/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5623 - mae: 0.6951 - mse: 3.5623 - val_loss: 6.3319 - val_mae: 0.8485 - val_mse: 6.3319\n",
            "Epoch 127/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.7488 - mae: 0.7756 - mse: 6.7488 - val_loss: 9.9463 - val_mae: 0.8384 - val_mse: 9.9463\n",
            "Epoch 128/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.0021 - mae: 0.7151 - mse: 4.0021 - val_loss: 8.5903 - val_mae: 0.9771 - val_mse: 8.5903\n",
            "Epoch 129/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0688 - mae: 0.7702 - mse: 3.0688 - val_loss: 6.7263 - val_mae: 0.7623 - val_mse: 6.7263\n",
            "Epoch 130/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0473 - mae: 0.6935 - mse: 3.0473 - val_loss: 9.4962 - val_mae: 0.7643 - val_mse: 9.4962\n",
            "Epoch 131/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.2922 - mae: 0.6813 - mse: 4.2922 - val_loss: 6.7308 - val_mae: 0.7501 - val_mse: 6.7308\n",
            "Epoch 132/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4732 - mae: 0.6754 - mse: 2.4732 - val_loss: 8.0652 - val_mae: 0.7434 - val_mse: 8.0652\n",
            "Epoch 133/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.1156 - mae: 0.6443 - mse: 2.1156 - val_loss: 7.1698 - val_mae: 0.7709 - val_mse: 7.1698\n",
            "Epoch 134/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.8032 - mae: 0.6906 - mse: 2.8032 - val_loss: 8.1895 - val_mae: 0.7528 - val_mse: 8.1895\n",
            "Epoch 135/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.1487 - mae: 0.6525 - mse: 2.1487 - val_loss: 8.0294 - val_mae: 0.7251 - val_mse: 8.0294\n",
            "Epoch 136/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3052 - mae: 0.6481 - mse: 2.3052 - val_loss: 7.2216 - val_mae: 0.7320 - val_mse: 7.2216\n",
            "Epoch 137/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1672 - mae: 0.6496 - mse: 2.1672 - val_loss: 7.6583 - val_mae: 0.7428 - val_mse: 7.6583\n",
            "Epoch 138/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0105 - mae: 0.6523 - mse: 2.0105 - val_loss: 7.2076 - val_mae: 0.7247 - val_mse: 7.2076\n",
            "Epoch 139/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9212 - mae: 0.6311 - mse: 1.9212 - val_loss: 7.0694 - val_mae: 0.7303 - val_mse: 7.0694\n",
            "Epoch 140/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9996 - mae: 0.6413 - mse: 1.9996 - val_loss: 7.1875 - val_mae: 0.7279 - val_mse: 7.1875\n",
            "Epoch 141/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.2445 - mae: 0.6561 - mse: 2.2445 - val_loss: 7.2167 - val_mae: 0.7271 - val_mse: 7.2167\n",
            "Epoch 142/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8850 - mae: 0.6286 - mse: 1.8850 - val_loss: 7.2593 - val_mae: 0.7188 - val_mse: 7.2593\n",
            "Epoch 143/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8524 - mae: 0.6294 - mse: 1.8524 - val_loss: 6.8961 - val_mae: 0.7083 - val_mse: 6.8961\n",
            "Epoch 144/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8658 - mae: 0.6320 - mse: 1.8658 - val_loss: 7.3379 - val_mae: 0.7423 - val_mse: 7.3379\n",
            "Epoch 145/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9790 - mae: 0.6301 - mse: 1.9790 - val_loss: 7.1507 - val_mae: 0.7129 - val_mse: 7.1507\n",
            "Epoch 146/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8385 - mae: 0.6208 - mse: 1.8385 - val_loss: 7.6514 - val_mae: 0.7250 - val_mse: 7.6514\n",
            "Epoch 147/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.9785 - mae: 0.6464 - mse: 1.9785 - val_loss: 6.8540 - val_mae: 0.7158 - val_mse: 6.8540\n",
            "Epoch 148/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0470 - mae: 0.6306 - mse: 2.0470 - val_loss: 7.6877 - val_mae: 0.7392 - val_mse: 7.6877\n",
            "Epoch 149/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.4223 - mae: 0.6880 - mse: 3.4223 - val_loss: 8.4211 - val_mae: 0.8108 - val_mse: 8.4211\n",
            "Epoch 150/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5676 - mae: 0.7131 - mse: 3.5676 - val_loss: 6.4475 - val_mae: 0.7496 - val_mse: 6.4475\n",
            "Epoch 151/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 15.0339 - mae: 0.8533 - mse: 15.0339 - val_loss: 7.9744 - val_mae: 0.8234 - val_mse: 7.9744\n",
            "Epoch 152/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.7694 - mae: 0.7327 - mse: 8.7694 - val_loss: 6.8667 - val_mae: 0.9572 - val_mse: 6.8667\n",
            "Epoch 153/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9327 - mae: 0.7666 - mse: 2.9327 - val_loss: 7.1077 - val_mae: 0.8282 - val_mse: 7.1077\n",
            "Epoch 154/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0767 - mae: 0.6711 - mse: 2.0767 - val_loss: 6.9158 - val_mae: 0.7217 - val_mse: 6.9158\n",
            "Epoch 155/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7735 - mae: 0.6259 - mse: 1.7735 - val_loss: 7.2248 - val_mae: 0.7220 - val_mse: 7.2248\n",
            "Epoch 156/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7550 - mae: 0.6141 - mse: 1.7550 - val_loss: 6.7757 - val_mae: 0.7055 - val_mse: 6.7757\n",
            "Epoch 157/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9644 - mae: 0.6287 - mse: 1.9644 - val_loss: 7.2818 - val_mae: 0.7295 - val_mse: 7.2818\n",
            "Epoch 158/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8145 - mae: 0.6233 - mse: 1.8145 - val_loss: 6.7721 - val_mae: 0.7055 - val_mse: 6.7721\n",
            "Epoch 159/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9547 - mae: 0.6242 - mse: 1.9547 - val_loss: 7.8976 - val_mae: 0.7199 - val_mse: 7.8976\n",
            "Epoch 160/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8189 - mae: 0.6207 - mse: 1.8189 - val_loss: 7.0938 - val_mae: 0.7044 - val_mse: 7.0938\n",
            "Epoch 161/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7818 - mae: 0.6036 - mse: 1.7818 - val_loss: 7.3377 - val_mae: 0.7203 - val_mse: 7.3377\n",
            "Epoch 162/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6779 - mae: 0.6103 - mse: 1.6779 - val_loss: 6.8383 - val_mae: 0.7175 - val_mse: 6.8383\n",
            "Epoch 163/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8558 - mae: 0.6172 - mse: 1.8558 - val_loss: 7.4898 - val_mae: 0.7142 - val_mse: 7.4898\n",
            "Epoch 164/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9519 - mae: 0.6224 - mse: 1.9519 - val_loss: 7.1021 - val_mae: 0.7154 - val_mse: 7.1021\n",
            "Epoch 165/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8860 - mae: 0.6151 - mse: 1.8860 - val_loss: 7.2606 - val_mae: 0.7033 - val_mse: 7.2606\n",
            "Epoch 166/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7659 - mae: 0.6050 - mse: 1.7659 - val_loss: 7.3211 - val_mae: 0.7381 - val_mse: 7.3211\n",
            "Epoch 167/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.0760 - mae: 0.6896 - mse: 5.0760 - val_loss: 6.1793 - val_mae: 0.9503 - val_mse: 6.1793\n",
            "Epoch 168/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.1181 - mae: 0.7350 - mse: 5.1181 - val_loss: 10.2987 - val_mae: 1.0746 - val_mse: 10.2987\n",
            "Epoch 169/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 19.4541 - mae: 1.0349 - mse: 19.4541 - val_loss: 8.2924 - val_mae: 0.7788 - val_mse: 8.2924\n",
            "Epoch 170/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.8650 - mae: 0.7818 - mse: 9.8650 - val_loss: 7.9064 - val_mae: 0.7417 - val_mse: 7.9064\n",
            "Epoch 171/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.2339 - mae: 0.6516 - mse: 2.2339 - val_loss: 5.6971 - val_mae: 0.7924 - val_mse: 5.6971\n",
            "Epoch 172/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5144 - mae: 0.7204 - mse: 2.5144 - val_loss: 7.4028 - val_mae: 0.7910 - val_mse: 7.4028\n",
            "Epoch 173/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2835 - mae: 0.7096 - mse: 2.2835 - val_loss: 7.3961 - val_mae: 0.7258 - val_mse: 7.3961\n",
            "Epoch 174/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2255 - mae: 0.6578 - mse: 2.2255 - val_loss: 6.7506 - val_mae: 0.7383 - val_mse: 6.7506\n",
            "Epoch 175/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.9327 - mae: 0.6354 - mse: 1.9327 - val_loss: 7.7167 - val_mae: 0.7218 - val_mse: 7.7167\n",
            "Epoch 176/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4433 - mae: 0.6388 - mse: 2.4433 - val_loss: 8.2329 - val_mae: 0.7824 - val_mse: 8.2329\n",
            "Epoch 177/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1332 - mae: 0.6656 - mse: 2.1332 - val_loss: 7.3897 - val_mae: 0.7094 - val_mse: 7.3897\n",
            "Epoch 178/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3224 - mae: 0.6472 - mse: 2.3224 - val_loss: 7.6030 - val_mae: 0.7226 - val_mse: 7.6030\n",
            "Epoch 179/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7330 - mae: 0.6218 - mse: 1.7330 - val_loss: 7.2362 - val_mae: 0.7508 - val_mse: 7.2362\n",
            "Epoch 180/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8291 - mae: 0.6371 - mse: 1.8291 - val_loss: 8.0241 - val_mae: 0.7235 - val_mse: 8.0241\n",
            "Epoch 181/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9048 - mae: 0.6281 - mse: 1.9048 - val_loss: 7.2645 - val_mae: 0.7047 - val_mse: 7.2645\n",
            "Epoch 182/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7322 - mae: 0.6072 - mse: 1.7322 - val_loss: 7.3686 - val_mae: 0.7025 - val_mse: 7.3686\n",
            "Epoch 183/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7829 - mae: 0.6192 - mse: 1.7829 - val_loss: 7.3284 - val_mae: 0.7215 - val_mse: 7.3284\n",
            "Epoch 184/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6757 - mae: 0.6137 - mse: 1.6757 - val_loss: 7.4672 - val_mae: 0.7083 - val_mse: 7.4672\n",
            "Epoch 185/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7102 - mae: 0.6136 - mse: 1.7102 - val_loss: 7.0913 - val_mae: 0.7105 - val_mse: 7.0913\n",
            "Epoch 186/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7265 - mae: 0.6168 - mse: 1.7265 - val_loss: 7.4823 - val_mae: 0.6995 - val_mse: 7.4823\n",
            "Epoch 187/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5987 - mae: 0.5976 - mse: 1.5987 - val_loss: 7.0554 - val_mae: 0.7233 - val_mse: 7.0554\n",
            "Epoch 188/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9530 - mae: 0.6275 - mse: 1.9530 - val_loss: 7.6321 - val_mae: 0.7120 - val_mse: 7.6321\n",
            "Epoch 189/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9493 - mae: 0.6155 - mse: 1.9493 - val_loss: 7.1360 - val_mae: 0.7050 - val_mse: 7.1360\n",
            "Epoch 190/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7967 - mae: 0.6149 - mse: 1.7967 - val_loss: 7.4935 - val_mae: 0.7125 - val_mse: 7.4935\n",
            "Epoch 191/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.6256 - mae: 0.6156 - mse: 1.6256 - val_loss: 6.7588 - val_mae: 0.7087 - val_mse: 6.7588\n",
            "Epoch 192/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.9752 - mae: 0.6245 - mse: 1.9752 - val_loss: 7.6127 - val_mae: 0.6987 - val_mse: 7.6127\n",
            "Epoch 193/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5296 - mae: 0.5968 - mse: 1.5296 - val_loss: 6.1374 - val_mae: 0.7081 - val_mse: 6.1374\n",
            "Epoch 194/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7898 - mae: 0.6100 - mse: 1.7898 - val_loss: 8.7330 - val_mae: 0.7063 - val_mse: 8.7330\n",
            "Epoch 195/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.3536 - mae: 0.6095 - mse: 2.3536 - val_loss: 7.6139 - val_mae: 0.7041 - val_mse: 7.6139\n",
            "Epoch 196/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6995 - mae: 0.6162 - mse: 1.6995 - val_loss: 6.7092 - val_mae: 0.7083 - val_mse: 6.7092\n",
            "Epoch 197/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8934 - mae: 0.6172 - mse: 1.8934 - val_loss: 6.9018 - val_mae: 0.7124 - val_mse: 6.9018\n",
            "Epoch 198/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7873 - mae: 0.6152 - mse: 1.7873 - val_loss: 7.6318 - val_mae: 0.6996 - val_mse: 7.6318\n",
            "Epoch 199/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7242 - mae: 0.6061 - mse: 1.7242 - val_loss: 7.3620 - val_mae: 0.6982 - val_mse: 7.3620\n",
            "Epoch 200/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6692 - mae: 0.6024 - mse: 1.6692 - val_loss: 7.3977 - val_mae: 0.7008 - val_mse: 7.3977\n",
            "Epoch 201/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6429 - mae: 0.6060 - mse: 1.6429 - val_loss: 7.2393 - val_mae: 0.6916 - val_mse: 7.2393\n",
            "Epoch 202/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5304 - mae: 0.5904 - mse: 1.5304 - val_loss: 7.1715 - val_mae: 0.6918 - val_mse: 7.1715\n",
            "Epoch 203/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.6117 - mae: 0.5928 - mse: 1.6117 - val_loss: 7.6022 - val_mae: 0.7085 - val_mse: 7.6022\n",
            "Epoch 204/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5450 - mae: 0.6024 - mse: 1.5450 - val_loss: 7.3648 - val_mae: 0.7296 - val_mse: 7.3648\n",
            "Epoch 205/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6768 - mae: 0.6128 - mse: 1.6768 - val_loss: 7.1980 - val_mae: 0.7045 - val_mse: 7.1980\n",
            "Epoch 206/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4993 - mae: 0.5962 - mse: 1.4993 - val_loss: 7.1313 - val_mae: 0.7502 - val_mse: 7.1313\n",
            "Epoch 207/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.0838 - mae: 0.6265 - mse: 2.0838 - val_loss: 7.5019 - val_mae: 0.6989 - val_mse: 7.5019\n",
            "Epoch 208/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.6653 - mae: 0.6103 - mse: 1.6653 - val_loss: 7.8939 - val_mae: 0.8968 - val_mse: 7.8939\n",
            "Epoch 209/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5689 - mae: 0.7821 - mse: 3.5689 - val_loss: 7.3282 - val_mae: 0.7082 - val_mse: 7.3282\n",
            "Epoch 210/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6151 - mae: 0.6142 - mse: 1.6151 - val_loss: 7.4786 - val_mae: 0.7069 - val_mse: 7.4786\n",
            "Epoch 211/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5949 - mae: 0.6028 - mse: 1.5949 - val_loss: 7.5259 - val_mae: 0.6951 - val_mse: 7.5259\n",
            "Epoch 212/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8491 - mae: 0.5958 - mse: 1.8491 - val_loss: 8.1945 - val_mae: 0.7595 - val_mse: 8.1945\n",
            "Epoch 213/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.8045 - mae: 0.6919 - mse: 2.8045 - val_loss: 9.0509 - val_mae: 0.9507 - val_mse: 9.0509\n",
            "Epoch 214/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 3.2819 - mae: 0.8674 - mse: 3.2819 - val_loss: 10.1116 - val_mae: 0.7729 - val_mse: 10.1116\n",
            "Epoch 215/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5515 - mae: 0.7037 - mse: 3.5515 - val_loss: 7.9072 - val_mae: 0.7158 - val_mse: 7.9072\n",
            "Epoch 216/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5423 - mae: 0.6053 - mse: 1.5423 - val_loss: 7.7202 - val_mae: 0.7022 - val_mse: 7.7202\n",
            "Epoch 217/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4430 - mae: 0.5957 - mse: 1.4430 - val_loss: 7.5387 - val_mae: 0.7021 - val_mse: 7.5387\n",
            "Epoch 218/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5154 - mae: 0.6054 - mse: 1.5154 - val_loss: 7.5491 - val_mae: 0.7062 - val_mse: 7.5491\n",
            "Epoch 219/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.6107 - mae: 0.5874 - mse: 1.6107 - val_loss: 7.2099 - val_mae: 0.6953 - val_mse: 7.2099\n",
            "Epoch 220/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4319 - mae: 0.5791 - mse: 1.4319 - val_loss: 7.9722 - val_mae: 0.7157 - val_mse: 7.9722\n",
            "Epoch 221/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7810 - mae: 0.6130 - mse: 1.7810 - val_loss: 7.1630 - val_mae: 0.7057 - val_mse: 7.1630\n",
            "Epoch 222/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1988 - mae: 0.6232 - mse: 2.1988 - val_loss: 7.7373 - val_mae: 0.7016 - val_mse: 7.7373\n",
            "Epoch 223/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.7402 - mae: 0.7099 - mse: 6.7402 - val_loss: 7.7159 - val_mae: 0.7172 - val_mse: 7.7159\n",
            "Epoch 224/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6371 - mae: 0.6269 - mse: 1.6371 - val_loss: 7.4108 - val_mae: 0.7054 - val_mse: 7.4108\n",
            "Epoch 225/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.5707 - mae: 0.5968 - mse: 1.5707 - val_loss: 7.6183 - val_mae: 0.6977 - val_mse: 7.6183\n",
            "Epoch 226/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4035 - mae: 0.5857 - mse: 1.4035 - val_loss: 7.7308 - val_mae: 0.6949 - val_mse: 7.7308\n",
            "Epoch 227/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3820 - mae: 0.5776 - mse: 1.3820 - val_loss: 7.6597 - val_mae: 0.6939 - val_mse: 7.6597\n",
            "Epoch 228/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4961 - mae: 0.5895 - mse: 1.4961 - val_loss: 7.8339 - val_mae: 0.7003 - val_mse: 7.8339\n",
            "Epoch 229/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5082 - mae: 0.5880 - mse: 1.5082 - val_loss: 7.7721 - val_mae: 0.7015 - val_mse: 7.7721\n",
            "Epoch 230/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4909 - mae: 0.5879 - mse: 1.4909 - val_loss: 7.5541 - val_mae: 0.7393 - val_mse: 7.5541\n",
            "Epoch 231/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5595 - mae: 0.6071 - mse: 1.5595 - val_loss: 8.4735 - val_mae: 0.7257 - val_mse: 8.4735\n",
            "Epoch 232/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5197 - mae: 0.6983 - mse: 3.5197 - val_loss: 8.7285 - val_mae: 0.8902 - val_mse: 8.7285\n",
            "Epoch 233/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 4.6455 - mae: 0.7781 - mse: 4.6455 - val_loss: 8.6594 - val_mae: 0.9309 - val_mse: 8.6594\n",
            "Epoch 234/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 3.2993 - mae: 0.7410 - mse: 3.2993 - val_loss: 7.6027 - val_mae: 0.7248 - val_mse: 7.6027\n",
            "Epoch 235/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.6022 - mae: 0.6067 - mse: 1.6022 - val_loss: 9.2703 - val_mae: 0.7684 - val_mse: 9.2703\n",
            "Epoch 236/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6567 - mae: 0.6650 - mse: 2.6567 - val_loss: 7.1280 - val_mae: 0.7792 - val_mse: 7.1280\n",
            "Epoch 237/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6053 - mae: 0.6769 - mse: 3.6053 - val_loss: 7.8491 - val_mae: 0.7066 - val_mse: 7.8491\n",
            "Epoch 238/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9572 - mae: 0.5997 - mse: 1.9572 - val_loss: 7.5291 - val_mae: 0.7395 - val_mse: 7.5291\n",
            "Epoch 239/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9989 - mae: 0.6300 - mse: 1.9989 - val_loss: 7.9203 - val_mae: 0.7089 - val_mse: 7.9203\n",
            "Epoch 240/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.6740 - mae: 0.5998 - mse: 1.6740 - val_loss: 7.5754 - val_mae: 0.7131 - val_mse: 7.5754\n",
            "Epoch 241/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4851 - mae: 0.5927 - mse: 1.4851 - val_loss: 7.7758 - val_mae: 0.6939 - val_mse: 7.7758\n",
            "Epoch 242/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4747 - mae: 0.5789 - mse: 1.4747 - val_loss: 7.6780 - val_mae: 0.7059 - val_mse: 7.6780\n",
            "Epoch 243/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4586 - mae: 0.5831 - mse: 1.4586 - val_loss: 7.9295 - val_mae: 0.6993 - val_mse: 7.9295\n",
            "Epoch 244/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4223 - mae: 0.5842 - mse: 1.4223 - val_loss: 7.9157 - val_mae: 0.7057 - val_mse: 7.9157\n",
            "Epoch 245/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3864 - mae: 0.5844 - mse: 1.3864 - val_loss: 7.7654 - val_mae: 0.6953 - val_mse: 7.7654\n",
            "Epoch 246/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.5444 - mae: 0.5940 - mse: 1.5444 - val_loss: 7.6598 - val_mae: 0.6970 - val_mse: 7.6598\n",
            "Epoch 247/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4040 - mae: 0.5768 - mse: 1.4040 - val_loss: 7.7954 - val_mae: 0.7049 - val_mse: 7.7954\n",
            "Epoch 248/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4283 - mae: 0.5852 - mse: 1.4283 - val_loss: 7.2607 - val_mae: 0.6961 - val_mse: 7.2607\n",
            "Epoch 249/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4734 - mae: 0.5865 - mse: 1.4734 - val_loss: 8.1164 - val_mae: 0.7138 - val_mse: 8.1164\n",
            "Epoch 250/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4618 - mae: 0.5907 - mse: 1.4618 - val_loss: 7.2552 - val_mae: 0.6962 - val_mse: 7.2552\n",
            "Epoch 251/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4895 - mae: 0.5936 - mse: 1.4895 - val_loss: 7.9088 - val_mae: 0.6970 - val_mse: 7.9088\n",
            "Epoch 252/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4306 - mae: 0.5789 - mse: 1.4306 - val_loss: 7.5509 - val_mae: 0.7012 - val_mse: 7.5509\n",
            "Epoch 253/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4364 - mae: 0.5842 - mse: 1.4364 - val_loss: 8.1277 - val_mae: 0.7127 - val_mse: 8.1277\n",
            "Epoch 254/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8717 - mae: 0.6099 - mse: 1.8717 - val_loss: 7.3338 - val_mae: 0.7060 - val_mse: 7.3338\n",
            "Epoch 255/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.8394 - mae: 0.6319 - mse: 2.8394 - val_loss: 8.0984 - val_mae: 0.7406 - val_mse: 8.0984\n",
            "Epoch 256/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.0139 - mae: 0.6829 - mse: 5.0139 - val_loss: 8.8750 - val_mae: 0.7823 - val_mse: 8.8750\n",
            "Epoch 257/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1231 - mae: 0.6443 - mse: 2.1231 - val_loss: 7.1000 - val_mae: 0.7855 - val_mse: 7.1000\n",
            "Epoch 258/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1217 - mae: 0.6426 - mse: 2.1217 - val_loss: 7.5222 - val_mae: 0.6997 - val_mse: 7.5222\n",
            "Epoch 259/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6429 - mae: 0.5962 - mse: 1.6429 - val_loss: 7.7662 - val_mae: 0.6997 - val_mse: 7.7662\n",
            "Epoch 260/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6113 - mae: 0.5961 - mse: 1.6113 - val_loss: 7.6175 - val_mae: 0.7017 - val_mse: 7.6175\n",
            "Epoch 261/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4815 - mae: 0.5785 - mse: 1.4815 - val_loss: 7.8030 - val_mae: 0.6964 - val_mse: 7.8030\n",
            "Epoch 262/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.2898 - mae: 0.5665 - mse: 1.2898 - val_loss: 7.4911 - val_mae: 0.6914 - val_mse: 7.4911\n",
            "Epoch 263/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.3642 - mae: 0.5731 - mse: 1.3642 - val_loss: 7.5157 - val_mae: 0.6897 - val_mse: 7.5157\n",
            "Epoch 264/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.2387 - mae: 0.5615 - mse: 1.2387 - val_loss: 7.6525 - val_mae: 0.6987 - val_mse: 7.6525\n",
            "Epoch 265/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3551 - mae: 0.5768 - mse: 1.3551 - val_loss: 7.8106 - val_mae: 0.6967 - val_mse: 7.8106\n",
            "Epoch 266/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2304 - mae: 0.5679 - mse: 1.2304 - val_loss: 7.4728 - val_mae: 0.7234 - val_mse: 7.4728\n",
            "Epoch 267/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4127 - mae: 0.5925 - mse: 1.4127 - val_loss: 8.0060 - val_mae: 0.7360 - val_mse: 8.0060\n",
            "Epoch 268/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7419 - mae: 0.6163 - mse: 1.7419 - val_loss: 7.2431 - val_mae: 0.6922 - val_mse: 7.2431\n",
            "Epoch 269/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7976 - mae: 0.5932 - mse: 1.7976 - val_loss: 7.7426 - val_mae: 0.7124 - val_mse: 7.7426\n",
            "Epoch 270/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0182 - mae: 0.6125 - mse: 2.0182 - val_loss: 8.3503 - val_mae: 0.7455 - val_mse: 8.3503\n",
            "Epoch 271/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.9653 - mae: 0.6559 - mse: 2.9653 - val_loss: 8.3835 - val_mae: 1.1219 - val_mse: 8.3835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "oj46uIxbCz42",
        "outputId": "568a4447-93da-45ae-969c-b817d1fa7315"
      },
      "source": [
        "# 테스트 세트에 대한 성능 평가\n",
        "print(\"Accuracy : \", model2.evaluate(X_test_scaled, y_test)[1])\n",
        "\n",
        "y_vloss = history2.history['val_loss'] # 테스트 세트 손실\n",
        "y_loss = history2.history['loss'] # 학습 세트의 정확도\n",
        "    \n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, '.', c='red', markersize=3, label=\"val_loss\")\n",
        "plt.plot(x_len, y_loss, '.', c='blue',  markersize=3,label = 'loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 0s 1ms/step - loss: 18.9102 - mae: 1.1084 - mse: 18.9102\n",
            "Accuracy :  1.1084024906158447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9p_dgq1SGCH",
        "outputId": "f90e3657-c497-44bc-f191-f84ce283a01a"
      },
      "source": [
        "# 자동 종료를 위해 추가\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "model4 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model4.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "history4 = model4.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "57/57 [==============================] - 1s 9ms/step - loss: 255.6876 - mae: 7.1183 - val_loss: 147.6676 - val_mae: 4.0916\n",
            "Epoch 2/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 197.2062 - mae: 4.2776 - val_loss: 96.7441 - val_mae: 3.0850\n",
            "Epoch 3/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 144.7659 - mae: 3.3301 - val_loss: 53.3903 - val_mae: 2.7151\n",
            "Epoch 4/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 61.1559 - mae: 2.7262 - val_loss: 36.0294 - val_mae: 2.5542\n",
            "Epoch 5/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 82.0393 - mae: 2.6606 - val_loss: 30.5870 - val_mae: 1.9752\n",
            "Epoch 6/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 63.5874 - mae: 2.0208 - val_loss: 23.9278 - val_mae: 1.8336\n",
            "Epoch 7/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 29.0822 - mae: 1.7484 - val_loss: 21.0933 - val_mae: 1.5571\n",
            "Epoch 8/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 32.0605 - mae: 1.6019 - val_loss: 17.3152 - val_mae: 1.4880\n",
            "Epoch 9/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 38.2058 - mae: 1.4942 - val_loss: 15.0685 - val_mae: 1.3364\n",
            "Epoch 10/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 32.1637 - mae: 1.3278 - val_loss: 14.6654 - val_mae: 1.3016\n",
            "Epoch 11/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.3502 - mae: 1.2597 - val_loss: 14.3924 - val_mae: 1.3932\n",
            "Epoch 12/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.8871 - mae: 1.2931 - val_loss: 15.1510 - val_mae: 1.7038\n",
            "Epoch 13/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.4582 - mae: 1.4160 - val_loss: 12.8254 - val_mae: 1.3088\n",
            "Epoch 14/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 46.5845 - mae: 1.3590 - val_loss: 10.6805 - val_mae: 1.1528\n",
            "Epoch 15/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.6687 - mae: 1.1844 - val_loss: 11.7844 - val_mae: 1.1570\n",
            "Epoch 16/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.4254 - mae: 1.1478 - val_loss: 10.5981 - val_mae: 1.2931\n",
            "Epoch 17/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 27.8218 - mae: 1.2020 - val_loss: 10.2024 - val_mae: 1.0919\n",
            "Epoch 18/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.6681 - mae: 1.1149 - val_loss: 10.4959 - val_mae: 1.1452\n",
            "Epoch 19/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 53.6480 - mae: 1.2523 - val_loss: 8.7481 - val_mae: 1.1017\n",
            "Epoch 20/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.8385 - mae: 1.1633 - val_loss: 10.3815 - val_mae: 1.1679\n",
            "Epoch 21/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 31.4626 - mae: 1.1332 - val_loss: 10.0237 - val_mae: 1.1794\n",
            "Epoch 22/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.7700 - mae: 1.0682 - val_loss: 9.4280 - val_mae: 1.2403\n",
            "Epoch 23/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1364 - mae: 1.1378 - val_loss: 9.3458 - val_mae: 1.0623\n",
            "Epoch 24/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.1968 - mae: 1.0521 - val_loss: 8.9207 - val_mae: 1.0466\n",
            "Epoch 25/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 33.7115 - mae: 1.0597 - val_loss: 9.5420 - val_mae: 1.1735\n",
            "Epoch 26/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.0531 - mae: 1.2891 - val_loss: 8.9943 - val_mae: 1.1928\n",
            "Epoch 27/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 40.7286 - mae: 1.2414 - val_loss: 11.2425 - val_mae: 1.0388\n",
            "Epoch 28/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 34.1391 - mae: 1.2146 - val_loss: 10.5878 - val_mae: 1.2425\n",
            "Epoch 29/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.4686 - mae: 1.0577 - val_loss: 9.1897 - val_mae: 1.0506\n",
            "Epoch 30/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.3564 - mae: 1.0446 - val_loss: 8.4545 - val_mae: 0.9898\n",
            "Epoch 31/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.4464 - mae: 0.9251 - val_loss: 9.4786 - val_mae: 1.0050\n",
            "Epoch 32/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.9292 - mae: 0.9600 - val_loss: 8.6016 - val_mae: 0.9500\n",
            "Epoch 33/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.1247 - mae: 0.9102 - val_loss: 10.4818 - val_mae: 1.0626\n",
            "Epoch 34/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.4792 - mae: 0.9285 - val_loss: 9.8540 - val_mae: 1.0544\n",
            "Epoch 35/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.7219 - mae: 0.9219 - val_loss: 10.6772 - val_mae: 0.9753\n",
            "Epoch 36/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.9508 - mae: 0.8905 - val_loss: 9.8494 - val_mae: 0.9934\n",
            "Epoch 37/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 11.4587 - mae: 0.9320 - val_loss: 8.8461 - val_mae: 0.9424\n",
            "Epoch 38/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.8131 - mae: 0.9386 - val_loss: 8.7442 - val_mae: 0.9211\n",
            "Epoch 39/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.7522 - mae: 0.8573 - val_loss: 11.2291 - val_mae: 0.9915\n",
            "Epoch 40/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.3455 - mae: 0.9392 - val_loss: 8.6565 - val_mae: 0.9176\n",
            "Epoch 41/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 22.4193 - mae: 0.9198 - val_loss: 9.2870 - val_mae: 0.9218\n",
            "Epoch 42/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 16.2867 - mae: 0.8921 - val_loss: 8.4383 - val_mae: 0.9017\n",
            "Epoch 43/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2048 - mae: 0.8364 - val_loss: 10.3179 - val_mae: 1.0084\n",
            "Epoch 44/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.3881 - mae: 0.8560 - val_loss: 9.3209 - val_mae: 0.9376\n",
            "Epoch 45/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.6198 - mae: 0.8413 - val_loss: 11.2907 - val_mae: 1.0189\n",
            "Epoch 46/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.2318 - mae: 0.9137 - val_loss: 8.9923 - val_mae: 0.9454\n",
            "Epoch 47/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.6665 - mae: 1.0473 - val_loss: 10.7280 - val_mae: 1.0393\n",
            "Epoch 48/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.9624 - mae: 0.8544 - val_loss: 8.3876 - val_mae: 0.9667\n",
            "Epoch 49/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.6318 - mae: 0.9095 - val_loss: 7.7734 - val_mae: 0.8636\n",
            "Epoch 50/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.7028 - mae: 0.7861 - val_loss: 10.5837 - val_mae: 0.9378\n",
            "Epoch 51/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.3537 - mae: 1.1986 - val_loss: 9.3237 - val_mae: 0.9273\n",
            "Epoch 52/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.9015 - mae: 0.8462 - val_loss: 9.8200 - val_mae: 0.9424\n",
            "Epoch 53/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1145 - mae: 0.8553 - val_loss: 8.0941 - val_mae: 0.8854\n",
            "Epoch 54/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2860 - mae: 0.8384 - val_loss: 13.0353 - val_mae: 1.0472\n",
            "Epoch 55/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.5668 - mae: 0.9672 - val_loss: 8.5878 - val_mae: 0.9686\n",
            "Epoch 56/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1230 - mae: 0.8884 - val_loss: 8.6463 - val_mae: 0.8638\n",
            "Epoch 57/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.1751 - mae: 0.7980 - val_loss: 9.1227 - val_mae: 0.8778\n",
            "Epoch 58/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2403 - mae: 0.8049 - val_loss: 10.1359 - val_mae: 0.8946\n",
            "Epoch 59/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.7543 - mae: 0.7956 - val_loss: 7.8653 - val_mae: 0.9239\n",
            "Epoch 60/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.6770 - mae: 0.9829 - val_loss: 10.2854 - val_mae: 0.8625\n",
            "Epoch 61/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.5332 - mae: 0.9048 - val_loss: 10.1940 - val_mae: 0.8784\n",
            "Epoch 62/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.1680 - mae: 0.8727 - val_loss: 9.7468 - val_mae: 0.9718\n",
            "Epoch 63/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.6218 - mae: 0.8417 - val_loss: 8.4482 - val_mae: 0.8420\n",
            "Epoch 64/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.0743 - mae: 0.8062 - val_loss: 8.3949 - val_mae: 0.8509\n",
            "Epoch 65/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.3226 - mae: 0.7573 - val_loss: 7.8326 - val_mae: 0.8532\n",
            "Epoch 66/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2948 - mae: 0.7989 - val_loss: 9.2716 - val_mae: 0.8491\n",
            "Epoch 67/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.8877 - mae: 0.8072 - val_loss: 7.6944 - val_mae: 0.8343\n",
            "Epoch 68/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.3516 - mae: 0.7812 - val_loss: 7.8508 - val_mae: 0.8212\n",
            "Epoch 69/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8340 - mae: 0.7587 - val_loss: 7.4490 - val_mae: 0.8733\n",
            "Epoch 70/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.5576 - mae: 0.7826 - val_loss: 8.4761 - val_mae: 0.8477\n",
            "Epoch 71/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.4244 - mae: 0.7452 - val_loss: 7.3773 - val_mae: 0.8126\n",
            "Epoch 72/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2324 - mae: 0.7852 - val_loss: 8.6643 - val_mae: 0.8217\n",
            "Epoch 73/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3446 - mae: 0.7341 - val_loss: 8.2853 - val_mae: 1.0260\n",
            "Epoch 74/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.8046 - mae: 1.0136 - val_loss: 8.1213 - val_mae: 0.8690\n",
            "Epoch 75/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.0012 - mae: 0.8251 - val_loss: 8.3275 - val_mae: 0.8358\n",
            "Epoch 76/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.9721 - mae: 0.8660 - val_loss: 6.4877 - val_mae: 1.0080\n",
            "Epoch 77/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.0623 - mae: 0.8550 - val_loss: 8.1080 - val_mae: 0.8665\n",
            "Epoch 78/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.9535 - mae: 0.7518 - val_loss: 7.9084 - val_mae: 0.8178\n",
            "Epoch 79/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3492 - mae: 0.7549 - val_loss: 7.9803 - val_mae: 0.8159\n",
            "Epoch 80/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8463 - mae: 0.7637 - val_loss: 7.8829 - val_mae: 0.8074\n",
            "Epoch 81/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7296 - mae: 0.7130 - val_loss: 7.6698 - val_mae: 0.8163\n",
            "Epoch 82/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2028 - mae: 0.7361 - val_loss: 8.1129 - val_mae: 0.8164\n",
            "Epoch 83/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.9769 - mae: 0.7235 - val_loss: 8.3554 - val_mae: 0.8716\n",
            "Epoch 84/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8753 - mae: 0.7642 - val_loss: 7.7784 - val_mae: 0.8025\n",
            "Epoch 85/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2727 - mae: 0.7767 - val_loss: 10.9521 - val_mae: 0.8385\n",
            "Epoch 86/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.6194 - mae: 0.7820 - val_loss: 6.4958 - val_mae: 0.7963\n",
            "Epoch 87/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9412 - mae: 0.7250 - val_loss: 8.0429 - val_mae: 0.8939\n",
            "Epoch 88/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.7768 - mae: 0.8774 - val_loss: 7.6893 - val_mae: 0.8315\n",
            "Epoch 89/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.9849 - mae: 0.8329 - val_loss: 6.4447 - val_mae: 0.8318\n",
            "Epoch 90/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.0903 - mae: 0.8330 - val_loss: 8.7538 - val_mae: 1.2878\n",
            "Epoch 91/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.0285 - mae: 1.0293 - val_loss: 11.0451 - val_mae: 0.9501\n",
            "Epoch 92/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2488 - mae: 0.8082 - val_loss: 14.2063 - val_mae: 1.1990\n",
            "Epoch 93/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.2829 - mae: 1.0772 - val_loss: 7.7204 - val_mae: 0.9210\n",
            "Epoch 94/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.4674 - mae: 0.7936 - val_loss: 7.2526 - val_mae: 0.7961\n",
            "Epoch 95/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3541 - mae: 0.7337 - val_loss: 7.6634 - val_mae: 0.7968\n",
            "Epoch 96/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7359 - mae: 0.7124 - val_loss: 7.3968 - val_mae: 0.7955\n",
            "Epoch 97/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9859 - mae: 0.7325 - val_loss: 7.7386 - val_mae: 0.7837\n",
            "Epoch 98/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7297 - mae: 0.7073 - val_loss: 6.9705 - val_mae: 0.7894\n",
            "Epoch 99/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7764 - mae: 0.7114 - val_loss: 7.1632 - val_mae: 0.7787\n",
            "Epoch 100/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.5946 - mae: 0.6874 - val_loss: 7.4516 - val_mae: 0.7890\n",
            "Epoch 101/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4264 - mae: 0.6942 - val_loss: 6.9991 - val_mae: 0.7866\n",
            "Epoch 102/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.5994 - mae: 0.7028 - val_loss: 7.1911 - val_mae: 0.7731\n",
            "Epoch 103/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4721 - mae: 0.6932 - val_loss: 7.3720 - val_mae: 0.7856\n",
            "Epoch 104/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.6893 - mae: 0.7004 - val_loss: 6.9684 - val_mae: 0.7677\n",
            "Epoch 105/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.6339 - mae: 0.7121 - val_loss: 7.1589 - val_mae: 0.7688\n",
            "Epoch 106/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3981 - mae: 0.6847 - val_loss: 6.8812 - val_mae: 0.7678\n",
            "Epoch 107/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4945 - mae: 0.6832 - val_loss: 7.6824 - val_mae: 0.7869\n",
            "Epoch 108/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.5956 - mae: 0.7099 - val_loss: 6.8577 - val_mae: 0.7663\n",
            "Epoch 109/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3066 - mae: 0.6712 - val_loss: 6.7151 - val_mae: 0.7560\n",
            "Epoch 110/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4554 - mae: 0.6836 - val_loss: 7.3436 - val_mae: 0.7862\n",
            "Epoch 111/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4482 - mae: 0.6951 - val_loss: 6.8268 - val_mae: 0.7631\n",
            "Epoch 112/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4089 - mae: 0.6910 - val_loss: 6.8024 - val_mae: 0.7917\n",
            "Epoch 113/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3623 - mae: 0.7052 - val_loss: 7.0797 - val_mae: 0.7889\n",
            "Epoch 114/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4025 - mae: 0.6916 - val_loss: 6.6673 - val_mae: 0.7650\n",
            "Epoch 115/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8802 - mae: 0.6975 - val_loss: 6.7727 - val_mae: 0.7836\n",
            "Epoch 116/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.5464 - mae: 0.6960 - val_loss: 6.8760 - val_mae: 0.7677\n",
            "Epoch 117/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5866 - mae: 0.7014 - val_loss: 7.1119 - val_mae: 0.7679\n",
            "Epoch 118/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4257 - mae: 0.6849 - val_loss: 6.7254 - val_mae: 0.7459\n",
            "Epoch 119/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5224 - mae: 0.6889 - val_loss: 7.1029 - val_mae: 0.7501\n",
            "Epoch 120/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1557 - mae: 0.6527 - val_loss: 7.4033 - val_mae: 0.8614\n",
            "Epoch 121/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8372 - mae: 0.7114 - val_loss: 6.6240 - val_mae: 0.8158\n",
            "Epoch 122/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.0183 - mae: 0.7858 - val_loss: 8.6091 - val_mae: 0.9139\n",
            "Epoch 123/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.7088 - mae: 0.8050 - val_loss: 6.4528 - val_mae: 0.7812\n",
            "Epoch 124/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2430 - mae: 0.7433 - val_loss: 6.9270 - val_mae: 0.7549\n",
            "Epoch 125/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9200 - mae: 0.6920 - val_loss: 7.0903 - val_mae: 0.8273\n",
            "Epoch 126/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7300 - mae: 0.7485 - val_loss: 6.4436 - val_mae: 0.7677\n",
            "Epoch 127/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3120 - mae: 0.6855 - val_loss: 7.1788 - val_mae: 0.7562\n",
            "Epoch 128/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2977 - mae: 0.6777 - val_loss: 7.5710 - val_mae: 0.7775\n",
            "Epoch 129/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2884 - mae: 0.6683 - val_loss: 6.7611 - val_mae: 0.7563\n",
            "Epoch 130/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4303 - mae: 0.6960 - val_loss: 6.8622 - val_mae: 0.7409\n",
            "Epoch 131/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3455 - mae: 0.6681 - val_loss: 7.9127 - val_mae: 0.7655\n",
            "Epoch 132/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1849 - mae: 0.6640 - val_loss: 7.0481 - val_mae: 0.7575\n",
            "Epoch 133/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1439 - mae: 0.6590 - val_loss: 6.6098 - val_mae: 0.7519\n",
            "Epoch 134/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3346 - mae: 0.6919 - val_loss: 7.3883 - val_mae: 0.7804\n",
            "Epoch 135/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3933 - mae: 0.6722 - val_loss: 7.4733 - val_mae: 0.7518\n",
            "Epoch 136/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.5052 - mae: 0.6749 - val_loss: 7.4411 - val_mae: 0.7508\n",
            "Epoch 137/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2982 - mae: 0.6733 - val_loss: 7.7216 - val_mae: 0.8378\n",
            "Epoch 138/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4788 - mae: 0.7102 - val_loss: 6.3796 - val_mae: 0.7427\n",
            "Epoch 139/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2124 - mae: 0.6559 - val_loss: 6.8371 - val_mae: 0.7954\n",
            "Epoch 140/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.8474 - mae: 0.7086 - val_loss: 6.2677 - val_mae: 0.7490\n",
            "Epoch 141/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4612 - mae: 0.7002 - val_loss: 6.6983 - val_mae: 0.7404\n",
            "Epoch 142/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2320 - mae: 0.6543 - val_loss: 6.0644 - val_mae: 0.7379\n",
            "Epoch 143/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1925 - mae: 0.6642 - val_loss: 6.4043 - val_mae: 0.7393\n",
            "Epoch 144/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2564 - mae: 0.6870 - val_loss: 7.1343 - val_mae: 0.7380\n",
            "Epoch 145/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2775 - mae: 0.6543 - val_loss: 6.7714 - val_mae: 0.7354\n",
            "Epoch 146/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3217 - mae: 0.6666 - val_loss: 6.2590 - val_mae: 0.7448\n",
            "Epoch 147/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2355 - mae: 0.6703 - val_loss: 6.7866 - val_mae: 0.7528\n",
            "Epoch 148/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.0126 - mae: 0.7322 - val_loss: 6.5991 - val_mae: 0.8117\n",
            "Epoch 149/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.9808 - mae: 0.9485 - val_loss: 12.5159 - val_mae: 1.1103\n",
            "Epoch 150/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 13.1599 - mae: 1.0452 - val_loss: 8.1224 - val_mae: 0.7721\n",
            "Epoch 151/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 19.6393 - mae: 0.9763 - val_loss: 7.7027 - val_mae: 0.7581\n",
            "Epoch 152/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.2465 - mae: 0.7093 - val_loss: 7.8585 - val_mae: 0.8949\n",
            "Epoch 153/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7078 - mae: 0.7224 - val_loss: 7.0487 - val_mae: 0.8278\n",
            "Epoch 154/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2129 - mae: 0.6817 - val_loss: 6.9255 - val_mae: 0.7334\n",
            "Epoch 155/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0179 - mae: 0.6521 - val_loss: 7.3795 - val_mae: 0.7445\n",
            "Epoch 156/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9749 - mae: 0.6370 - val_loss: 6.5923 - val_mae: 0.7347\n",
            "Epoch 157/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2614 - mae: 0.6569 - val_loss: 6.5857 - val_mae: 0.7219\n",
            "Epoch 158/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0779 - mae: 0.6602 - val_loss: 6.7775 - val_mae: 0.7269\n",
            "Epoch 159/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2060 - mae: 0.6742 - val_loss: 6.9055 - val_mae: 0.7380\n",
            "Epoch 160/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0786 - mae: 0.6482 - val_loss: 6.7379 - val_mae: 0.7350\n",
            "Epoch 161/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9649 - mae: 0.6355 - val_loss: 6.7899 - val_mae: 0.7297\n",
            "Epoch 162/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9669 - mae: 0.6390 - val_loss: 6.1401 - val_mae: 0.7142\n",
            "Epoch 163/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0261 - mae: 0.6405 - val_loss: 6.8832 - val_mae: 0.7278\n",
            "Epoch 164/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1839 - mae: 0.6522 - val_loss: 6.4799 - val_mae: 0.7206\n",
            "Epoch 165/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0594 - mae: 0.6381 - val_loss: 6.8250 - val_mae: 0.7278\n",
            "Epoch 166/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0153 - mae: 0.6379 - val_loss: 6.2196 - val_mae: 0.7181\n",
            "Epoch 167/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0021 - mae: 0.6495 - val_loss: 6.4055 - val_mae: 0.7471\n",
            "Epoch 168/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1202 - mae: 0.6538 - val_loss: 6.7078 - val_mae: 0.7227\n",
            "Epoch 169/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9393 - mae: 0.6410 - val_loss: 6.5203 - val_mae: 0.7547\n",
            "Epoch 170/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0000 - mae: 0.6572 - val_loss: 6.9425 - val_mae: 0.7368\n",
            "Epoch 171/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9655 - mae: 0.6429 - val_loss: 6.0374 - val_mae: 0.7367\n",
            "Epoch 172/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8878 - mae: 0.6399 - val_loss: 6.6997 - val_mae: 0.7229\n",
            "Epoch 173/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1039 - mae: 0.6621 - val_loss: 6.7576 - val_mae: 0.7237\n",
            "Epoch 174/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0684 - mae: 0.6527 - val_loss: 6.6287 - val_mae: 0.7203\n",
            "Epoch 175/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1130 - mae: 0.6485 - val_loss: 6.3902 - val_mae: 0.7233\n",
            "Epoch 176/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7780 - mae: 0.6297 - val_loss: 6.7226 - val_mae: 0.7176\n",
            "Epoch 177/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2396 - mae: 0.6605 - val_loss: 6.8966 - val_mae: 0.7375\n",
            "Epoch 178/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0557 - mae: 0.6627 - val_loss: 6.7873 - val_mae: 0.7368\n",
            "Epoch 179/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8620 - mae: 0.6338 - val_loss: 6.2207 - val_mae: 0.7127\n",
            "Epoch 180/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9782 - mae: 0.6414 - val_loss: 8.0930 - val_mae: 0.7344\n",
            "Epoch 181/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1344 - mae: 0.6601 - val_loss: 7.3284 - val_mae: 0.7443\n",
            "Epoch 182/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1120 - mae: 0.6520 - val_loss: 5.3951 - val_mae: 0.7222\n",
            "Epoch 183/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0233 - mae: 0.6435 - val_loss: 6.1105 - val_mae: 0.7441\n",
            "Epoch 184/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9187 - mae: 0.6351 - val_loss: 6.1957 - val_mae: 0.7607\n",
            "Epoch 185/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8385 - mae: 0.6390 - val_loss: 6.1034 - val_mae: 0.7029\n",
            "Epoch 186/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8277 - mae: 0.6215 - val_loss: 5.9623 - val_mae: 0.7281\n",
            "Epoch 187/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9264 - mae: 0.6497 - val_loss: 5.8480 - val_mae: 0.8274\n",
            "Epoch 188/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.5394 - mae: 0.7389 - val_loss: 6.5157 - val_mae: 0.7731\n",
            "Epoch 189/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.8432 - mae: 0.7533 - val_loss: 6.2584 - val_mae: 0.7293\n",
            "Epoch 190/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8275 - mae: 0.6617 - val_loss: 7.2989 - val_mae: 0.7583\n",
            "Epoch 191/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 14.5625 - mae: 0.8639 - val_loss: 5.5177 - val_mae: 1.1762\n",
            "Epoch 192/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1272 - mae: 1.0340 - val_loss: 17.0906 - val_mae: 0.8342\n",
            "Epoch 193/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.6770 - mae: 0.7748 - val_loss: 6.2651 - val_mae: 0.8108\n",
            "Epoch 194/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.6910 - mae: 0.7172 - val_loss: 6.8360 - val_mae: 0.7160\n",
            "Epoch 195/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0507 - mae: 0.6319 - val_loss: 5.9159 - val_mae: 0.7227\n",
            "Epoch 196/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.0682 - mae: 0.7040 - val_loss: 6.2315 - val_mae: 0.7126\n",
            "Epoch 197/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1022 - mae: 0.6388 - val_loss: 6.4078 - val_mae: 0.7236\n",
            "Epoch 198/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8512 - mae: 0.6317 - val_loss: 6.4978 - val_mae: 0.7074\n",
            "Epoch 199/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7973 - mae: 0.6210 - val_loss: 5.9563 - val_mae: 0.7152\n",
            "Epoch 200/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8722 - mae: 0.6266 - val_loss: 6.7138 - val_mae: 0.7188\n",
            "Epoch 201/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8640 - mae: 0.6334 - val_loss: 6.1605 - val_mae: 0.7197\n",
            "Epoch 202/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6525 - mae: 0.6127 - val_loss: 6.3421 - val_mae: 0.7034\n",
            "Epoch 203/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7824 - mae: 0.6113 - val_loss: 6.3273 - val_mae: 0.7236\n",
            "Epoch 204/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7385 - mae: 0.6248 - val_loss: 6.5035 - val_mae: 0.7583\n",
            "Epoch 205/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8138 - mae: 0.6353 - val_loss: 6.0618 - val_mae: 0.7032\n",
            "Epoch 206/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6976 - mae: 0.6191 - val_loss: 6.4415 - val_mae: 0.7163\n",
            "Epoch 207/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6352 - mae: 0.6131 - val_loss: 6.1187 - val_mae: 0.7312\n",
            "Epoch 208/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8023 - mae: 0.6383 - val_loss: 6.2447 - val_mae: 0.7033\n",
            "Epoch 209/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8584 - mae: 0.6215 - val_loss: 6.2725 - val_mae: 0.7144\n",
            "Epoch 210/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8015 - mae: 0.6383 - val_loss: 6.4406 - val_mae: 0.7442\n",
            "Epoch 211/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7638 - mae: 0.6245 - val_loss: 6.4119 - val_mae: 0.7167\n",
            "Epoch 212/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7405 - mae: 0.6318 - val_loss: 6.1592 - val_mae: 0.6986\n",
            "Epoch 213/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8185 - mae: 0.6171 - val_loss: 6.3116 - val_mae: 0.7136\n",
            "Epoch 214/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9456 - mae: 0.6326 - val_loss: 6.0647 - val_mae: 0.6974\n",
            "Epoch 215/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5818 - mae: 0.6095 - val_loss: 6.1629 - val_mae: 0.7150\n",
            "Epoch 216/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6477 - mae: 0.6108 - val_loss: 5.9025 - val_mae: 0.7081\n",
            "Epoch 217/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6119 - mae: 0.6067 - val_loss: 6.0776 - val_mae: 0.7123\n",
            "Epoch 218/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6432 - mae: 0.6119 - val_loss: 5.9639 - val_mae: 0.6963\n",
            "Epoch 219/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6093 - mae: 0.6077 - val_loss: 6.4479 - val_mae: 0.7073\n",
            "Epoch 220/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7116 - mae: 0.6169 - val_loss: 6.1106 - val_mae: 0.7372\n",
            "Epoch 221/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8725 - mae: 0.6388 - val_loss: 6.3220 - val_mae: 0.6991\n",
            "Epoch 222/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8682 - mae: 0.6293 - val_loss: 6.4454 - val_mae: 0.7207\n",
            "Epoch 223/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1772 - mae: 0.6463 - val_loss: 6.2816 - val_mae: 0.6979\n",
            "Epoch 224/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7048 - mae: 0.6243 - val_loss: 6.7843 - val_mae: 0.7014\n",
            "Epoch 225/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3569 - mae: 0.7023 - val_loss: 12.7860 - val_mae: 0.8788\n",
            "Epoch 226/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.7145 - mae: 0.7616 - val_loss: 8.3594 - val_mae: 1.3513\n",
            "Epoch 227/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6411 - mae: 0.9130 - val_loss: 6.3555 - val_mae: 0.7143\n",
            "Epoch 228/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8019 - mae: 0.6326 - val_loss: 6.3550 - val_mae: 0.7082\n",
            "Epoch 229/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7642 - mae: 0.6283 - val_loss: 6.2617 - val_mae: 0.7115\n",
            "Epoch 230/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8706 - mae: 0.6409 - val_loss: 5.9619 - val_mae: 0.8848\n",
            "Epoch 231/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0871 - mae: 0.6845 - val_loss: 8.2243 - val_mae: 0.8191\n",
            "Epoch 232/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.6097 - mae: 0.7772 - val_loss: 6.4854 - val_mae: 0.7934\n",
            "Epoch 233/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7384 - mae: 0.6831 - val_loss: 6.0267 - val_mae: 0.7590\n",
            "Epoch 234/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2063 - mae: 0.6389 - val_loss: 5.9815 - val_mae: 0.7296\n",
            "Epoch 235/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7958 - mae: 0.6250 - val_loss: 6.8676 - val_mae: 0.7190\n",
            "Epoch 236/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1096 - mae: 0.6520 - val_loss: 5.7912 - val_mae: 0.7384\n",
            "Epoch 237/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5773 - mae: 0.7010 - val_loss: 6.1331 - val_mae: 0.7073\n",
            "Epoch 238/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1170 - mae: 0.6333 - val_loss: 6.0360 - val_mae: 0.7931\n",
            "Epoch 239/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4160 - mae: 0.6791 - val_loss: 6.2262 - val_mae: 0.7058\n",
            "Epoch 240/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1903 - mae: 0.6374 - val_loss: 5.2207 - val_mae: 0.7025\n",
            "Epoch 241/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8026 - mae: 0.6217 - val_loss: 6.2536 - val_mae: 0.6902\n",
            "Epoch 242/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8258 - mae: 0.6125 - val_loss: 5.4312 - val_mae: 0.6933\n",
            "Epoch 243/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8242 - mae: 0.6175 - val_loss: 6.4562 - val_mae: 0.6911\n",
            "Epoch 244/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6541 - mae: 0.6091 - val_loss: 5.6502 - val_mae: 0.7102\n",
            "Epoch 245/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6466 - mae: 0.6213 - val_loss: 5.9142 - val_mae: 0.6894\n",
            "Epoch 246/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7652 - mae: 0.6089 - val_loss: 5.4759 - val_mae: 0.6999\n",
            "Epoch 247/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4529 - mae: 0.6290 - val_loss: 5.7991 - val_mae: 0.7015\n",
            "Epoch 248/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2610 - mae: 0.6280 - val_loss: 5.9176 - val_mae: 0.6917\n",
            "Epoch 249/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6725 - mae: 0.6071 - val_loss: 5.8327 - val_mae: 0.7132\n",
            "Epoch 250/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8249 - mae: 0.6356 - val_loss: 5.0906 - val_mae: 0.7083\n",
            "Epoch 251/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9260 - mae: 0.6637 - val_loss: 6.7512 - val_mae: 0.7006\n",
            "Epoch 252/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1543 - mae: 0.6443 - val_loss: 5.4297 - val_mae: 0.8313\n",
            "Epoch 253/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8099 - mae: 0.7283 - val_loss: 7.8631 - val_mae: 0.7355\n",
            "Epoch 254/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.4095 - mae: 0.6870 - val_loss: 6.7896 - val_mae: 0.8015\n",
            "Epoch 255/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.7920 - mae: 0.7908 - val_loss: 8.5359 - val_mae: 0.8141\n",
            "Epoch 256/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.4594 - mae: 0.7337 - val_loss: 7.2039 - val_mae: 0.7977\n",
            "Epoch 257/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2761 - mae: 0.6720 - val_loss: 5.8276 - val_mae: 0.8436\n",
            "Epoch 258/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.4198 - mae: 0.6965 - val_loss: 5.3054 - val_mae: 0.6873\n",
            "Epoch 259/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6050 - mae: 0.6107 - val_loss: 6.1200 - val_mae: 0.6973\n",
            "Epoch 260/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7938 - mae: 0.6186 - val_loss: 5.6591 - val_mae: 0.6933\n",
            "Epoch 261/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7105 - mae: 0.6059 - val_loss: 5.7983 - val_mae: 0.6841\n",
            "Epoch 262/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5230 - mae: 0.5918 - val_loss: 5.7050 - val_mae: 0.6917\n",
            "Epoch 263/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5316 - mae: 0.5922 - val_loss: 5.4832 - val_mae: 0.6837\n",
            "Epoch 264/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5050 - mae: 0.5940 - val_loss: 5.6898 - val_mae: 0.6859\n",
            "Epoch 265/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4976 - mae: 0.6005 - val_loss: 5.7311 - val_mae: 0.6840\n",
            "Epoch 266/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4703 - mae: 0.5923 - val_loss: 5.4704 - val_mae: 0.7005\n",
            "Epoch 267/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5807 - mae: 0.6027 - val_loss: 5.8365 - val_mae: 0.7073\n",
            "Epoch 268/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5802 - mae: 0.6156 - val_loss: 5.5557 - val_mae: 0.6820\n",
            "Epoch 269/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6714 - mae: 0.6174 - val_loss: 5.9521 - val_mae: 0.6986\n",
            "Epoch 270/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6922 - mae: 0.6054 - val_loss: 6.0326 - val_mae: 0.7196\n",
            "Epoch 271/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6214 - mae: 0.6101 - val_loss: 5.6451 - val_mae: 0.6920\n",
            "Epoch 272/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4862 - mae: 0.5879 - val_loss: 5.9201 - val_mae: 0.6831\n",
            "Epoch 273/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5538 - mae: 0.5934 - val_loss: 5.4667 - val_mae: 0.6889\n",
            "Epoch 274/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6127 - mae: 0.6099 - val_loss: 6.2916 - val_mae: 0.6864\n",
            "Epoch 275/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5224 - mae: 0.5946 - val_loss: 5.6342 - val_mae: 0.6820\n",
            "Epoch 276/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5751 - mae: 0.5922 - val_loss: 5.5156 - val_mae: 0.6871\n",
            "Epoch 277/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1479 - mae: 0.6264 - val_loss: 5.8959 - val_mae: 0.6892\n",
            "Epoch 278/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6614 - mae: 0.6318 - val_loss: 7.1218 - val_mae: 0.7224\n",
            "Epoch 279/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4175 - mae: 0.6559 - val_loss: 4.8080 - val_mae: 0.8150\n",
            "Epoch 280/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 12.8370 - mae: 0.8573 - val_loss: 15.2030 - val_mae: 1.1625\n",
            "Epoch 281/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 24.3214 - mae: 0.9818 - val_loss: 8.8906 - val_mae: 0.7559\n",
            "Epoch 282/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7258 - mae: 0.6806 - val_loss: 7.5195 - val_mae: 0.7402\n",
            "Epoch 283/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.6125 - mae: 0.6832 - val_loss: 6.7774 - val_mae: 0.7166\n",
            "Epoch 284/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1784 - mae: 0.6464 - val_loss: 5.9903 - val_mae: 0.6967\n",
            "Epoch 285/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6784 - mae: 0.6146 - val_loss: 5.8570 - val_mae: 0.6984\n",
            "Epoch 286/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5588 - mae: 0.6097 - val_loss: 6.2153 - val_mae: 0.6952\n",
            "Epoch 287/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6519 - mae: 0.6165 - val_loss: 6.3511 - val_mae: 0.6956\n",
            "Epoch 288/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7596 - mae: 0.6123 - val_loss: 6.2688 - val_mae: 0.6962\n",
            "Epoch 289/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7538 - mae: 0.6202 - val_loss: 5.7268 - val_mae: 0.6935\n",
            "Epoch 290/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5394 - mae: 0.6030 - val_loss: 6.2563 - val_mae: 0.6882\n",
            "Epoch 291/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5509 - mae: 0.5956 - val_loss: 5.9992 - val_mae: 0.6890\n",
            "Epoch 292/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5405 - mae: 0.6007 - val_loss: 6.1605 - val_mae: 0.6986\n",
            "Epoch 293/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5024 - mae: 0.5954 - val_loss: 5.9459 - val_mae: 0.6824\n",
            "Epoch 294/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4505 - mae: 0.5896 - val_loss: 6.0658 - val_mae: 0.6836\n",
            "Epoch 295/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4384 - mae: 0.5881 - val_loss: 6.0659 - val_mae: 0.6904\n",
            "Epoch 296/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5788 - mae: 0.5980 - val_loss: 5.7584 - val_mae: 0.6813\n",
            "Epoch 297/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4996 - mae: 0.5921 - val_loss: 5.9288 - val_mae: 0.6812\n",
            "Epoch 298/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5925 - mae: 0.5935 - val_loss: 5.7893 - val_mae: 0.6855\n",
            "Epoch 299/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5465 - mae: 0.6011 - val_loss: 6.0270 - val_mae: 0.6926\n",
            "Epoch 300/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6548 - mae: 0.6040 - val_loss: 5.8649 - val_mae: 0.6839\n",
            "Epoch 301/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5424 - mae: 0.6002 - val_loss: 5.7454 - val_mae: 0.6985\n",
            "Epoch 302/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7203 - mae: 0.6297 - val_loss: 5.9446 - val_mae: 0.6838\n",
            "Epoch 303/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4885 - mae: 0.5955 - val_loss: 5.8333 - val_mae: 0.6855\n",
            "Epoch 304/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4967 - mae: 0.5970 - val_loss: 5.7551 - val_mae: 0.6853\n",
            "Epoch 305/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4806 - mae: 0.5880 - val_loss: 5.8155 - val_mae: 0.6968\n",
            "Epoch 306/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5436 - mae: 0.5960 - val_loss: 5.8305 - val_mae: 0.6797\n",
            "Epoch 307/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4413 - mae: 0.5881 - val_loss: 6.0241 - val_mae: 0.6938\n",
            "Epoch 308/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4900 - mae: 0.6013 - val_loss: 5.9856 - val_mae: 0.6922\n",
            "Epoch 309/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5576 - mae: 0.6050 - val_loss: 5.5709 - val_mae: 0.6907\n",
            "Epoch 310/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3383 - mae: 0.5829 - val_loss: 5.8359 - val_mae: 0.6810\n",
            "Epoch 311/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3124 - mae: 0.5806 - val_loss: 6.0371 - val_mae: 0.6818\n",
            "Epoch 312/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5179 - mae: 0.5930 - val_loss: 5.9631 - val_mae: 0.6897\n",
            "Epoch 313/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5376 - mae: 0.5981 - val_loss: 5.6957 - val_mae: 0.6765\n",
            "Epoch 314/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3592 - mae: 0.5801 - val_loss: 5.7959 - val_mae: 0.6759\n",
            "Epoch 315/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4697 - mae: 0.5889 - val_loss: 5.4891 - val_mae: 0.6752\n",
            "Epoch 316/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4945 - mae: 0.6069 - val_loss: 6.0263 - val_mae: 0.6843\n",
            "Epoch 317/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5378 - mae: 0.5962 - val_loss: 5.6143 - val_mae: 0.6734\n",
            "Epoch 318/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4334 - mae: 0.5924 - val_loss: 6.1918 - val_mae: 0.6780\n",
            "Epoch 319/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8681 - mae: 0.6008 - val_loss: 7.9341 - val_mae: 0.7861\n",
            "Epoch 320/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.0335 - mae: 0.7064 - val_loss: 6.5758 - val_mae: 0.6903\n",
            "Epoch 321/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6229 - mae: 0.6204 - val_loss: 6.0724 - val_mae: 0.6963\n",
            "Epoch 322/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2662 - mae: 0.6246 - val_loss: 6.2641 - val_mae: 0.8132\n",
            "Epoch 323/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.5939 - mae: 0.8917 - val_loss: 7.6397 - val_mae: 0.7507\n",
            "Epoch 324/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.6615 - mae: 0.7278 - val_loss: 5.7875 - val_mae: 0.8313\n",
            "Epoch 325/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2306 - mae: 0.7245 - val_loss: 7.3227 - val_mae: 0.7421\n",
            "Epoch 326/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.7357 - mae: 0.6660 - val_loss: 6.2026 - val_mae: 0.7219\n",
            "Epoch 327/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7195 - mae: 0.6267 - val_loss: 6.7465 - val_mae: 0.6944\n",
            "Epoch 328/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4527 - mae: 0.5979 - val_loss: 6.2488 - val_mae: 0.6856\n",
            "Epoch 329/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4773 - mae: 0.5950 - val_loss: 6.4807 - val_mae: 0.6941\n",
            "Epoch 330/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4063 - mae: 0.5893 - val_loss: 6.2188 - val_mae: 0.6843\n",
            "Epoch 331/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4115 - mae: 0.5884 - val_loss: 6.3312 - val_mae: 0.6976\n",
            "Epoch 332/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5269 - mae: 0.6102 - val_loss: 6.3394 - val_mae: 0.6924\n",
            "Epoch 333/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4340 - mae: 0.5898 - val_loss: 6.3636 - val_mae: 0.6952\n",
            "Epoch 334/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4433 - mae: 0.5915 - val_loss: 6.0887 - val_mae: 0.6830\n",
            "Epoch 335/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3738 - mae: 0.5882 - val_loss: 5.8911 - val_mae: 0.6811\n",
            "Epoch 336/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6064 - mae: 0.6107 - val_loss: 6.2567 - val_mae: 0.6888\n",
            "Epoch 337/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4951 - mae: 0.5938 - val_loss: 6.0810 - val_mae: 0.6799\n",
            "Epoch 338/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4101 - mae: 0.5863 - val_loss: 6.1284 - val_mae: 0.6763\n",
            "Epoch 339/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4894 - mae: 0.5910 - val_loss: 6.2349 - val_mae: 0.6836\n",
            "Epoch 340/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5832 - mae: 0.5949 - val_loss: 6.0651 - val_mae: 0.6821\n",
            "Epoch 341/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6185 - mae: 0.6112 - val_loss: 6.1230 - val_mae: 0.6815\n",
            "Epoch 342/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4681 - mae: 0.5947 - val_loss: 6.1919 - val_mae: 0.7020\n",
            "Epoch 343/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5632 - mae: 0.6090 - val_loss: 6.0829 - val_mae: 0.6759\n",
            "Epoch 344/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4200 - mae: 0.5841 - val_loss: 6.4898 - val_mae: 0.6902\n",
            "Epoch 345/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3607 - mae: 0.5944 - val_loss: 6.2139 - val_mae: 0.6801\n",
            "Epoch 346/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3535 - mae: 0.5795 - val_loss: 5.8676 - val_mae: 0.6820\n",
            "Epoch 347/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6368 - mae: 0.6026 - val_loss: 6.3530 - val_mae: 0.7738\n",
            "Epoch 348/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6168 - mae: 0.6429 - val_loss: 6.2809 - val_mae: 0.7237\n",
            "Epoch 349/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4217 - mae: 0.6602 - val_loss: 6.4024 - val_mae: 0.6919\n",
            "Epoch 350/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.4143 - mae: 0.6860 - val_loss: 7.7037 - val_mae: 0.6932\n",
            "Epoch 351/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.9624 - mae: 0.6165 - val_loss: 6.5115 - val_mae: 1.2019\n",
            "Epoch 352/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.5792 - mae: 1.1320 - val_loss: 5.6734 - val_mae: 0.8352\n",
            "Epoch 353/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9834 - mae: 0.6743 - val_loss: 6.1534 - val_mae: 0.7207\n",
            "Epoch 354/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.7197 - mae: 0.6308 - val_loss: 5.7056 - val_mae: 0.7051\n",
            "Epoch 355/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7562 - mae: 0.6218 - val_loss: 5.9751 - val_mae: 0.7269\n",
            "Epoch 356/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5537 - mae: 0.6052 - val_loss: 5.9027 - val_mae: 0.6870\n",
            "Epoch 357/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4918 - mae: 0.5908 - val_loss: 5.6814 - val_mae: 0.6813\n",
            "Epoch 358/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2722 - mae: 0.5712 - val_loss: 5.9882 - val_mae: 0.6893\n",
            "Epoch 359/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5068 - mae: 0.5945 - val_loss: 5.7696 - val_mae: 0.6884\n",
            "Epoch 360/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4186 - mae: 0.5939 - val_loss: 5.8978 - val_mae: 0.6861\n",
            "Epoch 361/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4111 - mae: 0.5909 - val_loss: 5.7295 - val_mae: 0.6887\n",
            "Epoch 362/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3677 - mae: 0.5894 - val_loss: 6.0941 - val_mae: 0.6851\n",
            "Epoch 363/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3276 - mae: 0.5847 - val_loss: 5.7534 - val_mae: 0.6847\n",
            "Epoch 364/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4231 - mae: 0.5801 - val_loss: 5.8024 - val_mae: 0.6837\n",
            "Epoch 365/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5344 - mae: 0.5962 - val_loss: 5.6828 - val_mae: 0.6835\n",
            "Epoch 366/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4554 - mae: 0.5922 - val_loss: 6.0689 - val_mae: 0.6917\n",
            "Epoch 367/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6471 - mae: 0.6192 - val_loss: 6.0327 - val_mae: 0.6952\n",
            "Epoch 368/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4572 - mae: 0.6050 - val_loss: 5.8829 - val_mae: 0.6851\n",
            "Epoch 369/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4346 - mae: 0.5956 - val_loss: 5.5016 - val_mae: 0.6832\n",
            "Epoch 370/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4908 - mae: 0.5908 - val_loss: 6.1318 - val_mae: 0.7088\n",
            "Epoch 371/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8831 - mae: 0.6390 - val_loss: 5.9917 - val_mae: 0.6831\n",
            "Epoch 372/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5075 - mae: 0.5949 - val_loss: 5.4825 - val_mae: 0.6873\n",
            "Epoch 373/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6815 - mae: 0.6005 - val_loss: 5.6377 - val_mae: 0.6920\n",
            "Epoch 374/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2132 - mae: 0.6246 - val_loss: 5.8573 - val_mae: 0.6823\n",
            "Epoch 375/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8815 - mae: 0.6119 - val_loss: 5.8635 - val_mae: 0.6965\n",
            "Epoch 376/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3924 - mae: 0.6420 - val_loss: 6.8668 - val_mae: 0.8159\n",
            "Epoch 377/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.1307 - mae: 0.7329 - val_loss: 5.8573 - val_mae: 0.6796\n",
            "Epoch 378/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5111 - mae: 0.5919 - val_loss: 6.6053 - val_mae: 0.7225\n",
            "Epoch 379/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4347 - mae: 0.5992 - val_loss: 5.4390 - val_mae: 0.6925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "7erW9qMiSIy_",
        "outputId": "7a0010f2-148b-42f8-89d4-36078aa0d9e4"
      },
      "source": [
        "# 테스트 세트에 대한 성능 평가\n",
        "print(\"Accuracy : \", model4.evaluate(X_test_scaled, y_testd)[1])\n",
        "\n",
        "y_vloss = history4.history['val_loss'] # 테스트 세트 손실\n",
        "y_loss = history4.history['loss'] # 학습 세트의 정확도\n",
        "    \n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, '.', c='red', markersize=3, label=\"val_loss\")\n",
        "plt.plot(x_len, y_loss, '.', c='blue',  markersize=3,label = 'loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 0s 1ms/step - loss: 8.3478 - mae: 0.6850\n",
            "Accuracy :  0.6849756836891174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKJWIbjBSwHV",
        "outputId": "cb9ae963-ab01-4a79-cac5-cfa54871b530"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "modelpath = './model/{epoch:02d}.hdf5'\n",
        "checkpointer = ModelCheckpoint(filepath = modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "model4 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model4.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "history4 = model4.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping, checkpointer])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "57/57 [==============================] - 1s 8ms/step - loss: 251.8914 - mae: 7.1623 - val_loss: 138.4092 - val_mae: 3.6894\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 138.40918, saving model to ./model/01.hdf5\n",
            "Epoch 2/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 193.6483 - mae: 3.9010 - val_loss: 87.6876 - val_mae: 3.1564\n",
            "\n",
            "Epoch 00002: val_loss improved from 138.40918 to 87.68758, saving model to ./model/02.hdf5\n",
            "Epoch 3/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 138.4404 - mae: 3.3600 - val_loss: 51.4564 - val_mae: 2.6342\n",
            "\n",
            "Epoch 00003: val_loss improved from 87.68758 to 51.45639, saving model to ./model/03.hdf5\n",
            "Epoch 4/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 58.7409 - mae: 2.6328 - val_loss: 35.9200 - val_mae: 2.3693\n",
            "\n",
            "Epoch 00004: val_loss improved from 51.45639 to 35.91999, saving model to ./model/04.hdf5\n",
            "Epoch 5/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 81.1409 - mae: 2.3957 - val_loss: 29.5204 - val_mae: 1.8459\n",
            "\n",
            "Epoch 00005: val_loss improved from 35.91999 to 29.52044, saving model to ./model/05.hdf5\n",
            "Epoch 6/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 62.7333 - mae: 1.9059 - val_loss: 24.0724 - val_mae: 1.7056\n",
            "\n",
            "Epoch 00006: val_loss improved from 29.52044 to 24.07244, saving model to ./model/06.hdf5\n",
            "Epoch 7/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 29.6481 - mae: 1.7014 - val_loss: 22.4526 - val_mae: 1.5615\n",
            "\n",
            "Epoch 00007: val_loss improved from 24.07244 to 22.45263, saving model to ./model/07.hdf5\n",
            "Epoch 8/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 33.8778 - mae: 1.6334 - val_loss: 18.4701 - val_mae: 1.5762\n",
            "\n",
            "Epoch 00008: val_loss improved from 22.45263 to 18.47008, saving model to ./model/08.hdf5\n",
            "Epoch 9/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 42.5026 - mae: 1.5396 - val_loss: 16.1859 - val_mae: 1.3971\n",
            "\n",
            "Epoch 00009: val_loss improved from 18.47008 to 16.18594, saving model to ./model/09.hdf5\n",
            "Epoch 10/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 34.1469 - mae: 1.3797 - val_loss: 16.2390 - val_mae: 1.3348\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 16.18594\n",
            "Epoch 11/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.3907 - mae: 1.2932 - val_loss: 15.5049 - val_mae: 1.4035\n",
            "\n",
            "Epoch 00011: val_loss improved from 16.18594 to 15.50493, saving model to ./model/11.hdf5\n",
            "Epoch 12/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.9632 - mae: 1.3008 - val_loss: 15.2282 - val_mae: 1.4788\n",
            "\n",
            "Epoch 00012: val_loss improved from 15.50493 to 15.22825, saving model to ./model/12.hdf5\n",
            "Epoch 13/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.4040 - mae: 1.3693 - val_loss: 13.3493 - val_mae: 1.2700\n",
            "\n",
            "Epoch 00013: val_loss improved from 15.22825 to 13.34927, saving model to ./model/13.hdf5\n",
            "Epoch 14/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 50.0840 - mae: 1.3215 - val_loss: 11.0646 - val_mae: 1.1407\n",
            "\n",
            "Epoch 00014: val_loss improved from 13.34927 to 11.06462, saving model to ./model/14.hdf5\n",
            "Epoch 15/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 28.0938 - mae: 1.1579 - val_loss: 12.9030 - val_mae: 1.1446\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 11.06462\n",
            "Epoch 16/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.7456 - mae: 1.1121 - val_loss: 11.0930 - val_mae: 1.2198\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 11.06462\n",
            "Epoch 17/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 29.1812 - mae: 1.1220 - val_loss: 10.3734 - val_mae: 1.0569\n",
            "\n",
            "Epoch 00017: val_loss improved from 11.06462 to 10.37339, saving model to ./model/17.hdf5\n",
            "Epoch 18/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.1562 - mae: 1.0605 - val_loss: 11.1533 - val_mae: 1.0681\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 10.37339\n",
            "Epoch 19/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 57.5722 - mae: 1.1769 - val_loss: 9.4739 - val_mae: 1.1289\n",
            "\n",
            "Epoch 00019: val_loss improved from 10.37339 to 9.47392, saving model to ./model/19.hdf5\n",
            "Epoch 20/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.5678 - mae: 1.1435 - val_loss: 10.1571 - val_mae: 1.0353\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 9.47392\n",
            "Epoch 21/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.9241 - mae: 1.0353 - val_loss: 11.3918 - val_mae: 1.0571\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 9.47392\n",
            "Epoch 22/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.9433 - mae: 1.0154 - val_loss: 8.4124 - val_mae: 1.0708\n",
            "\n",
            "Epoch 00022: val_loss improved from 9.47392 to 8.41238, saving model to ./model/22.hdf5\n",
            "Epoch 23/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1717 - mae: 1.0156 - val_loss: 9.6111 - val_mae: 1.0059\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 8.41238\n",
            "Epoch 24/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.7419 - mae: 0.9732 - val_loss: 8.6667 - val_mae: 1.0052\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 8.41238\n",
            "Epoch 25/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 38.6645 - mae: 1.0061 - val_loss: 7.9125 - val_mae: 0.9191\n",
            "\n",
            "Epoch 00025: val_loss improved from 8.41238 to 7.91253, saving model to ./model/25.hdf5\n",
            "Epoch 26/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 37.7890 - mae: 1.0059 - val_loss: 7.1234 - val_mae: 0.9336\n",
            "\n",
            "Epoch 00026: val_loss improved from 7.91253 to 7.12339, saving model to ./model/26.hdf5\n",
            "Epoch 27/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 49.7844 - mae: 1.0732 - val_loss: 11.0542 - val_mae: 1.0304\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 7.12339\n",
            "Epoch 28/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 39.3979 - mae: 1.1680 - val_loss: 9.5769 - val_mae: 0.9873\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 7.12339\n",
            "Epoch 29/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.3525 - mae: 0.9041 - val_loss: 11.1831 - val_mae: 1.6960\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 7.12339\n",
            "Epoch 30/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.9567 - mae: 1.1655 - val_loss: 7.3903 - val_mae: 0.9329\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 7.12339\n",
            "Epoch 31/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.3224 - mae: 0.9429 - val_loss: 8.6114 - val_mae: 1.0071\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 7.12339\n",
            "Epoch 32/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.9580 - mae: 0.9882 - val_loss: 7.8382 - val_mae: 0.9002\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 7.12339\n",
            "Epoch 33/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.6897 - mae: 0.9007 - val_loss: 9.6302 - val_mae: 0.9604\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 7.12339\n",
            "Epoch 34/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.8257 - mae: 0.8750 - val_loss: 9.0869 - val_mae: 1.1477\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 7.12339\n",
            "Epoch 35/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.3696 - mae: 0.9420 - val_loss: 8.5000 - val_mae: 0.9557\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 7.12339\n",
            "Epoch 36/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.6034 - mae: 0.8779 - val_loss: 8.5391 - val_mae: 0.9468\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 7.12339\n",
            "Epoch 37/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.1805 - mae: 0.8676 - val_loss: 7.7550 - val_mae: 0.8688\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 7.12339\n",
            "Epoch 38/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 27.4918 - mae: 0.8880 - val_loss: 6.3098 - val_mae: 0.8565\n",
            "\n",
            "Epoch 00038: val_loss improved from 7.12339 to 6.30975, saving model to ./model/38.hdf5\n",
            "Epoch 39/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.8742 - mae: 0.8147 - val_loss: 9.6626 - val_mae: 0.9291\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 6.30975\n",
            "Epoch 40/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.0619 - mae: 0.8858 - val_loss: 6.5712 - val_mae: 0.8549\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 6.30975\n",
            "Epoch 41/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 28.0302 - mae: 0.9118 - val_loss: 7.9915 - val_mae: 0.8780\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 6.30975\n",
            "Epoch 42/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.1549 - mae: 0.9020 - val_loss: 5.8525 - val_mae: 0.8502\n",
            "\n",
            "Epoch 00042: val_loss improved from 6.30975 to 5.85249, saving model to ./model/42.hdf5\n",
            "Epoch 43/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.3308 - mae: 0.8573 - val_loss: 7.8562 - val_mae: 0.8774\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 5.85249\n",
            "Epoch 44/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.9226 - mae: 0.7980 - val_loss: 7.6219 - val_mae: 0.9126\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 5.85249\n",
            "Epoch 45/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.6919 - mae: 0.7943 - val_loss: 9.2961 - val_mae: 0.8861\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 5.85249\n",
            "Epoch 46/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.6478 - mae: 0.8329 - val_loss: 6.1762 - val_mae: 0.8160\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 5.85249\n",
            "Epoch 47/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.1007 - mae: 0.8308 - val_loss: 6.2933 - val_mae: 0.8173\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 5.85249\n",
            "Epoch 48/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.7099 - mae: 0.7635 - val_loss: 6.6776 - val_mae: 0.8528\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 5.85249\n",
            "Epoch 49/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.3234 - mae: 0.8595 - val_loss: 5.9106 - val_mae: 0.8157\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 5.85249\n",
            "Epoch 50/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1201 - mae: 0.7748 - val_loss: 8.4021 - val_mae: 0.8909\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 5.85249\n",
            "Epoch 51/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 24.6747 - mae: 1.1801 - val_loss: 7.6117 - val_mae: 0.9301\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 5.85249\n",
            "Epoch 52/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.3920 - mae: 0.8528 - val_loss: 8.6126 - val_mae: 0.9336\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 5.85249\n",
            "Epoch 53/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.0835 - mae: 0.8599 - val_loss: 6.9080 - val_mae: 0.8991\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 5.85249\n",
            "Epoch 54/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.5168 - mae: 0.8696 - val_loss: 11.6130 - val_mae: 0.9731\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 5.85249\n",
            "Epoch 55/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.4551 - mae: 0.9750 - val_loss: 8.2549 - val_mae: 0.8946\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 5.85249\n",
            "Epoch 56/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 11.5486 - mae: 0.8974 - val_loss: 7.1156 - val_mae: 0.8205\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 5.85249\n",
            "Epoch 57/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.6788 - mae: 0.7987 - val_loss: 7.4188 - val_mae: 0.8369\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 5.85249\n",
            "Epoch 58/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.7313 - mae: 0.7760 - val_loss: 6.7929 - val_mae: 0.8295\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 5.85249\n",
            "Epoch 59/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8631 - mae: 0.7726 - val_loss: 6.5541 - val_mae: 0.9305\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 5.85249\n",
            "Epoch 60/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.6724 - mae: 0.8412 - val_loss: 5.8172 - val_mae: 0.8004\n",
            "\n",
            "Epoch 00060: val_loss improved from 5.85249 to 5.81725, saving model to ./model/60.hdf5\n",
            "Epoch 61/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.0651 - mae: 0.7766 - val_loss: 6.5997 - val_mae: 0.8296\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 5.81725\n",
            "Epoch 62/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.1538 - mae: 0.8064 - val_loss: 6.1670 - val_mae: 0.8683\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 5.81725\n",
            "Epoch 63/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.3626 - mae: 0.8365 - val_loss: 5.3985 - val_mae: 0.7927\n",
            "\n",
            "Epoch 00063: val_loss improved from 5.81725 to 5.39852, saving model to ./model/63.hdf5\n",
            "Epoch 64/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.5353 - mae: 0.7612 - val_loss: 5.4151 - val_mae: 0.8073\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 5.39852\n",
            "Epoch 65/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6344 - mae: 0.7521 - val_loss: 6.0728 - val_mae: 0.8685\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 5.39852\n",
            "Epoch 66/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.5156 - mae: 0.7721 - val_loss: 6.7996 - val_mae: 0.9212\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 5.39852\n",
            "Epoch 67/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2854 - mae: 0.8153 - val_loss: 5.4543 - val_mae: 0.8089\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 5.39852\n",
            "Epoch 68/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2880 - mae: 0.8085 - val_loss: 5.8541 - val_mae: 0.7838\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 5.39852\n",
            "Epoch 69/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.1999 - mae: 0.7530 - val_loss: 5.9012 - val_mae: 0.9359\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 5.39852\n",
            "Epoch 70/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.9851 - mae: 0.8241 - val_loss: 6.7056 - val_mae: 0.8119\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 5.39852\n",
            "Epoch 71/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.0612 - mae: 0.7609 - val_loss: 5.8856 - val_mae: 0.8247\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 5.39852\n",
            "Epoch 72/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.6659 - mae: 0.8465 - val_loss: 6.4666 - val_mae: 0.8699\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 5.39852\n",
            "Epoch 73/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6126 - mae: 0.7920 - val_loss: 5.9325 - val_mae: 0.8398\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 5.39852\n",
            "Epoch 74/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.6748 - mae: 0.7896 - val_loss: 6.1398 - val_mae: 0.8138\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 5.39852\n",
            "Epoch 75/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.6242 - mae: 0.7658 - val_loss: 5.7724 - val_mae: 0.7983\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 5.39852\n",
            "Epoch 76/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.0320 - mae: 0.7644 - val_loss: 5.1543 - val_mae: 0.7767\n",
            "\n",
            "Epoch 00076: val_loss improved from 5.39852 to 5.15434, saving model to ./model/76.hdf5\n",
            "Epoch 77/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.4413 - mae: 0.7609 - val_loss: 5.5451 - val_mae: 0.8094\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 5.15434\n",
            "Epoch 78/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.1790 - mae: 0.7497 - val_loss: 5.4626 - val_mae: 0.7996\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 5.15434\n",
            "Epoch 79/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2459 - mae: 0.7395 - val_loss: 5.4686 - val_mae: 0.7923\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 5.15434\n",
            "Epoch 80/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.2226 - mae: 0.7682 - val_loss: 5.0055 - val_mae: 0.7596\n",
            "\n",
            "Epoch 00080: val_loss improved from 5.15434 to 5.00554, saving model to ./model/80.hdf5\n",
            "Epoch 81/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.7793 - mae: 0.7085 - val_loss: 5.3739 - val_mae: 0.7714\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 5.00554\n",
            "Epoch 82/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.1956 - mae: 0.7179 - val_loss: 5.3048 - val_mae: 0.7933\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 5.00554\n",
            "Epoch 83/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.1358 - mae: 0.7218 - val_loss: 5.8335 - val_mae: 0.8095\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 5.00554\n",
            "Epoch 84/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.6541 - mae: 0.7519 - val_loss: 5.1492 - val_mae: 0.7734\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 5.00554\n",
            "Epoch 85/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.9226 - mae: 0.7494 - val_loss: 5.9041 - val_mae: 0.7866\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 5.00554\n",
            "Epoch 86/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.1256 - mae: 0.7503 - val_loss: 4.9399 - val_mae: 0.7563\n",
            "\n",
            "Epoch 00086: val_loss improved from 5.00554 to 4.93986, saving model to ./model/86.hdf5\n",
            "Epoch 87/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8816 - mae: 0.7116 - val_loss: 5.6148 - val_mae: 0.7767\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 4.93986\n",
            "Epoch 88/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.9447 - mae: 0.7418 - val_loss: 4.9978 - val_mae: 0.7724\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 4.93986\n",
            "Epoch 89/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9660 - mae: 0.7339 - val_loss: 5.4900 - val_mae: 0.7975\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 4.93986\n",
            "Epoch 90/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9468 - mae: 0.7189 - val_loss: 4.8213 - val_mae: 0.7502\n",
            "\n",
            "Epoch 00090: val_loss improved from 4.93986 to 4.82127, saving model to ./model/90.hdf5\n",
            "Epoch 91/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2604 - mae: 0.7181 - val_loss: 5.1250 - val_mae: 0.7945\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 4.82127\n",
            "Epoch 92/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.1001 - mae: 0.7308 - val_loss: 6.1218 - val_mae: 0.8925\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 4.82127\n",
            "Epoch 93/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.2677 - mae: 0.8033 - val_loss: 6.0056 - val_mae: 1.2391\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 4.82127\n",
            "Epoch 94/3000\n",
            "44/57 [======================>.......] - ETA: 0s - loss: 16.0275 - mae: 1.0030"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyB9JJ0CTaxe"
      },
      "source": [
        "mymodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PujR9-k-S8CR"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "mymodel = load_model('./model/168.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DEMCx0NHTViv",
        "outputId": "b3e04181-bc3c-4201-c676-f00d5866a47f"
      },
      "source": [
        "# 테스트 세트에 대한 성능 평가\n",
        "print(\"Accuracy : \", model4.evaluate(X_test_scaled, y_testd)[1])\n",
        "\n",
        "y_vloss = history4.history['val_loss'] # 테스트 세트 손실\n",
        "y_loss = history4.history['loss'] # 학습 세트의 정확도\n",
        "    \n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, '.', c='red', markersize=3, label=\"val_loss\")\n",
        "plt.plot(x_len, y_loss, '.', c='blue',  markersize=3,label = 'loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 0s 991us/step - loss: 9.7253 - mae: 0.6764\n",
            "Accuracy :  0.6763774752616882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDDBi2Q4Ieb9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggOZazeVTqJO",
        "outputId": "4da5bea6-8f27-48cd-d559-1d8333f57ed7"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "model5 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dense(8, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model5.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "history5 = model5.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "57/57 [==============================] - 1s 8ms/step - loss: 253.5326 - mae: 7.3046 - val_loss: 129.6341 - val_mae: 3.5259\n",
            "Epoch 2/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 171.0369 - mae: 3.7302 - val_loss: 77.6340 - val_mae: 2.7569\n",
            "Epoch 3/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 126.5786 - mae: 3.1861 - val_loss: 50.9051 - val_mae: 2.7856\n",
            "Epoch 4/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 59.7726 - mae: 2.8197 - val_loss: 39.6354 - val_mae: 2.6568\n",
            "Epoch 5/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 88.9549 - mae: 2.8106 - val_loss: 34.4176 - val_mae: 2.3233\n",
            "Epoch 6/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 68.7451 - mae: 2.2732 - val_loss: 28.7348 - val_mae: 1.9268\n",
            "Epoch 7/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.1613 - mae: 1.8628 - val_loss: 24.7874 - val_mae: 1.7077\n",
            "Epoch 8/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 36.6902 - mae: 1.7433 - val_loss: 22.2156 - val_mae: 1.5992\n",
            "Epoch 9/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 40.2617 - mae: 1.5684 - val_loss: 19.1399 - val_mae: 1.4438\n",
            "Epoch 10/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.1984 - mae: 1.4332 - val_loss: 17.9239 - val_mae: 1.3921\n",
            "Epoch 11/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.2197 - mae: 1.3543 - val_loss: 18.6522 - val_mae: 1.5412\n",
            "Epoch 12/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.6040 - mae: 1.4397 - val_loss: 19.3523 - val_mae: 1.9196\n",
            "Epoch 13/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 24.3286 - mae: 1.5665 - val_loss: 16.3836 - val_mae: 1.4350\n",
            "Epoch 14/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 52.2662 - mae: 1.4997 - val_loss: 14.0176 - val_mae: 1.2404\n",
            "Epoch 15/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 32.2487 - mae: 1.3052 - val_loss: 14.4321 - val_mae: 1.2632\n",
            "Epoch 16/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 16.7783 - mae: 1.2187 - val_loss: 14.5060 - val_mae: 1.3926\n",
            "Epoch 17/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 28.7350 - mae: 1.2668 - val_loss: 13.5754 - val_mae: 1.1896\n",
            "Epoch 18/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.7616 - mae: 1.2494 - val_loss: 14.1281 - val_mae: 1.1905\n",
            "Epoch 19/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 55.3558 - mae: 1.2717 - val_loss: 13.5877 - val_mae: 1.1843\n",
            "Epoch 20/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.8900 - mae: 1.2165 - val_loss: 15.1106 - val_mae: 1.4978\n",
            "Epoch 21/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.3674 - mae: 1.3303 - val_loss: 13.0355 - val_mae: 1.2097\n",
            "Epoch 22/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.3258 - mae: 1.0902 - val_loss: 12.7051 - val_mae: 1.1101\n",
            "Epoch 23/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.2108 - mae: 1.0625 - val_loss: 13.9221 - val_mae: 1.1405\n",
            "Epoch 24/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.6143 - mae: 1.0603 - val_loss: 12.4319 - val_mae: 1.0855\n",
            "Epoch 25/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 34.6356 - mae: 1.0833 - val_loss: 12.6611 - val_mae: 1.0686\n",
            "Epoch 26/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 44.7664 - mae: 1.2169 - val_loss: 11.8415 - val_mae: 1.2318\n",
            "Epoch 27/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 38.4730 - mae: 1.1493 - val_loss: 11.0666 - val_mae: 1.0303\n",
            "Epoch 28/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.3987 - mae: 0.9933 - val_loss: 13.6552 - val_mae: 1.2020\n",
            "Epoch 29/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.5737 - mae: 1.0636 - val_loss: 13.4982 - val_mae: 1.3292\n",
            "Epoch 30/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 16.8809 - mae: 1.2002 - val_loss: 11.3617 - val_mae: 1.0381\n",
            "Epoch 31/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.2213 - mae: 0.9983 - val_loss: 12.9514 - val_mae: 1.1076\n",
            "Epoch 32/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.8751 - mae: 1.1043 - val_loss: 11.9140 - val_mae: 1.0366\n",
            "Epoch 33/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.8408 - mae: 0.9990 - val_loss: 14.9000 - val_mae: 1.0805\n",
            "Epoch 34/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.0489 - mae: 0.9574 - val_loss: 12.9133 - val_mae: 1.0818\n",
            "Epoch 35/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.6560 - mae: 0.9857 - val_loss: 14.3508 - val_mae: 1.0271\n",
            "Epoch 36/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.9171 - mae: 0.9087 - val_loss: 13.6035 - val_mae: 1.0886\n",
            "Epoch 37/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.2072 - mae: 0.9831 - val_loss: 12.4581 - val_mae: 0.9857\n",
            "Epoch 38/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.7208 - mae: 0.9781 - val_loss: 11.2796 - val_mae: 0.9721\n",
            "Epoch 39/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.8537 - mae: 0.8802 - val_loss: 17.5241 - val_mae: 1.0555\n",
            "Epoch 40/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.1673 - mae: 0.9899 - val_loss: 11.8753 - val_mae: 0.9578\n",
            "Epoch 41/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.1044 - mae: 0.9786 - val_loss: 13.5132 - val_mae: 0.9676\n",
            "Epoch 42/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 19.0129 - mae: 0.9676 - val_loss: 10.7483 - val_mae: 0.9454\n",
            "Epoch 43/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 19.0614 - mae: 1.0067 - val_loss: 15.0192 - val_mae: 1.0230\n",
            "Epoch 44/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.6337 - mae: 0.8727 - val_loss: 12.5329 - val_mae: 0.9536\n",
            "Epoch 45/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.5129 - mae: 0.8490 - val_loss: 15.3944 - val_mae: 0.9723\n",
            "Epoch 46/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.7739 - mae: 0.8606 - val_loss: 11.1940 - val_mae: 0.9270\n",
            "Epoch 47/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.5116 - mae: 0.9148 - val_loss: 11.1893 - val_mae: 0.9120\n",
            "Epoch 48/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.8796 - mae: 0.8282 - val_loss: 12.1470 - val_mae: 0.9077\n",
            "Epoch 49/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.5475 - mae: 0.9199 - val_loss: 11.0919 - val_mae: 0.9469\n",
            "Epoch 50/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.0495 - mae: 0.8607 - val_loss: 16.5776 - val_mae: 1.0016\n",
            "Epoch 51/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.2052 - mae: 1.2666 - val_loss: 12.8371 - val_mae: 0.9870\n",
            "Epoch 52/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.6821 - mae: 0.9338 - val_loss: 14.9568 - val_mae: 1.2251\n",
            "Epoch 53/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.8804 - mae: 1.1825 - val_loss: 13.1353 - val_mae: 1.3002\n",
            "Epoch 54/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.1856 - mae: 1.0267 - val_loss: 12.7091 - val_mae: 1.0775\n",
            "Epoch 55/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.8784 - mae: 0.9168 - val_loss: 14.5706 - val_mae: 1.1056\n",
            "Epoch 56/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.6904 - mae: 1.0640 - val_loss: 12.0702 - val_mae: 0.9559\n",
            "Epoch 57/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2880 - mae: 0.9266 - val_loss: 13.2593 - val_mae: 0.9804\n",
            "Epoch 58/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.8201 - mae: 0.8747 - val_loss: 12.1240 - val_mae: 0.9481\n",
            "Epoch 59/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.2949 - mae: 0.8604 - val_loss: 11.9717 - val_mae: 0.9664\n",
            "Epoch 60/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.1788 - mae: 0.9605 - val_loss: 11.5066 - val_mae: 0.9087\n",
            "Epoch 61/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.8489 - mae: 0.8880 - val_loss: 12.5682 - val_mae: 0.9468\n",
            "Epoch 62/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.7353 - mae: 0.8890 - val_loss: 12.4718 - val_mae: 1.1080\n",
            "Epoch 63/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.5729 - mae: 0.9495 - val_loss: 10.9570 - val_mae: 0.8979\n",
            "Epoch 64/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.0194 - mae: 0.8250 - val_loss: 10.8725 - val_mae: 0.9465\n",
            "Epoch 65/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.5213 - mae: 0.8696 - val_loss: 12.3975 - val_mae: 1.0695\n",
            "Epoch 66/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.9806 - mae: 0.9070 - val_loss: 13.1570 - val_mae: 0.9412\n",
            "Epoch 67/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.1494 - mae: 0.8758 - val_loss: 11.1577 - val_mae: 0.9040\n",
            "Epoch 68/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.5780 - mae: 0.8468 - val_loss: 11.1941 - val_mae: 0.8822\n",
            "Epoch 69/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.0945 - mae: 0.8192 - val_loss: 9.9360 - val_mae: 0.9340\n",
            "Epoch 70/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.3009 - mae: 0.8706 - val_loss: 12.2219 - val_mae: 0.9275\n",
            "Epoch 71/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.0510 - mae: 0.8431 - val_loss: 10.1049 - val_mae: 0.8905\n",
            "Epoch 72/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.0686 - mae: 0.8793 - val_loss: 11.1024 - val_mae: 0.9216\n",
            "Epoch 73/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3872 - mae: 0.7884 - val_loss: 11.4523 - val_mae: 0.9458\n",
            "Epoch 74/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.7840 - mae: 0.8158 - val_loss: 12.4618 - val_mae: 0.9439\n",
            "Epoch 75/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.4115 - mae: 0.8157 - val_loss: 9.7334 - val_mae: 0.8667\n",
            "Epoch 76/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.2522 - mae: 0.8176 - val_loss: 8.6266 - val_mae: 0.8552\n",
            "Epoch 77/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.5184 - mae: 0.7923 - val_loss: 10.4142 - val_mae: 0.8783\n",
            "Epoch 78/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.3264 - mae: 0.7900 - val_loss: 10.5839 - val_mae: 0.9337\n",
            "Epoch 79/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.6188 - mae: 0.7943 - val_loss: 10.3571 - val_mae: 0.8743\n",
            "Epoch 80/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.5118 - mae: 0.7901 - val_loss: 9.8760 - val_mae: 0.8418\n",
            "Epoch 81/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.9156 - mae: 0.7515 - val_loss: 10.1502 - val_mae: 0.8467\n",
            "Epoch 82/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2800 - mae: 0.7700 - val_loss: 10.1185 - val_mae: 0.8576\n",
            "Epoch 83/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.0957 - mae: 0.7603 - val_loss: 11.6200 - val_mae: 0.8601\n",
            "Epoch 84/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.9707 - mae: 0.8241 - val_loss: 9.9027 - val_mae: 0.8555\n",
            "Epoch 85/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.5727 - mae: 0.7867 - val_loss: 10.9419 - val_mae: 0.8401\n",
            "Epoch 86/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2981 - mae: 0.7870 - val_loss: 9.4442 - val_mae: 0.8328\n",
            "Epoch 87/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8006 - mae: 0.7462 - val_loss: 9.8931 - val_mae: 0.8302\n",
            "Epoch 88/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.7320 - mae: 0.7688 - val_loss: 9.8003 - val_mae: 0.8181\n",
            "Epoch 89/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0510 - mae: 0.7440 - val_loss: 9.6771 - val_mae: 0.8494\n",
            "Epoch 90/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.0787 - mae: 0.7881 - val_loss: 8.8655 - val_mae: 0.8287\n",
            "Epoch 91/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.0057 - mae: 0.7506 - val_loss: 9.6927 - val_mae: 0.8217\n",
            "Epoch 92/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8481 - mae: 0.7314 - val_loss: 9.5702 - val_mae: 0.8191\n",
            "Epoch 93/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.6916 - mae: 0.7253 - val_loss: 9.4159 - val_mae: 0.8231\n",
            "Epoch 94/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7616 - mae: 0.7353 - val_loss: 8.8056 - val_mae: 0.8223\n",
            "Epoch 95/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.1622 - mae: 0.7476 - val_loss: 9.3734 - val_mae: 0.8208\n",
            "Epoch 96/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.6161 - mae: 0.7315 - val_loss: 9.0205 - val_mae: 0.8437\n",
            "Epoch 97/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.3711 - mae: 0.7976 - val_loss: 11.2079 - val_mae: 0.8398\n",
            "Epoch 98/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.2500 - mae: 0.7622 - val_loss: 8.3802 - val_mae: 1.0963\n",
            "Epoch 99/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.8087 - mae: 0.9906 - val_loss: 7.3697 - val_mae: 1.0021\n",
            "Epoch 100/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 15.0257 - mae: 1.0457 - val_loss: 12.4215 - val_mae: 1.4282\n",
            "Epoch 101/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.5018 - mae: 1.0339 - val_loss: 6.7657 - val_mae: 0.9374\n",
            "Epoch 102/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.7335 - mae: 0.9272 - val_loss: 8.8973 - val_mae: 0.8459\n",
            "Epoch 103/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.8081 - mae: 0.7578 - val_loss: 7.9503 - val_mae: 0.8231\n",
            "Epoch 104/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8628 - mae: 0.7466 - val_loss: 7.3318 - val_mae: 0.7866\n",
            "Epoch 105/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6302 - mae: 0.7162 - val_loss: 7.9852 - val_mae: 0.8264\n",
            "Epoch 106/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.5227 - mae: 0.7206 - val_loss: 7.9679 - val_mae: 0.7954\n",
            "Epoch 107/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.5142 - mae: 0.6981 - val_loss: 8.3965 - val_mae: 0.8264\n",
            "Epoch 108/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.6720 - mae: 0.7528 - val_loss: 7.4616 - val_mae: 0.8179\n",
            "Epoch 109/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1981 - mae: 0.6851 - val_loss: 7.0272 - val_mae: 0.7773\n",
            "Epoch 110/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3655 - mae: 0.6969 - val_loss: 7.6023 - val_mae: 0.7748\n",
            "Epoch 111/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3890 - mae: 0.6988 - val_loss: 7.7290 - val_mae: 0.7741\n",
            "Epoch 112/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5856 - mae: 0.7246 - val_loss: 6.9594 - val_mae: 0.7862\n",
            "Epoch 113/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5051 - mae: 0.7158 - val_loss: 7.6240 - val_mae: 0.7773\n",
            "Epoch 114/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5544 - mae: 0.7352 - val_loss: 7.7658 - val_mae: 0.8966\n",
            "Epoch 115/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.9584 - mae: 0.7397 - val_loss: 7.0865 - val_mae: 0.7643\n",
            "Epoch 116/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4042 - mae: 0.6888 - val_loss: 8.2305 - val_mae: 0.7913\n",
            "Epoch 117/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3541 - mae: 0.6915 - val_loss: 7.4323 - val_mae: 0.7642\n",
            "Epoch 118/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4661 - mae: 0.7043 - val_loss: 6.9413 - val_mae: 0.7625\n",
            "Epoch 119/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1623 - mae: 0.6777 - val_loss: 7.2482 - val_mae: 0.7600\n",
            "Epoch 120/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0204 - mae: 0.6536 - val_loss: 6.6878 - val_mae: 0.8217\n",
            "Epoch 121/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3473 - mae: 0.7037 - val_loss: 8.2722 - val_mae: 0.7887\n",
            "Epoch 122/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7716 - mae: 0.7252 - val_loss: 7.5284 - val_mae: 0.7750\n",
            "Epoch 123/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2502 - mae: 0.6873 - val_loss: 6.5991 - val_mae: 0.7458\n",
            "Epoch 124/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2590 - mae: 0.6798 - val_loss: 6.9803 - val_mae: 0.7578\n",
            "Epoch 125/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3231 - mae: 0.6958 - val_loss: 7.3989 - val_mae: 0.9500\n",
            "Epoch 126/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.9296 - mae: 0.7991 - val_loss: 6.6247 - val_mae: 0.7813\n",
            "Epoch 127/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1629 - mae: 0.6870 - val_loss: 7.7972 - val_mae: 0.7569\n",
            "Epoch 128/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1838 - mae: 0.6726 - val_loss: 7.7186 - val_mae: 0.7799\n",
            "Epoch 129/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9270 - mae: 0.6520 - val_loss: 7.0302 - val_mae: 0.7419\n",
            "Epoch 130/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2620 - mae: 0.6747 - val_loss: 8.6483 - val_mae: 0.7613\n",
            "Epoch 131/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.2418 - mae: 0.7369 - val_loss: 7.5928 - val_mae: 0.9765\n",
            "Epoch 132/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.7858 - mae: 0.8955 - val_loss: 13.9574 - val_mae: 1.7123\n",
            "Epoch 133/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.1817 - mae: 0.9970 - val_loss: 9.0619 - val_mae: 1.3500\n",
            "Epoch 134/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.7101 - mae: 1.0837 - val_loss: 11.1824 - val_mae: 0.9024\n",
            "Epoch 135/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.5391 - mae: 0.8907 - val_loss: 10.1681 - val_mae: 1.0349\n",
            "Epoch 136/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.4077 - mae: 0.8890 - val_loss: 7.8224 - val_mae: 0.8173\n",
            "Epoch 137/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2976 - mae: 0.8256 - val_loss: 7.9306 - val_mae: 0.8267\n",
            "Epoch 138/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.5602 - mae: 0.7480 - val_loss: 7.3504 - val_mae: 0.7954\n",
            "Epoch 139/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7135 - mae: 0.7066 - val_loss: 7.0835 - val_mae: 0.7825\n",
            "Epoch 140/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.2504 - mae: 0.7781 - val_loss: 6.8322 - val_mae: 0.7599\n",
            "Epoch 141/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.0468 - mae: 0.7359 - val_loss: 7.3508 - val_mae: 0.7536\n",
            "Epoch 142/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5163 - mae: 0.6985 - val_loss: 7.5332 - val_mae: 0.7672\n",
            "Epoch 143/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1277 - mae: 0.6784 - val_loss: 7.0556 - val_mae: 0.8386\n",
            "Epoch 144/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1434 - mae: 0.7008 - val_loss: 6.8553 - val_mae: 0.7945\n",
            "Epoch 145/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1549 - mae: 0.6728 - val_loss: 6.5552 - val_mae: 0.7497\n",
            "Epoch 146/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9854 - mae: 0.6641 - val_loss: 6.6996 - val_mae: 0.7568\n",
            "Epoch 147/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9428 - mae: 0.6593 - val_loss: 6.8504 - val_mae: 0.7395\n",
            "Epoch 148/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1294 - mae: 0.6635 - val_loss: 6.7077 - val_mae: 0.7448\n",
            "Epoch 149/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.8168 - mae: 0.6953 - val_loss: 6.8951 - val_mae: 0.7679\n",
            "Epoch 150/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1589 - mae: 0.6612 - val_loss: 6.6594 - val_mae: 0.7695\n",
            "Epoch 151/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2440 - mae: 0.6846 - val_loss: 6.7005 - val_mae: 0.7562\n",
            "Epoch 152/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1581 - mae: 0.6492 - val_loss: 6.3815 - val_mae: 0.7751\n",
            "Epoch 153/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0887 - mae: 0.6582 - val_loss: 6.4197 - val_mae: 0.7453\n",
            "Epoch 154/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0078 - mae: 0.6520 - val_loss: 6.4904 - val_mae: 0.7371\n",
            "Epoch 155/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7338 - mae: 0.6403 - val_loss: 6.5366 - val_mae: 0.7405\n",
            "Epoch 156/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8437 - mae: 0.6403 - val_loss: 6.4324 - val_mae: 0.7597\n",
            "Epoch 157/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0560 - mae: 0.6668 - val_loss: 6.1996 - val_mae: 0.7312\n",
            "Epoch 158/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0360 - mae: 0.6587 - val_loss: 6.3422 - val_mae: 0.7245\n",
            "Epoch 159/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2604 - mae: 0.6708 - val_loss: 7.3963 - val_mae: 0.7629\n",
            "Epoch 160/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0993 - mae: 0.6700 - val_loss: 7.0336 - val_mae: 0.7371\n",
            "Epoch 161/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9447 - mae: 0.6415 - val_loss: 5.9033 - val_mae: 0.7930\n",
            "Epoch 162/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1476 - mae: 0.6748 - val_loss: 6.0637 - val_mae: 0.7313\n",
            "Epoch 163/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9013 - mae: 0.6475 - val_loss: 6.7289 - val_mae: 0.7431\n",
            "Epoch 164/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0540 - mae: 0.6686 - val_loss: 6.2671 - val_mae: 0.7233\n",
            "Epoch 165/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1372 - mae: 0.6598 - val_loss: 6.1549 - val_mae: 0.8094\n",
            "Epoch 166/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1336 - mae: 0.6871 - val_loss: 6.4083 - val_mae: 0.9500\n",
            "Epoch 167/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.1136 - mae: 1.1394 - val_loss: 7.5581 - val_mae: 1.7410\n",
            "Epoch 168/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.3749 - mae: 0.9840 - val_loss: 12.0683 - val_mae: 1.2205\n",
            "Epoch 169/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 10.7429 - mae: 0.9741 - val_loss: 7.8338 - val_mae: 0.8700\n",
            "Epoch 170/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6484 - mae: 0.7075 - val_loss: 6.8778 - val_mae: 0.7546\n",
            "Epoch 171/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0608 - mae: 0.6556 - val_loss: 6.0110 - val_mae: 0.7258\n",
            "Epoch 172/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0154 - mae: 0.6573 - val_loss: 6.2318 - val_mae: 0.7511\n",
            "Epoch 173/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2092 - mae: 0.6815 - val_loss: 5.9874 - val_mae: 0.7141\n",
            "Epoch 174/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0324 - mae: 0.6446 - val_loss: 6.3383 - val_mae: 0.7251\n",
            "Epoch 175/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9146 - mae: 0.6338 - val_loss: 7.0964 - val_mae: 0.7231\n",
            "Epoch 176/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7813 - mae: 0.6209 - val_loss: 6.4470 - val_mae: 0.7611\n",
            "Epoch 177/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0181 - mae: 0.6462 - val_loss: 6.4333 - val_mae: 0.7198\n",
            "Epoch 178/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8290 - mae: 0.6402 - val_loss: 6.0609 - val_mae: 0.7802\n",
            "Epoch 179/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0406 - mae: 0.6698 - val_loss: 5.7925 - val_mae: 0.7392\n",
            "Epoch 180/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8970 - mae: 0.6483 - val_loss: 7.2696 - val_mae: 0.7190\n",
            "Epoch 181/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9747 - mae: 0.6464 - val_loss: 5.7960 - val_mae: 0.7742\n",
            "Epoch 182/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9125 - mae: 0.6569 - val_loss: 5.7918 - val_mae: 0.7044\n",
            "Epoch 183/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9348 - mae: 0.6280 - val_loss: 6.0536 - val_mae: 0.7150\n",
            "Epoch 184/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8057 - mae: 0.6224 - val_loss: 6.3403 - val_mae: 0.7354\n",
            "Epoch 185/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7649 - mae: 0.6281 - val_loss: 6.1580 - val_mae: 0.7210\n",
            "Epoch 186/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6836 - mae: 0.6194 - val_loss: 6.0010 - val_mae: 0.7053\n",
            "Epoch 187/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6849 - mae: 0.6163 - val_loss: 6.2321 - val_mae: 0.7213\n",
            "Epoch 188/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7880 - mae: 0.6269 - val_loss: 6.2993 - val_mae: 0.7095\n",
            "Epoch 189/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6414 - mae: 0.6146 - val_loss: 5.5483 - val_mae: 0.7056\n",
            "Epoch 190/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1626 - mae: 0.6552 - val_loss: 5.8000 - val_mae: 0.7234\n",
            "Epoch 191/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9973 - mae: 0.6429 - val_loss: 6.1246 - val_mae: 0.7600\n",
            "Epoch 192/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3061 - mae: 0.7093 - val_loss: 6.0536 - val_mae: 0.7041\n",
            "Epoch 193/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6618 - mae: 0.6160 - val_loss: 5.5950 - val_mae: 0.7061\n",
            "Epoch 194/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7353 - mae: 0.6137 - val_loss: 6.7509 - val_mae: 0.7140\n",
            "Epoch 195/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7519 - mae: 0.6230 - val_loss: 6.0936 - val_mae: 0.7053\n",
            "Epoch 196/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7669 - mae: 0.6352 - val_loss: 5.5616 - val_mae: 0.7269\n",
            "Epoch 197/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0684 - mae: 0.6478 - val_loss: 6.1767 - val_mae: 0.7217\n",
            "Epoch 198/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0726 - mae: 0.6439 - val_loss: 6.8746 - val_mae: 0.7397\n",
            "Epoch 199/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0037 - mae: 0.6516 - val_loss: 5.0670 - val_mae: 0.7474\n",
            "Epoch 200/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1131 - mae: 0.6671 - val_loss: 5.9725 - val_mae: 0.7077\n",
            "Epoch 201/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8684 - mae: 0.6404 - val_loss: 6.1465 - val_mae: 0.7130\n",
            "Epoch 202/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6384 - mae: 0.6104 - val_loss: 6.2109 - val_mae: 0.7086\n",
            "Epoch 203/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8007 - mae: 0.6182 - val_loss: 5.5725 - val_mae: 0.7208\n",
            "Epoch 204/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1966 - mae: 0.6442 - val_loss: 4.6025 - val_mae: 0.7082\n",
            "Epoch 205/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.7228 - mae: 0.8425 - val_loss: 7.1758 - val_mae: 0.7942\n",
            "Epoch 206/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.1041 - mae: 0.7819 - val_loss: 5.8207 - val_mae: 1.1750\n",
            "Epoch 207/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3691 - mae: 0.8162 - val_loss: 6.2093 - val_mae: 0.7819\n",
            "Epoch 208/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7575 - mae: 0.6919 - val_loss: 6.1479 - val_mae: 0.8083\n",
            "Epoch 209/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.8571 - mae: 0.7069 - val_loss: 5.7940 - val_mae: 0.7056\n",
            "Epoch 210/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.6143 - mae: 0.6824 - val_loss: 6.5004 - val_mae: 0.7318\n",
            "Epoch 211/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9590 - mae: 0.6290 - val_loss: 5.8946 - val_mae: 0.7355\n",
            "Epoch 212/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7428 - mae: 0.6482 - val_loss: 5.8081 - val_mae: 0.7023\n",
            "Epoch 213/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7469 - mae: 0.6173 - val_loss: 5.6821 - val_mae: 0.7095\n",
            "Epoch 214/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9342 - mae: 0.6321 - val_loss: 5.6348 - val_mae: 0.7136\n",
            "Epoch 215/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6641 - mae: 0.6189 - val_loss: 5.9395 - val_mae: 0.7143\n",
            "Epoch 216/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5904 - mae: 0.6069 - val_loss: 5.7403 - val_mae: 0.6955\n",
            "Epoch 217/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5434 - mae: 0.6032 - val_loss: 5.3972 - val_mae: 0.6992\n",
            "Epoch 218/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6823 - mae: 0.6201 - val_loss: 5.8348 - val_mae: 0.6933\n",
            "Epoch 219/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7119 - mae: 0.6116 - val_loss: 5.4263 - val_mae: 0.6969\n",
            "Epoch 220/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8439 - mae: 0.6284 - val_loss: 7.1324 - val_mae: 0.7608\n",
            "Epoch 221/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9213 - mae: 0.6497 - val_loss: 5.6572 - val_mae: 0.7131\n",
            "Epoch 222/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9073 - mae: 0.6298 - val_loss: 6.0003 - val_mae: 0.7277\n",
            "Epoch 223/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0699 - mae: 0.6418 - val_loss: 6.3407 - val_mae: 0.7169\n",
            "Epoch 224/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6465 - mae: 0.6229 - val_loss: 5.2411 - val_mae: 0.7580\n",
            "Epoch 225/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1982 - mae: 0.6523 - val_loss: 5.8460 - val_mae: 0.7502\n",
            "Epoch 226/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8525 - mae: 0.6457 - val_loss: 5.8395 - val_mae: 0.7158\n",
            "Epoch 227/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7085 - mae: 0.6452 - val_loss: 6.0522 - val_mae: 0.7020\n",
            "Epoch 228/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8127 - mae: 0.6208 - val_loss: 5.5386 - val_mae: 0.7026\n",
            "Epoch 229/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7193 - mae: 0.6207 - val_loss: 7.5302 - val_mae: 0.8417\n",
            "Epoch 230/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8695 - mae: 0.6633 - val_loss: 5.3343 - val_mae: 0.7431\n",
            "Epoch 231/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7600 - mae: 0.6482 - val_loss: 5.6649 - val_mae: 0.9832\n",
            "Epoch 232/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.8366 - mae: 0.7705 - val_loss: 8.5565 - val_mae: 0.9174\n",
            "Epoch 233/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.3927 - mae: 0.9787 - val_loss: 6.9683 - val_mae: 1.1613\n",
            "Epoch 234/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.2243 - mae: 0.8179 - val_loss: 7.5071 - val_mae: 0.8152\n",
            "Epoch 235/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0380 - mae: 0.6755 - val_loss: 4.6326 - val_mae: 0.7602\n",
            "Epoch 236/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6948 - mae: 0.6387 - val_loss: 6.3252 - val_mae: 0.7184\n",
            "Epoch 237/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8020 - mae: 0.6285 - val_loss: 5.7796 - val_mae: 0.6956\n",
            "Epoch 238/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5370 - mae: 0.6038 - val_loss: 6.1565 - val_mae: 0.7073\n",
            "Epoch 239/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0202 - mae: 0.6381 - val_loss: 5.7832 - val_mae: 0.7036\n",
            "Epoch 240/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8843 - mae: 0.6214 - val_loss: 6.0329 - val_mae: 0.7302\n",
            "Epoch 241/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6488 - mae: 0.6214 - val_loss: 4.9556 - val_mae: 0.6810\n",
            "Epoch 242/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6019 - mae: 0.6026 - val_loss: 5.5432 - val_mae: 0.7142\n",
            "Epoch 243/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7717 - mae: 0.6253 - val_loss: 5.7264 - val_mae: 0.6963\n",
            "Epoch 244/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6339 - mae: 0.6097 - val_loss: 5.4402 - val_mae: 0.6895\n",
            "Epoch 245/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5881 - mae: 0.6044 - val_loss: 5.0787 - val_mae: 0.7078\n",
            "Epoch 246/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7093 - mae: 0.6268 - val_loss: 6.0043 - val_mae: 0.6911\n",
            "Epoch 247/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6183 - mae: 0.6080 - val_loss: 5.6036 - val_mae: 0.7276\n",
            "Epoch 248/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7006 - mae: 0.6327 - val_loss: 4.4170 - val_mae: 0.6988\n",
            "Epoch 249/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8540 - mae: 0.6342 - val_loss: 6.7296 - val_mae: 0.7442\n",
            "Epoch 250/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7704 - mae: 0.6342 - val_loss: 4.3797 - val_mae: 0.6999\n",
            "Epoch 251/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7784 - mae: 0.6771 - val_loss: 5.3552 - val_mae: 0.7106\n",
            "Epoch 252/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8781 - mae: 0.6557 - val_loss: 5.7877 - val_mae: 0.7997\n",
            "Epoch 253/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5565 - mae: 0.6640 - val_loss: 5.7597 - val_mae: 0.7071\n",
            "Epoch 254/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1878 - mae: 0.6404 - val_loss: 5.7640 - val_mae: 0.7437\n",
            "Epoch 255/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5726 - mae: 0.6967 - val_loss: 5.4917 - val_mae: 0.7616\n",
            "Epoch 256/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9658 - mae: 0.6488 - val_loss: 5.4547 - val_mae: 0.7527\n",
            "Epoch 257/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3730 - mae: 0.6686 - val_loss: 4.6929 - val_mae: 0.7563\n",
            "Epoch 258/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4257 - mae: 0.6626 - val_loss: 5.1715 - val_mae: 0.7019\n",
            "Epoch 259/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6876 - mae: 0.6816 - val_loss: 5.4771 - val_mae: 0.6930\n",
            "Epoch 260/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1758 - mae: 0.6430 - val_loss: 5.9458 - val_mae: 0.7040\n",
            "Epoch 261/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8987 - mae: 0.6183 - val_loss: 6.1341 - val_mae: 0.7387\n",
            "Epoch 262/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.1314 - mae: 0.7050 - val_loss: 6.7151 - val_mae: 1.0145\n",
            "Epoch 263/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.9167 - mae: 0.8588 - val_loss: 4.8290 - val_mae: 0.7054\n",
            "Epoch 264/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3912 - mae: 0.6507 - val_loss: 5.8210 - val_mae: 0.6931\n",
            "Epoch 265/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0712 - mae: 0.6314 - val_loss: 5.9239 - val_mae: 0.6991\n",
            "Epoch 266/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2497 - mae: 0.6488 - val_loss: 5.2071 - val_mae: 0.7510\n",
            "Epoch 267/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6601 - mae: 0.6310 - val_loss: 5.4911 - val_mae: 0.7134\n",
            "Epoch 268/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.3088 - mae: 0.6759 - val_loss: 4.8829 - val_mae: 0.7277\n",
            "Epoch 269/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.7077 - mae: 0.7225 - val_loss: 5.5191 - val_mae: 0.7155\n",
            "Epoch 270/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9012 - mae: 0.6455 - val_loss: 6.2003 - val_mae: 0.7006\n",
            "Epoch 271/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6133 - mae: 0.6034 - val_loss: 5.5378 - val_mae: 0.7392\n",
            "Epoch 272/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5138 - mae: 0.6159 - val_loss: 5.3562 - val_mae: 0.6888\n",
            "Epoch 273/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5198 - mae: 0.5948 - val_loss: 5.6191 - val_mae: 0.7047\n",
            "Epoch 274/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5813 - mae: 0.6186 - val_loss: 5.5923 - val_mae: 0.7000\n",
            "Epoch 275/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0201 - mae: 0.6616 - val_loss: 5.1257 - val_mae: 0.6818\n",
            "Epoch 276/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9082 - mae: 0.6093 - val_loss: 6.1343 - val_mae: 0.7928\n",
            "Epoch 277/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.6997 - mae: 0.8880 - val_loss: 8.7818 - val_mae: 0.8166\n",
            "Epoch 278/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.4206 - mae: 0.6641 - val_loss: 6.3453 - val_mae: 1.1481\n",
            "Epoch 279/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2968 - mae: 0.8789 - val_loss: 6.2418 - val_mae: 0.7673\n",
            "Epoch 280/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2638 - mae: 0.6785 - val_loss: 6.3770 - val_mae: 0.7916\n",
            "Epoch 281/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5353 - mae: 0.6453 - val_loss: 5.2740 - val_mae: 0.7135\n",
            "Epoch 282/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7632 - mae: 0.6207 - val_loss: 5.5909 - val_mae: 0.6954\n",
            "Epoch 283/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6896 - mae: 0.6031 - val_loss: 5.5201 - val_mae: 0.7003\n",
            "Epoch 284/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7049 - mae: 0.6224 - val_loss: 5.4842 - val_mae: 0.6973\n",
            "Epoch 285/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5799 - mae: 0.6027 - val_loss: 5.8154 - val_mae: 0.6980\n",
            "Epoch 286/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7102 - mae: 0.6242 - val_loss: 5.0695 - val_mae: 0.7076\n",
            "Epoch 287/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9063 - mae: 0.6245 - val_loss: 6.1612 - val_mae: 0.7007\n",
            "Epoch 288/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8237 - mae: 0.6014 - val_loss: 5.4765 - val_mae: 0.7057\n",
            "Epoch 289/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0552 - mae: 0.6450 - val_loss: 5.4216 - val_mae: 0.7014\n",
            "Epoch 290/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8499 - mae: 0.6559 - val_loss: 5.7306 - val_mae: 0.6933\n",
            "Epoch 291/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4721 - mae: 0.5909 - val_loss: 5.7365 - val_mae: 0.8091\n",
            "Epoch 292/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6272 - mae: 0.6385 - val_loss: 5.7105 - val_mae: 0.7050\n",
            "Epoch 293/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6476 - mae: 0.6075 - val_loss: 5.6150 - val_mae: 0.6945\n",
            "Epoch 294/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4155 - mae: 0.5861 - val_loss: 5.2776 - val_mae: 0.6845\n",
            "Epoch 295/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3766 - mae: 0.5861 - val_loss: 5.9027 - val_mae: 0.7036\n",
            "Epoch 296/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4702 - mae: 0.5860 - val_loss: 5.1199 - val_mae: 0.6954\n",
            "Epoch 297/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4300 - mae: 0.5988 - val_loss: 5.6648 - val_mae: 0.7036\n",
            "Epoch 298/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6527 - mae: 0.6001 - val_loss: 4.9170 - val_mae: 0.6901\n",
            "Epoch 299/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6789 - mae: 0.6003 - val_loss: 6.3549 - val_mae: 0.7170\n",
            "Epoch 300/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7574 - mae: 0.6124 - val_loss: 6.3438 - val_mae: 0.7380\n",
            "Epoch 301/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1061 - mae: 0.6771 - val_loss: 7.4288 - val_mae: 0.7139\n",
            "Epoch 302/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5661 - mae: 0.6131 - val_loss: 5.6547 - val_mae: 0.6938\n",
            "Epoch 303/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6111 - mae: 0.6084 - val_loss: 6.0938 - val_mae: 0.7233\n",
            "Epoch 304/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7141 - mae: 0.6263 - val_loss: 5.5067 - val_mae: 0.8585\n",
            "Epoch 305/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0757 - mae: 0.6543 - val_loss: 7.3417 - val_mae: 0.7791\n",
            "Epoch 306/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.2527 - mae: 0.6336 - val_loss: 5.4276 - val_mae: 0.8565\n",
            "Epoch 307/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.5531 - mae: 0.8140 - val_loss: 5.0595 - val_mae: 0.7899\n",
            "Epoch 308/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.9099 - mae: 0.7794 - val_loss: 9.1710 - val_mae: 0.8947\n",
            "Epoch 309/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.7630 - mae: 1.0963 - val_loss: 7.3531 - val_mae: 0.8740\n",
            "Epoch 310/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9806 - mae: 0.6784 - val_loss: 6.1240 - val_mae: 0.7824\n",
            "Epoch 311/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0370 - mae: 0.6887 - val_loss: 6.0939 - val_mae: 0.9382\n",
            "Epoch 312/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5636 - mae: 0.7355 - val_loss: 5.2024 - val_mae: 0.6963\n",
            "Epoch 313/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8906 - mae: 0.6299 - val_loss: 4.8566 - val_mae: 0.6897\n",
            "Epoch 314/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5357 - mae: 0.6039 - val_loss: 5.5324 - val_mae: 0.6904\n",
            "Epoch 315/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6129 - mae: 0.6063 - val_loss: 5.0168 - val_mae: 0.6836\n",
            "Epoch 316/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4743 - mae: 0.5948 - val_loss: 5.5951 - val_mae: 0.6984\n",
            "Epoch 317/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.5526 - mae: 0.5943 - val_loss: 5.5389 - val_mae: 0.7118\n",
            "Epoch 318/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4212 - mae: 0.6018 - val_loss: 5.0395 - val_mae: 0.7300\n",
            "Epoch 319/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4474 - mae: 0.5983 - val_loss: 5.6062 - val_mae: 0.6958\n",
            "Epoch 320/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4348 - mae: 0.5919 - val_loss: 5.2665 - val_mae: 0.6962\n",
            "Epoch 321/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4664 - mae: 0.6005 - val_loss: 5.6948 - val_mae: 0.6870\n",
            "Epoch 322/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4050 - mae: 0.5827 - val_loss: 6.1253 - val_mae: 0.6925\n",
            "Epoch 323/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.5654 - mae: 0.5907 - val_loss: 4.6780 - val_mae: 0.6951\n",
            "Epoch 324/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4686 - mae: 0.5939 - val_loss: 4.3268 - val_mae: 0.6805\n",
            "Epoch 325/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5243 - mae: 0.5873 - val_loss: 4.5629 - val_mae: 0.6817\n",
            "Epoch 326/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5041 - mae: 0.5851 - val_loss: 6.2471 - val_mae: 0.7035\n",
            "Epoch 327/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4097 - mae: 0.5919 - val_loss: 4.7731 - val_mae: 0.6838\n",
            "Epoch 328/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5631 - mae: 0.6170 - val_loss: 6.0840 - val_mae: 0.7257\n",
            "Epoch 329/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5131 - mae: 0.6047 - val_loss: 5.0705 - val_mae: 0.6915\n",
            "Epoch 330/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3906 - mae: 0.5907 - val_loss: 5.3352 - val_mae: 0.6868\n",
            "Epoch 331/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4124 - mae: 0.5812 - val_loss: 5.0512 - val_mae: 0.6906\n",
            "Epoch 332/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5407 - mae: 0.6092 - val_loss: 5.8382 - val_mae: 0.6945\n",
            "Epoch 333/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5673 - mae: 0.6028 - val_loss: 4.9986 - val_mae: 0.7382\n",
            "Epoch 334/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7262 - mae: 0.6292 - val_loss: 5.6653 - val_mae: 0.6870\n",
            "Epoch 335/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5984 - mae: 0.6130 - val_loss: 5.4730 - val_mae: 0.7615\n",
            "Epoch 336/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3438 - mae: 0.6626 - val_loss: 5.1725 - val_mae: 0.6919\n",
            "Epoch 337/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6549 - mae: 0.6098 - val_loss: 5.2617 - val_mae: 0.6890\n",
            "Epoch 338/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4195 - mae: 0.5882 - val_loss: 5.4102 - val_mae: 0.7054\n",
            "Epoch 339/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6559 - mae: 0.6064 - val_loss: 5.5059 - val_mae: 0.7232\n",
            "Epoch 340/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1020 - mae: 0.6571 - val_loss: 5.4943 - val_mae: 0.7174\n",
            "Epoch 341/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6866 - mae: 0.6133 - val_loss: 5.1379 - val_mae: 0.6899\n",
            "Epoch 342/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5121 - mae: 0.5998 - val_loss: 5.1734 - val_mae: 0.6988\n",
            "Epoch 343/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4191 - mae: 0.5928 - val_loss: 5.3385 - val_mae: 0.6892\n",
            "Epoch 344/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4788 - mae: 0.5891 - val_loss: 5.2665 - val_mae: 0.6962\n",
            "Epoch 345/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3897 - mae: 0.5876 - val_loss: 5.3405 - val_mae: 0.6791\n",
            "Epoch 346/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3924 - mae: 0.5874 - val_loss: 4.9870 - val_mae: 0.7131\n",
            "Epoch 347/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8789 - mae: 0.6082 - val_loss: 6.6428 - val_mae: 0.7258\n",
            "Epoch 348/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5032 - mae: 0.5956 - val_loss: 5.5750 - val_mae: 0.7344\n",
            "Epoch 349/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4855 - mae: 0.6220 - val_loss: 4.9881 - val_mae: 0.6951\n",
            "Epoch 350/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.1653 - mae: 0.6304 - val_loss: 4.8723 - val_mae: 0.7142\n",
            "Epoch 351/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4532 - mae: 0.5948 - val_loss: 5.4460 - val_mae: 0.7420\n",
            "Epoch 352/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8887 - mae: 0.6753 - val_loss: 4.5261 - val_mae: 0.7023\n",
            "Epoch 353/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6940 - mae: 0.6307 - val_loss: 5.8223 - val_mae: 0.7089\n",
            "Epoch 354/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3095 - mae: 0.6755 - val_loss: 5.4989 - val_mae: 0.7385\n",
            "Epoch 355/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0802 - mae: 0.7202 - val_loss: 5.4958 - val_mae: 0.9328\n",
            "Epoch 356/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9101 - mae: 0.6649 - val_loss: 5.8013 - val_mae: 0.7418\n",
            "Epoch 357/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6381 - mae: 0.6110 - val_loss: 5.3807 - val_mae: 0.7020\n",
            "Epoch 358/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4475 - mae: 0.5793 - val_loss: 7.1241 - val_mae: 0.6934\n",
            "Epoch 359/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7253 - mae: 0.6082 - val_loss: 4.8232 - val_mae: 0.7062\n",
            "Epoch 360/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9317 - mae: 0.6406 - val_loss: 6.4528 - val_mae: 0.7373\n",
            "Epoch 361/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8649 - mae: 0.6290 - val_loss: 4.3907 - val_mae: 0.7042\n",
            "Epoch 362/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.6896 - mae: 0.8922 - val_loss: 4.6011 - val_mae: 0.7495\n",
            "Epoch 363/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.5997 - mae: 0.8377 - val_loss: 5.2427 - val_mae: 0.7684\n",
            "Epoch 364/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.1871 - mae: 0.8492 - val_loss: 7.3566 - val_mae: 0.8339\n",
            "Epoch 365/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.8974 - mae: 0.7086 - val_loss: 6.4689 - val_mae: 0.7369\n",
            "Epoch 366/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.2347 - mae: 0.6554 - val_loss: 6.5677 - val_mae: 0.7092\n",
            "Epoch 367/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.2543 - mae: 0.6997 - val_loss: 5.4956 - val_mae: 0.7611\n",
            "Epoch 368/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0661 - mae: 0.6484 - val_loss: 5.1950 - val_mae: 0.7013\n",
            "Epoch 369/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.9498 - mae: 0.6302 - val_loss: 5.8399 - val_mae: 0.7223\n",
            "Epoch 370/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3622 - mae: 0.6180 - val_loss: 4.9001 - val_mae: 0.6968\n",
            "Epoch 371/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5347 - mae: 0.5995 - val_loss: 5.0111 - val_mae: 0.6909\n",
            "Epoch 372/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5174 - mae: 0.5967 - val_loss: 5.2554 - val_mae: 0.6898\n",
            "Epoch 373/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5833 - mae: 0.5945 - val_loss: 5.0563 - val_mae: 0.6977\n",
            "Epoch 374/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4013 - mae: 0.5930 - val_loss: 4.9982 - val_mae: 0.7022\n",
            "Epoch 375/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5261 - mae: 0.5981 - val_loss: 5.1594 - val_mae: 0.7174\n",
            "Epoch 376/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5437 - mae: 0.6275 - val_loss: 5.1502 - val_mae: 0.6846\n",
            "Epoch 377/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3249 - mae: 0.5772 - val_loss: 5.2813 - val_mae: 0.6949\n",
            "Epoch 378/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5351 - mae: 0.6000 - val_loss: 4.9686 - val_mae: 0.6867\n",
            "Epoch 379/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3145 - mae: 0.5763 - val_loss: 4.9308 - val_mae: 0.7446\n",
            "Epoch 380/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3985 - mae: 0.6087 - val_loss: 4.7029 - val_mae: 0.6985\n",
            "Epoch 381/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6345 - mae: 0.5929 - val_loss: 5.1963 - val_mae: 0.6889\n",
            "Epoch 382/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3861 - mae: 0.5815 - val_loss: 5.0050 - val_mae: 0.6901\n",
            "Epoch 383/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6526 - mae: 0.6902 - val_loss: 8.1663 - val_mae: 0.7657\n",
            "Epoch 384/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.7580 - mae: 0.7747 - val_loss: 4.7229 - val_mae: 0.6936\n",
            "Epoch 385/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7174 - mae: 0.6133 - val_loss: 5.7861 - val_mae: 0.6982\n",
            "Epoch 386/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.5761 - mae: 0.5927 - val_loss: 4.9086 - val_mae: 0.6804\n",
            "Epoch 387/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5806 - mae: 0.5911 - val_loss: 9.2523 - val_mae: 0.7203\n",
            "Epoch 388/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7382 - mae: 0.5934 - val_loss: 5.1152 - val_mae: 0.6893\n",
            "Epoch 389/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6187 - mae: 0.6032 - val_loss: 6.2913 - val_mae: 0.7112\n",
            "Epoch 390/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5458 - mae: 0.5976 - val_loss: 5.0781 - val_mae: 0.6847\n",
            "Epoch 391/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5349 - mae: 0.5961 - val_loss: 5.2450 - val_mae: 0.6823\n",
            "Epoch 392/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4406 - mae: 0.5906 - val_loss: 5.3657 - val_mae: 0.7013\n",
            "Epoch 393/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.2666 - mae: 0.5753 - val_loss: 5.1575 - val_mae: 0.6858\n",
            "Epoch 394/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4496 - mae: 0.5976 - val_loss: 5.4057 - val_mae: 0.6887\n",
            "Epoch 395/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.2781 - mae: 0.5752 - val_loss: 5.2016 - val_mae: 0.6836\n",
            "Epoch 396/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4249 - mae: 0.5856 - val_loss: 5.2379 - val_mae: 0.6971\n",
            "Epoch 397/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4056 - mae: 0.5760 - val_loss: 5.4282 - val_mae: 0.6816\n",
            "Epoch 398/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6918 - mae: 0.6274 - val_loss: 5.2935 - val_mae: 0.6921\n",
            "Epoch 399/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.4688 - mae: 0.5805 - val_loss: 5.2657 - val_mae: 0.7060\n",
            "Epoch 400/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4827 - mae: 0.5916 - val_loss: 5.0298 - val_mae: 0.6993\n",
            "Epoch 401/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8049 - mae: 0.6055 - val_loss: 5.7428 - val_mae: 0.7015\n",
            "Epoch 402/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8358 - mae: 0.6091 - val_loss: 7.4678 - val_mae: 1.2645\n",
            "Epoch 403/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.9100 - mae: 0.7983 - val_loss: 4.6207 - val_mae: 0.6936\n",
            "Epoch 404/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0041 - mae: 0.6342 - val_loss: 7.0772 - val_mae: 0.8403\n",
            "Epoch 405/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.1290 - mae: 0.8414 - val_loss: 5.0568 - val_mae: 0.7722\n",
            "Epoch 406/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.6160 - mae: 0.7966 - val_loss: 6.6055 - val_mae: 0.7954\n",
            "Epoch 407/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.7580 - mae: 0.7510 - val_loss: 5.6805 - val_mae: 0.8258\n",
            "Epoch 408/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6049 - mae: 0.7125 - val_loss: 5.5441 - val_mae: 0.7090\n",
            "Epoch 409/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1934 - mae: 0.6243 - val_loss: 5.2366 - val_mae: 0.7257\n",
            "Epoch 410/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5469 - mae: 0.6103 - val_loss: 5.3520 - val_mae: 0.6887\n",
            "Epoch 411/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4195 - mae: 0.5852 - val_loss: 5.1248 - val_mae: 0.7050\n",
            "Epoch 412/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5633 - mae: 0.6121 - val_loss: 5.3568 - val_mae: 0.6857\n",
            "Epoch 413/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.2363 - mae: 0.5673 - val_loss: 5.1685 - val_mae: 0.6925\n",
            "Epoch 414/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3489 - mae: 0.5879 - val_loss: 5.5629 - val_mae: 0.6904\n",
            "Epoch 415/3000\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.3629 - mae: 0.5759 - val_loss: 5.0138 - val_mae: 0.6787\n",
            "Epoch 416/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3413 - mae: 0.5714 - val_loss: 5.5251 - val_mae: 0.6919\n",
            "Epoch 417/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2212 - mae: 0.5714 - val_loss: 4.9000 - val_mae: 0.6829\n",
            "Epoch 418/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3629 - mae: 0.5801 - val_loss: 5.6005 - val_mae: 0.6857\n",
            "Epoch 419/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2311 - mae: 0.5783 - val_loss: 5.2969 - val_mae: 0.6882\n",
            "Epoch 420/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3708 - mae: 0.5832 - val_loss: 5.2482 - val_mae: 0.6867\n",
            "Epoch 421/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.3636 - mae: 0.5878 - val_loss: 5.1737 - val_mae: 0.6861\n",
            "Epoch 422/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.2767 - mae: 0.5705 - val_loss: 5.4517 - val_mae: 0.6876\n",
            "Epoch 423/3000\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7207 - mae: 0.6122 - val_loss: 5.5427 - val_mae: 0.7096\n",
            "Epoch 424/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7435 - mae: 0.6041 - val_loss: 5.2215 - val_mae: 0.6887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CjrhzLGTyic",
        "outputId": "0c1e64d7-e10b-4d5a-cfea-788c8b787078"
      },
      "source": [
        "# 테스트 세트에 대한 성능 평가\n",
        "print(\"Accuracy : \", model5.evaluate(X_test_scaled, y_testd)[1])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 0s 985us/step - loss: 14.0024 - mae: 0.6833\n",
            "Accuracy :  0.6833480596542358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "949KwMMiUMqv",
        "outputId": "daaf52a8-c83e-4742-ff0e-9597e34416e8"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "model6 = Sequential([\n",
        "      Dense(32, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model6.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "history6 = model6.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "57/57 [==============================] - 1s 7ms/step - loss: 274.1829 - mae: 8.0148 - val_loss: 211.4858 - val_mae: 6.7229\n",
            "Epoch 2/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 289.2833 - mae: 6.2268 - val_loss: 158.7015 - val_mae: 4.3962\n",
            "Epoch 3/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 228.8797 - mae: 4.3065 - val_loss: 123.8680 - val_mae: 3.4335\n",
            "Epoch 4/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 133.6031 - mae: 3.5444 - val_loss: 102.0885 - val_mae: 3.4845\n",
            "Epoch 5/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 168.7346 - mae: 3.6394 - val_loss: 84.0419 - val_mae: 2.9653\n",
            "Epoch 6/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 127.1057 - mae: 3.0307 - val_loss: 68.7240 - val_mae: 2.6968\n",
            "Epoch 7/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 78.7803 - mae: 2.7407 - val_loss: 58.2687 - val_mae: 2.4800\n",
            "Epoch 8/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 76.8536 - mae: 2.6173 - val_loss: 50.8182 - val_mae: 2.7497\n",
            "Epoch 9/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 71.9187 - mae: 2.6987 - val_loss: 45.8092 - val_mae: 2.6488\n",
            "Epoch 10/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 69.9620 - mae: 2.6707 - val_loss: 42.2131 - val_mae: 2.5948\n",
            "Epoch 11/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 49.7672 - mae: 2.5313 - val_loss: 39.7173 - val_mae: 2.5015\n",
            "Epoch 12/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 51.9068 - mae: 2.4785 - val_loss: 37.2973 - val_mae: 2.4525\n",
            "Epoch 13/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 54.4340 - mae: 2.4099 - val_loss: 34.9515 - val_mae: 2.3243\n",
            "Epoch 14/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 92.3294 - mae: 2.4430 - val_loss: 33.1302 - val_mae: 2.1896\n",
            "Epoch 15/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 67.3161 - mae: 2.2257 - val_loss: 31.5956 - val_mae: 2.0696\n",
            "Epoch 16/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 45.6201 - mae: 2.0475 - val_loss: 29.4372 - val_mae: 2.0183\n",
            "Epoch 17/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 64.7665 - mae: 2.0546 - val_loss: 27.9174 - val_mae: 1.8960\n",
            "Epoch 18/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 33.6633 - mae: 1.8744 - val_loss: 26.7076 - val_mae: 1.7879\n",
            "Epoch 19/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 99.9348 - mae: 1.8903 - val_loss: 25.1249 - val_mae: 1.7671\n",
            "Epoch 20/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 41.9222 - mae: 1.7694 - val_loss: 24.9426 - val_mae: 1.7028\n",
            "Epoch 21/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 71.9570 - mae: 1.7304 - val_loss: 23.4755 - val_mae: 1.6262\n",
            "Epoch 22/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 26.6676 - mae: 1.6027 - val_loss: 22.5013 - val_mae: 1.5332\n",
            "Epoch 23/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.9538 - mae: 1.5155 - val_loss: 20.9938 - val_mae: 1.5184\n",
            "Epoch 24/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 33.9152 - mae: 1.5227 - val_loss: 20.7256 - val_mae: 1.5282\n",
            "Epoch 25/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 81.2799 - mae: 1.6132 - val_loss: 19.4907 - val_mae: 1.4437\n",
            "Epoch 26/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 76.7656 - mae: 1.5172 - val_loss: 18.9915 - val_mae: 1.4035\n",
            "Epoch 27/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 83.7640 - mae: 1.5089 - val_loss: 18.0364 - val_mae: 1.3791\n",
            "Epoch 28/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 28.8986 - mae: 1.3791 - val_loss: 17.4342 - val_mae: 1.3773\n",
            "Epoch 29/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 21.2504 - mae: 1.3688 - val_loss: 16.8086 - val_mae: 1.3633\n",
            "Epoch 30/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 39.4454 - mae: 1.3906 - val_loss: 16.0487 - val_mae: 1.3137\n",
            "Epoch 31/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 25.9959 - mae: 1.3307 - val_loss: 15.6206 - val_mae: 1.2929\n",
            "Epoch 32/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 48.1067 - mae: 1.3488 - val_loss: 14.9091 - val_mae: 1.2563\n",
            "Epoch 33/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 29.7950 - mae: 1.3162 - val_loss: 14.7457 - val_mae: 1.2526\n",
            "Epoch 34/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.8082 - mae: 1.2278 - val_loss: 13.8626 - val_mae: 1.2473\n",
            "Epoch 35/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.6600 - mae: 1.2372 - val_loss: 13.6011 - val_mae: 1.2320\n",
            "Epoch 36/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 22.8917 - mae: 1.2252 - val_loss: 13.2645 - val_mae: 1.2031\n",
            "Epoch 37/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 36.1800 - mae: 1.2932 - val_loss: 12.9544 - val_mae: 1.2013\n",
            "Epoch 38/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 72.2594 - mae: 1.2895 - val_loss: 12.3380 - val_mae: 1.1747\n",
            "Epoch 39/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15.1325 - mae: 1.1435 - val_loss: 12.4966 - val_mae: 1.2074\n",
            "Epoch 40/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 27.3786 - mae: 1.2145 - val_loss: 11.8766 - val_mae: 1.1620\n",
            "Epoch 41/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 71.6716 - mae: 1.2781 - val_loss: 11.7129 - val_mae: 1.1394\n",
            "Epoch 42/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 54.4360 - mae: 1.2465 - val_loss: 10.9812 - val_mae: 1.1230\n",
            "Epoch 43/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 20.2513 - mae: 1.1436 - val_loss: 11.0444 - val_mae: 1.1558\n",
            "Epoch 44/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.9656 - mae: 1.1326 - val_loss: 10.6232 - val_mae: 1.1221\n",
            "Epoch 45/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.4179 - mae: 1.1492 - val_loss: 10.9712 - val_mae: 1.2132\n",
            "Epoch 46/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.0651 - mae: 1.1614 - val_loss: 9.6810 - val_mae: 1.1091\n",
            "Epoch 47/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 41.9326 - mae: 1.1787 - val_loss: 10.2690 - val_mae: 1.0863\n",
            "Epoch 48/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 19.3326 - mae: 1.0686 - val_loss: 9.9804 - val_mae: 1.1547\n",
            "Epoch 49/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 41.2296 - mae: 1.1671 - val_loss: 9.2669 - val_mae: 1.0666\n",
            "Epoch 50/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.0039 - mae: 1.0686 - val_loss: 10.0330 - val_mae: 1.1568\n",
            "Epoch 51/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.4999 - mae: 1.4041 - val_loss: 9.0753 - val_mae: 1.0982\n",
            "Epoch 52/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.2684 - mae: 1.0693 - val_loss: 8.8278 - val_mae: 1.0681\n",
            "Epoch 53/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24.0506 - mae: 1.0835 - val_loss: 8.6229 - val_mae: 1.0930\n",
            "Epoch 54/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 25.7626 - mae: 1.0859 - val_loss: 8.4727 - val_mae: 1.0532\n",
            "Epoch 55/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.6484 - mae: 1.0372 - val_loss: 8.5860 - val_mae: 1.0948\n",
            "Epoch 56/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 23.3657 - mae: 1.0891 - val_loss: 8.0135 - val_mae: 1.0416\n",
            "Epoch 57/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15.9073 - mae: 1.0310 - val_loss: 8.3208 - val_mae: 1.0622\n",
            "Epoch 58/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.1315 - mae: 1.0597 - val_loss: 8.1456 - val_mae: 1.0575\n",
            "Epoch 59/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.5265 - mae: 1.0497 - val_loss: 7.8940 - val_mae: 1.0207\n",
            "Epoch 60/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 46.4832 - mae: 1.0911 - val_loss: 7.5411 - val_mae: 1.0201\n",
            "Epoch 61/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 27.9202 - mae: 1.0764 - val_loss: 8.0768 - val_mae: 1.0321\n",
            "Epoch 62/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 26.0387 - mae: 1.0739 - val_loss: 7.6364 - val_mae: 1.0297\n",
            "Epoch 63/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 57.7915 - mae: 1.1099 - val_loss: 7.2653 - val_mae: 1.0184\n",
            "Epoch 64/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 28.2233 - mae: 1.0374 - val_loss: 7.3927 - val_mae: 1.0266\n",
            "Epoch 65/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.1104 - mae: 0.9823 - val_loss: 7.3010 - val_mae: 1.0390\n",
            "Epoch 66/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 14.2405 - mae: 1.0559 - val_loss: 7.7025 - val_mae: 1.0272\n",
            "Epoch 67/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.3395 - mae: 1.0577 - val_loss: 6.7744 - val_mae: 1.0231\n",
            "Epoch 68/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 35.0829 - mae: 1.0608 - val_loss: 6.9837 - val_mae: 1.0054\n",
            "Epoch 69/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 18.0206 - mae: 1.0057 - val_loss: 6.7505 - val_mae: 1.0225\n",
            "Epoch 70/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.1901 - mae: 1.0168 - val_loss: 7.7138 - val_mae: 1.0619\n",
            "Epoch 71/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.1319 - mae: 1.0338 - val_loss: 6.7426 - val_mae: 1.0248\n",
            "Epoch 72/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 29.2418 - mae: 1.1565 - val_loss: 6.9080 - val_mae: 1.0243\n",
            "Epoch 73/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.5375 - mae: 0.9749 - val_loss: 6.8629 - val_mae: 1.0129\n",
            "Epoch 74/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.3007 - mae: 0.9665 - val_loss: 7.3478 - val_mae: 1.0495\n",
            "Epoch 75/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 30.1220 - mae: 1.0627 - val_loss: 6.5138 - val_mae: 1.0025\n",
            "Epoch 76/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.5534 - mae: 1.0096 - val_loss: 6.5381 - val_mae: 1.0195\n",
            "Epoch 77/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.3395 - mae: 0.9672 - val_loss: 6.4795 - val_mae: 1.0475\n",
            "Epoch 78/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2754 - mae: 0.9698 - val_loss: 7.5418 - val_mae: 1.0834\n",
            "Epoch 79/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.4908 - mae: 1.0153 - val_loss: 6.1856 - val_mae: 0.9910\n",
            "Epoch 80/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 42.4086 - mae: 1.0684 - val_loss: 6.1500 - val_mae: 0.9893\n",
            "Epoch 81/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.9629 - mae: 0.9432 - val_loss: 6.8978 - val_mae: 1.0305\n",
            "Epoch 82/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 23.8221 - mae: 1.0142 - val_loss: 6.0590 - val_mae: 1.0143\n",
            "Epoch 83/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.9338 - mae: 0.9604 - val_loss: 6.9366 - val_mae: 1.0754\n",
            "Epoch 84/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.0783 - mae: 1.0111 - val_loss: 6.1275 - val_mae: 0.9896\n",
            "Epoch 85/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.2510 - mae: 0.9790 - val_loss: 7.6393 - val_mae: 1.1372\n",
            "Epoch 86/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15.9610 - mae: 1.0525 - val_loss: 6.1083 - val_mae: 1.0404\n",
            "Epoch 87/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.6512 - mae: 0.9564 - val_loss: 6.5959 - val_mae: 1.0325\n",
            "Epoch 88/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 22.2700 - mae: 1.0405 - val_loss: 6.0653 - val_mae: 0.9820\n",
            "Epoch 89/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.6784 - mae: 0.9647 - val_loss: 6.9404 - val_mae: 1.0283\n",
            "Epoch 90/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 17.0554 - mae: 0.9954 - val_loss: 5.9449 - val_mae: 0.9990\n",
            "Epoch 91/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 24.1032 - mae: 0.9904 - val_loss: 6.0012 - val_mae: 0.9982\n",
            "Epoch 92/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 21.2583 - mae: 0.9936 - val_loss: 5.7774 - val_mae: 0.9830\n",
            "Epoch 93/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.0095 - mae: 0.9426 - val_loss: 6.1531 - val_mae: 1.0002\n",
            "Epoch 94/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.7934 - mae: 0.9625 - val_loss: 6.0486 - val_mae: 1.0005\n",
            "Epoch 95/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.4205 - mae: 0.9646 - val_loss: 6.0290 - val_mae: 1.0022\n",
            "Epoch 96/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.4118 - mae: 0.9465 - val_loss: 5.8116 - val_mae: 0.9890\n",
            "Epoch 97/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.3624 - mae: 0.9616 - val_loss: 6.6738 - val_mae: 1.0028\n",
            "Epoch 98/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.4431 - mae: 0.9515 - val_loss: 5.8270 - val_mae: 0.9684\n",
            "Epoch 99/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.5250 - mae: 0.9162 - val_loss: 6.0173 - val_mae: 0.9862\n",
            "Epoch 100/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.8678 - mae: 0.9314 - val_loss: 6.1681 - val_mae: 0.9890\n",
            "Epoch 101/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.3357 - mae: 0.9498 - val_loss: 5.7311 - val_mae: 0.9778\n",
            "Epoch 102/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.3008 - mae: 0.9428 - val_loss: 6.2044 - val_mae: 0.9944\n",
            "Epoch 103/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.6741 - mae: 0.9472 - val_loss: 6.2290 - val_mae: 1.0129\n",
            "Epoch 104/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.9095 - mae: 0.9658 - val_loss: 5.8506 - val_mae: 0.9833\n",
            "Epoch 105/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 25.3729 - mae: 0.9670 - val_loss: 5.6984 - val_mae: 0.9562\n",
            "Epoch 106/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.2374 - mae: 0.8844 - val_loss: 6.4293 - val_mae: 0.9876\n",
            "Epoch 107/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.5390 - mae: 0.8957 - val_loss: 6.4752 - val_mae: 1.0437\n",
            "Epoch 108/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.8382 - mae: 0.9420 - val_loss: 6.0530 - val_mae: 0.9865\n",
            "Epoch 109/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.0564 - mae: 0.9232 - val_loss: 5.7326 - val_mae: 0.9514\n",
            "Epoch 110/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.8614 - mae: 0.8900 - val_loss: 6.3650 - val_mae: 0.9813\n",
            "Epoch 111/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15.1913 - mae: 0.9506 - val_loss: 5.6551 - val_mae: 0.9495\n",
            "Epoch 112/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.9501 - mae: 0.8913 - val_loss: 6.1608 - val_mae: 0.9682\n",
            "Epoch 113/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.9900 - mae: 0.9297 - val_loss: 5.9148 - val_mae: 0.9547\n",
            "Epoch 114/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 34.8888 - mae: 1.0155 - val_loss: 5.5918 - val_mae: 0.9456\n",
            "Epoch 115/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.0706 - mae: 0.9156 - val_loss: 6.0108 - val_mae: 0.9462\n",
            "Epoch 116/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.3393 - mae: 0.8931 - val_loss: 6.1982 - val_mae: 1.0018\n",
            "Epoch 117/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 16.8119 - mae: 0.9423 - val_loss: 5.6082 - val_mae: 0.9215\n",
            "Epoch 118/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 18.2005 - mae: 0.9378 - val_loss: 5.5711 - val_mae: 0.9243\n",
            "Epoch 119/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.6131 - mae: 0.8741 - val_loss: 6.2363 - val_mae: 1.0180\n",
            "Epoch 120/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.2761 - mae: 0.9343 - val_loss: 5.8978 - val_mae: 0.9602\n",
            "Epoch 121/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.1347 - mae: 0.8787 - val_loss: 7.0566 - val_mae: 1.0765\n",
            "Epoch 122/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.5109 - mae: 0.9793 - val_loss: 5.9373 - val_mae: 0.9357\n",
            "Epoch 123/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.7560 - mae: 0.9157 - val_loss: 5.9464 - val_mae: 0.9452\n",
            "Epoch 124/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 39.4036 - mae: 0.9863 - val_loss: 5.3111 - val_mae: 0.9061\n",
            "Epoch 125/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.1802 - mae: 0.8801 - val_loss: 6.0418 - val_mae: 0.9571\n",
            "Epoch 126/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.7455 - mae: 0.8946 - val_loss: 6.3415 - val_mae: 0.9667\n",
            "Epoch 127/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.7811 - mae: 0.8975 - val_loss: 6.6588 - val_mae: 0.9613\n",
            "Epoch 128/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.8236 - mae: 0.9105 - val_loss: 5.6917 - val_mae: 0.9194\n",
            "Epoch 129/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.6879 - mae: 0.8900 - val_loss: 5.8146 - val_mae: 0.9169\n",
            "Epoch 130/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.1762 - mae: 0.8789 - val_loss: 6.0159 - val_mae: 0.9440\n",
            "Epoch 131/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.2223 - mae: 0.9005 - val_loss: 6.2270 - val_mae: 0.9616\n",
            "Epoch 132/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 28.4596 - mae: 0.9256 - val_loss: 5.4910 - val_mae: 0.9073\n",
            "Epoch 133/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.3757 - mae: 0.8760 - val_loss: 5.6511 - val_mae: 0.9178\n",
            "Epoch 134/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.0126 - mae: 0.8386 - val_loss: 6.7263 - val_mae: 1.0263\n",
            "Epoch 135/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.6419 - mae: 0.9257 - val_loss: 6.6853 - val_mae: 0.9307\n",
            "Epoch 136/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.4959 - mae: 0.9088 - val_loss: 5.5950 - val_mae: 0.9023\n",
            "Epoch 137/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.2487 - mae: 0.8398 - val_loss: 6.3916 - val_mae: 0.9631\n",
            "Epoch 138/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.5384 - mae: 0.8898 - val_loss: 5.8123 - val_mae: 0.9125\n",
            "Epoch 139/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.9039 - mae: 0.8446 - val_loss: 6.1777 - val_mae: 0.9436\n",
            "Epoch 140/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.5534 - mae: 0.8830 - val_loss: 5.8270 - val_mae: 0.9141\n",
            "Epoch 141/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.5428 - mae: 0.8902 - val_loss: 5.7965 - val_mae: 0.9052\n",
            "Epoch 142/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.6575 - mae: 0.8295 - val_loss: 6.3663 - val_mae: 0.9768\n",
            "Epoch 143/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.9038 - mae: 0.9066 - val_loss: 5.5826 - val_mae: 0.8970\n",
            "Epoch 144/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.2493 - mae: 0.8673 - val_loss: 5.8371 - val_mae: 0.9139\n",
            "Epoch 145/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.9670 - mae: 0.8366 - val_loss: 7.1552 - val_mae: 1.1530\n",
            "Epoch 146/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.0610 - mae: 0.9285 - val_loss: 7.2135 - val_mae: 1.0584\n",
            "Epoch 147/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 13.7652 - mae: 0.9441 - val_loss: 5.6726 - val_mae: 0.9065\n",
            "Epoch 148/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.1284 - mae: 0.8364 - val_loss: 6.2990 - val_mae: 0.9200\n",
            "Epoch 149/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.5797 - mae: 0.8656 - val_loss: 6.1665 - val_mae: 0.9221\n",
            "Epoch 150/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 11.3335 - mae: 0.8666 - val_loss: 5.7497 - val_mae: 0.8951\n",
            "Epoch 151/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.3819 - mae: 0.8532 - val_loss: 5.9406 - val_mae: 0.9171\n",
            "Epoch 152/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 10.8325 - mae: 0.8668 - val_loss: 6.1572 - val_mae: 0.9062\n",
            "Epoch 153/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.0338 - mae: 0.8321 - val_loss: 6.3877 - val_mae: 0.9267\n",
            "Epoch 154/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.5178 - mae: 0.8411 - val_loss: 5.8855 - val_mae: 0.8971\n",
            "Epoch 155/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 11.4655 - mae: 0.8550 - val_loss: 5.7807 - val_mae: 0.8889\n",
            "Epoch 156/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3.7901 - mae: 0.8161 - val_loss: 6.6197 - val_mae: 0.9460\n",
            "Epoch 157/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.7270 - mae: 0.9254 - val_loss: 6.3945 - val_mae: 0.9313\n",
            "Epoch 158/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.9034 - mae: 0.8783 - val_loss: 6.5754 - val_mae: 0.9541\n",
            "Epoch 159/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.6521 - mae: 0.9027 - val_loss: 7.0103 - val_mae: 0.9347\n",
            "Epoch 160/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 9.3363 - mae: 0.8978 - val_loss: 5.8200 - val_mae: 0.8932\n",
            "Epoch 161/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.9577 - mae: 0.8574 - val_loss: 5.8790 - val_mae: 0.9206\n",
            "Epoch 162/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.6957 - mae: 0.8715 - val_loss: 5.8546 - val_mae: 0.9094\n",
            "Epoch 163/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 19.4202 - mae: 0.9051 - val_loss: 5.6554 - val_mae: 0.8813\n",
            "Epoch 164/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3.1023 - mae: 0.7973 - val_loss: 5.9952 - val_mae: 0.9104\n",
            "Epoch 165/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 17.7173 - mae: 0.9302 - val_loss: 5.7289 - val_mae: 0.8825\n",
            "Epoch 166/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.2176 - mae: 0.8059 - val_loss: 6.2235 - val_mae: 0.9454\n",
            "Epoch 167/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.4071 - mae: 0.8613 - val_loss: 6.8393 - val_mae: 0.9589\n",
            "Epoch 168/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2628 - mae: 0.8289 - val_loss: 6.5299 - val_mae: 0.9051\n",
            "Epoch 169/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.1715 - mae: 0.8279 - val_loss: 6.1285 - val_mae: 0.8944\n",
            "Epoch 170/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.9385 - mae: 0.8592 - val_loss: 6.3558 - val_mae: 0.8986\n",
            "Epoch 171/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.5626 - mae: 0.8268 - val_loss: 6.0267 - val_mae: 0.8906\n",
            "Epoch 172/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.4909 - mae: 0.8798 - val_loss: 6.0946 - val_mae: 0.8776\n",
            "Epoch 173/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.9641 - mae: 0.8577 - val_loss: 5.9712 - val_mae: 0.9011\n",
            "Epoch 174/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.6239 - mae: 0.8441 - val_loss: 6.2195 - val_mae: 0.9058\n",
            "Epoch 175/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.9141 - mae: 0.7897 - val_loss: 6.6184 - val_mae: 0.9801\n",
            "Epoch 176/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.7576 - mae: 0.8458 - val_loss: 6.6823 - val_mae: 0.8941\n",
            "Epoch 177/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.7217 - mae: 0.8057 - val_loss: 6.3099 - val_mae: 0.8737\n",
            "Epoch 178/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.6222 - mae: 0.8545 - val_loss: 6.2614 - val_mae: 0.8830\n",
            "Epoch 179/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.7703 - mae: 0.8617 - val_loss: 6.0480 - val_mae: 0.8881\n",
            "Epoch 180/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.5556 - mae: 0.8410 - val_loss: 6.1697 - val_mae: 0.8852\n",
            "Epoch 181/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.0731 - mae: 0.8079 - val_loss: 7.1980 - val_mae: 0.9839\n",
            "Epoch 182/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.1911 - mae: 0.8475 - val_loss: 6.1026 - val_mae: 0.8928\n",
            "Epoch 183/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 14.5749 - mae: 0.9059 - val_loss: 5.9054 - val_mae: 0.8694\n",
            "Epoch 184/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.1128 - mae: 0.8147 - val_loss: 6.2270 - val_mae: 0.8922\n",
            "Epoch 185/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 10.1799 - mae: 0.8498 - val_loss: 5.8758 - val_mae: 0.8696\n",
            "Epoch 186/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.4776 - mae: 0.7799 - val_loss: 7.1502 - val_mae: 1.0255\n",
            "Epoch 187/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.9729 - mae: 0.8853 - val_loss: 6.6768 - val_mae: 0.9627\n",
            "Epoch 188/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3.9143 - mae: 0.8211 - val_loss: 7.2139 - val_mae: 0.9734\n",
            "Epoch 189/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.0011 - mae: 0.8318 - val_loss: 6.3094 - val_mae: 0.8842\n",
            "Epoch 190/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.9910 - mae: 0.8280 - val_loss: 6.0491 - val_mae: 0.8765\n",
            "Epoch 191/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 12.8494 - mae: 0.8932 - val_loss: 5.8976 - val_mae: 0.8638\n",
            "Epoch 192/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 20.7416 - mae: 0.8860 - val_loss: 6.7654 - val_mae: 0.8807\n",
            "Epoch 193/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.8004 - mae: 0.8526 - val_loss: 5.9372 - val_mae: 0.8773\n",
            "Epoch 194/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.0292 - mae: 0.8805 - val_loss: 6.5748 - val_mae: 0.8773\n",
            "Epoch 195/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.6471 - mae: 0.8156 - val_loss: 6.8806 - val_mae: 1.0182\n",
            "Epoch 196/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.2082 - mae: 0.8649 - val_loss: 6.7859 - val_mae: 0.8976\n",
            "Epoch 197/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 13.2128 - mae: 0.8980 - val_loss: 6.0079 - val_mae: 0.8660\n",
            "Epoch 198/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.5632 - mae: 0.8320 - val_loss: 6.3257 - val_mae: 0.8832\n",
            "Epoch 199/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.8633 - mae: 0.8219 - val_loss: 7.0049 - val_mae: 0.8982\n",
            "Epoch 200/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.5426 - mae: 0.8312 - val_loss: 5.9130 - val_mae: 0.8478\n",
            "Epoch 201/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.3107 - mae: 0.8252 - val_loss: 6.1790 - val_mae: 0.8577\n",
            "Epoch 202/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.7506 - mae: 0.8071 - val_loss: 5.9752 - val_mae: 0.8509\n",
            "Epoch 203/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.9601 - mae: 0.7783 - val_loss: 6.9151 - val_mae: 0.9461\n",
            "Epoch 204/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.3580 - mae: 0.8146 - val_loss: 6.9303 - val_mae: 0.8959\n",
            "Epoch 205/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.1570 - mae: 0.8213 - val_loss: 6.3389 - val_mae: 0.8498\n",
            "Epoch 206/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3.7190 - mae: 0.7859 - val_loss: 7.0422 - val_mae: 0.9393\n",
            "Epoch 207/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 12.2414 - mae: 0.8408 - val_loss: 5.8882 - val_mae: 0.8583\n",
            "Epoch 208/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.9274 - mae: 0.8197 - val_loss: 6.3423 - val_mae: 0.8786\n",
            "Epoch 209/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3.4807 - mae: 0.8015 - val_loss: 7.1429 - val_mae: 0.9071\n",
            "Epoch 210/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.3184 - mae: 0.8685 - val_loss: 6.0666 - val_mae: 0.8518\n",
            "Epoch 211/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 8.1638 - mae: 0.8233 - val_loss: 5.9957 - val_mae: 0.8382\n",
            "Epoch 212/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 5.3145 - mae: 0.7843 - val_loss: 6.0837 - val_mae: 0.8428\n",
            "Epoch 213/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 3.4502 - mae: 0.7943 - val_loss: 7.0369 - val_mae: 0.8935\n",
            "Epoch 214/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.7028 - mae: 0.8991 - val_loss: 6.3907 - val_mae: 0.8500\n",
            "Epoch 215/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 15.0651 - mae: 0.8338 - val_loss: 5.9801 - val_mae: 0.8612\n",
            "Epoch 216/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.4495 - mae: 0.8078 - val_loss: 6.2122 - val_mae: 0.8481\n",
            "Epoch 217/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.1864 - mae: 0.7919 - val_loss: 6.7268 - val_mae: 0.9203\n",
            "Epoch 218/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.8871 - mae: 0.8450 - val_loss: 6.2008 - val_mae: 0.8657\n",
            "Epoch 219/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 5.6609 - mae: 0.8033 - val_loss: 6.5397 - val_mae: 0.8864\n",
            "Epoch 220/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.4897 - mae: 0.7874 - val_loss: 6.7072 - val_mae: 0.8696\n",
            "Epoch 221/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 6.7198 - mae: 0.7949 - val_loss: 5.9068 - val_mae: 0.8329\n",
            "Epoch 222/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 4.3153 - mae: 0.7829 - val_loss: 6.7037 - val_mae: 0.8689\n",
            "Epoch 223/3000\n",
            "57/57 [==============================] - 0s 2ms/step - loss: 7.0904 - mae: 0.8562 - val_loss: 6.5063 - val_mae: 0.8895\n",
            "Epoch 224/3000\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.4059 - mae: 0.7926 - val_loss: 7.1813 - val_mae: 0.9223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceq0pc7jUTxk",
        "outputId": "c8eda858-f4a9-4a2a-e4e5-731dbd83ab78"
      },
      "source": [
        "# 테스트 세트에 대한 성능 평가\n",
        "print(\"Accuracy : \", model6.evaluate(X_test_scaled, y_testd)[1])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 0s 972us/step - loss: 11.7356 - mae: 0.9017\n",
            "Accuracy :  0.9017428159713745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tatjlGBdI6gB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnSWZC02I7cU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UTrpGqWI7it"
      },
      "source": [
        "# 성능평가 최종"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgYjSAfGI92X"
      },
      "source": [
        "rf = RandomForestRegressor(max_depth=11, random_state=0)\n",
        "\n",
        "mlp = MLPRegressor(random_state=0, hidden_layer_sizes=(10,10))\n",
        "\n",
        "\n",
        "# 자동 종료를 위해 추가\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "model4 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model4.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "history4 = model4.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "model5 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dense(8, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTxBxV3EJp5L",
        "outputId": "579e81f2-6bc7-4f65-ec07-7e762baee28b"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "X_res = np.array(X_res)\n",
        "y_res = np.array(y_res)\n",
        "\n",
        "\n",
        "rf = RandomForestRegressor(max_depth=11, random_state=0)\n",
        "\n",
        "for train,test in kf.split(X_res,y_res):\n",
        "  rf = RandomForestRegressor(max_depth=11, random_state=0)\n",
        "  rf.fit(X_res[train], y_res[train])\n",
        "  print(rf.score(X_res[test], y_res[test]))\n",
        "  print(mean_squared_error(y_res[test], rf.predict(X_res[test])))\n",
        "  print(mean_absolute_error(y_res[test], rf.predict(X_res[test])))\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9818978586816753\n",
            "3.0669812563896244\n",
            "0.581497211332357\n",
            "\n",
            "\n",
            "0.9468431114684789\n",
            "15.072933444538153\n",
            "0.6650790841608569\n",
            "\n",
            "\n",
            "0.9826199873919741\n",
            "2.551726166394124\n",
            "0.5916477956099763\n",
            "\n",
            "\n",
            "0.9640301437519567\n",
            "6.775687689722222\n",
            "0.6529677530105051\n",
            "\n",
            "\n",
            "0.9830549971441325\n",
            "2.50653043977803\n",
            "0.5924612650707548\n",
            "\n",
            "\n",
            "0.8981986840669036\n",
            "39.79997124537171\n",
            "0.7138426173427876\n",
            "\n",
            "\n",
            "0.9864065838344989\n",
            "2.687177130685316\n",
            "0.6150639759760421\n",
            "\n",
            "\n",
            "0.977900459811904\n",
            "3.4441327577931173\n",
            "0.6176411996028255\n",
            "\n",
            "\n",
            "0.9709845947361029\n",
            "9.139235681583422\n",
            "0.6302676967678215\n",
            "\n",
            "\n",
            "0.9759130410712755\n",
            "4.932558937521613\n",
            "0.6621796109764766\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-2CcZOGKKAj",
        "outputId": "e7d88758-bc48-4233-dd95-33bea1309a5a"
      },
      "source": [
        "std = StandardScaler()\n",
        "\n",
        "for train,test in kf.split(X_res,y_res):\n",
        "  X_train_scaled = std.fit_transform(X_res[train])\n",
        "  X_test_scaled = std.transform(X_res[test])\n",
        "  mlp = MLPRegressor(random_state=0, hidden_layer_sizes=(10,10), max_iter=1000)\n",
        "  mlp.fit(X_train_scaled, y_res[train])\n",
        "  print(mlp.score(X_test_scaled, y_res[test]))\n",
        "  print(mean_squared_error(y_res[test], mlp.predict(X_test_scaled)))\n",
        "  print(mean_absolute_error(y_res[test], mlp.predict(X_test_scaled)))\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9525109265909998\n",
            "8.045904374930254\n",
            "0.8428739454785087\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9356000836382351\n",
            "18.260956951592444\n",
            "0.9101387149459275\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9800446725333054\n",
            "2.9298328145178334\n",
            "0.7939157534919336\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9771311198128364\n",
            "4.3078401229453265\n",
            "0.7498555771445173\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9756962170571164\n",
            "3.5950523152023086\n",
            "0.811100615155521\n",
            "\n",
            "\n",
            "0.802062499099197\n",
            "77.38511798226695\n",
            "1.115095523638183\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9406582650072468\n",
            "11.730807857734424\n",
            "0.8515181335339778\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9739696399948331\n",
            "4.056736693518806\n",
            "0.7543372870241808\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8691607598021904\n",
            "41.21157852842186\n",
            "0.9074545051125499\n",
            "\n",
            "\n",
            "0.8651141542572047\n",
            "27.62209982308539\n",
            "0.9590527977330032\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4wL13XxKT6A",
        "outputId": "2dd68cc5-2129-4dbc-c2e6-d5f14f31d1f5"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "model4 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model4.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "for train,test in kf.split(X_res,y_res):\n",
        "\n",
        "  X_traind, X_valid, y_traind, y_valid = train_test_split(X_res[train], y_res[train], random_state=0)\n",
        "  std = StandardScaler()\n",
        "  X_train_scaled = std.fit_transform(X_traind)\n",
        "  X_valid_scaled = std.transform(X_valid)\n",
        "  X_test_scaled = std.transform(X_res[test])\n",
        "\n",
        "  history4 = model4.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping], verbose=0)\n",
        "  print(\"Loss : \", model4.evaluate(X_test_scaled, y_res[test])[1])\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 987us/step - loss: 2.2673 - mae: 0.6126\n",
            "Loss :  0.6126148700714111\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 17.0380 - mae: 0.7185\n",
            "Loss :  0.7185357213020325\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 2.0912 - mae: 0.6181\n",
            "Loss :  0.6181231141090393\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 2.9793 - mae: 0.6401\n",
            "Loss :  0.6401382088661194\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 2.3629 - mae: 0.6173\n",
            "Loss :  0.6173050999641418\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 2.3770 - mae: 0.6245\n",
            "Loss :  0.6245232224464417\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 2.6128 - mae: 0.6243\n",
            "Loss :  0.6242926120758057\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 2.4278 - mae: 0.6277\n",
            "Loss :  0.6277058720588684\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 4.9252 - mae: 0.6377\n",
            "Loss :  0.6376808285713196\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 3.7041 - mae: 0.7003\n",
            "Loss :  0.7003070712089539\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbNWsj-7KVeP",
        "outputId": "7af3b539-5f60-4603-ac42-00c827f3893b"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "model5 = Sequential([\n",
        "      Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dense(8, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tensorflow.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model5.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "for train,test in kf.split(X_res,y_res):\n",
        "\n",
        "  X_traind, X_valid, y_traind, y_valid = train_test_split(X_res[train], y_res[train], random_state=0)\n",
        "  std = StandardScaler()\n",
        "  X_train_scaled = std.fit_transform(X_traind)\n",
        "  X_valid_scaled = std.transform(X_valid)\n",
        "  X_test_scaled = std.transform(X_res[test])\n",
        "\n",
        "  history5 = model5.fit(X_train_scaled, y_traind, validation_data=(X_valid_scaled, y_valid), epochs=3000, batch_size=500,\n",
        "                    callbacks=[early_stopping], verbose=0)\n",
        "  print(\"Loss : \", model5.evaluate(X_test_scaled, y_res[test])[1])\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 3.5979 - mae: 0.6835\n",
            "Loss :  0.6834807991981506\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 11.8944 - mae: 0.7650\n",
            "Loss :  0.7649785876274109\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 3.3977 - mae: 0.6931\n",
            "Loss :  0.6931307315826416\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 2.1963 - mae: 0.6199\n",
            "Loss :  0.6198510527610779\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.5707 - mae: 0.5856\n",
            "Loss :  0.585618793964386\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 966us/step - loss: 1.9677 - mae: 0.6092\n",
            "Loss :  0.6092431545257568\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 3.3151 - mae: 0.6561\n",
            "Loss :  0.656103253364563\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.6748 - mae: 0.6083\n",
            "Loss :  0.608311653137207\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 10.4970 - mae: 0.6604\n",
            "Loss :  0.6603654026985168\n",
            "\n",
            "\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 3.2552 - mae: 0.6168\n",
            "Loss :  0.6167736053466797\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4fwneind-j7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, random_state=0)\n",
        "\n",
        "std = StandardScaler()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIG42zGfeKox"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "rf = RandomForestRegressor(max_depth=11, random_state=0)\n",
        "cv = cross_val_score(rf, X_res, y_res, cv=10 ,scoring='neg_mean_squared_error')"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s2QF1W3emsl",
        "outputId": "526f7757-8298-4958-9f62-2576bf52d7a2"
      },
      "source": [
        "print(-cv)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.83323991e+02 1.15531056e+00 2.32836534e+00 1.02071158e+01\n",
            " 4.06528344e-01 3.57428686e-01 3.65065445e-01 4.34760745e-01\n",
            " 4.51534855e-01 2.77587411e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa6QgjRmjKRb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}